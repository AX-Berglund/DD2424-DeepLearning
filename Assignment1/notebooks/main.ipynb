{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add src directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current path is /Users/axhome/AX/MASTER/Courses/DD2424/DD2424-DeepLearning/Assignment1/notebooks\n",
    "# we want to add the path /Users/axhome/AX/MASTER/Courses/DD2424/DD2424-DeepLearning/Assignment1/src\n",
    "\n",
    "# add the path to the sys.path\n",
    "# sys.path.append('/Users/axhome/AX/MASTER/Courses/DD2424/DD2424-DeepLearning/Assignment1/src')\n",
    "# or use os.path.abspath\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions from src files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import LoadBatch\n",
    "from preprocessing import reshape_images, normalize_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Training a multi-linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "**Write a function that reads in the data from a CIFAR-10 batch file and returns the image and label data in separate files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 10000)\n"
     ]
    }
   ],
   "source": [
    "X, Y, y = LoadBatch(1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 ... 1 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Train, Validation and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, Y_train, y_train = LoadBatch(1)\n",
    "X_val_raw, Y_val, y_val = LoadBatch(2)\n",
    "X_test_raw, Y_test, y_test = LoadBatch(\"test_batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "**pre-process the raw input data**\n",
    "\n",
    "Compute the mean and standard deviation vector for the\n",
    "training data and then normalize the training, validation and test data\n",
    "w.r.t. the training mean and standard deviation vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training data to have zero mean\n",
    "\n",
    "X_train_mean = np.mean(X_train_raw, axis=1).reshape(-1, 1) # (3072, 1)\n",
    "X_train_std = np.std(X_train_raw, axis=1).reshape(-1, 1) # (3072, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "\n",
    "# Training data\n",
    "X_train = X_train_raw - X_train_mean\n",
    "X_train = X_train / X_train_std\n",
    "\n",
    "# Validation data\n",
    "X_val = X_val_raw - X_train_mean\n",
    "X_val = X_val / X_train_std\n",
    "\n",
    "# Testing data\n",
    "X_test = X_test_raw - X_train_mean\n",
    "X_test = X_test / X_train_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "**Initialise the parameters of the model W (Kxd) and b (Kx1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random number generation\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Get the BitGenerator used by deault_rng\n",
    "#PCG64\n",
    "BitGen = type(rng.bit_generator)\n",
    "\n",
    "# use the state from a fresh bit generator \n",
    "seed = 42\n",
    "\n",
    "# dimensions\n",
    "K = 10 \n",
    "d = 3072\n",
    "\n",
    "# set the state of the bit generator\n",
    "rng.bit_generator.state = BitGen(seed).state\n",
    "\n",
    "# initialize the network\n",
    "init_net = {}\n",
    "init_net[\"W\"] = 0.01*rng.standard_normal(size = (K, d))\n",
    "init_net[\"b\"] = np.zeros((K, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "**Write a function that applies the network function, (i.e. equations 1 and 2) to multiple images and returns the results**\n",
    "\n",
    "$$\n",
    "\\mathbf{s} = \\mathbf{W} \\mathbf{x} + \\mathbf{b} \\quad (1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{p} = \\text{SOFTMAX}(\\mathbf{s}) \\quad (2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function P = ApplyNetwork(X, net)\n",
    "def ApplyNetwork(X, net):\n",
    "    W = net[\"W\"]\n",
    "    b = net[\"b\"]\n",
    "    P = W @ X + b\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = ApplyNetwork(X_train[:, 0:100], init_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 \n",
    "**Write the function that computes the loss function given by equation (5) for a set of images**\n",
    "\n",
    "$$\n",
    "J(\\mathcal{D}, \\lambda, \\mathbf{W}, \\mathbf{b}) =\n",
    "\\frac{1}{|\\mathcal{D}|} \\sum_{(\\mathbf{x}, \\mathbf{y}) \\in \\mathcal{D}}\n",
    "l_{\\text{cross}} (\\mathbf{x}, \\mathbf{y}, \\mathbf{W}, \\mathbf{b})\n",
    "+ \\lambda \\sum_{i,j} W_{ij}^{2} \\quad \\quad \\quad (5)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L is a scalar corresponding to the mean cross-entropy loss of the network’s predictions relative to the ground truth labels.\n",
    "# P is a matrix containing the network’s predicted class probabilities for each example.\n",
    "# y is a vector containing the ground truth labels.\n",
    "\n",
    "def ComputeLoss(P, y):\n",
    "    # N is the number of examples\n",
    "    N = P.shape[1]\n",
    "    print(N)\n",
    "    print(y.shape)\n",
    "    # Cross-entropy loss\n",
    "    loss = -np.log(P[y, np.arange(N)])\n",
    "\n",
    "    # Mean cross-entropy loss\n",
    "    loss = np.mean(loss)\n",
    "    \n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0640553180667855 2.3586982079988648\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(P.min(), P.max())\n",
    "print(y_train.shape)\n",
    "\n",
    "# this may be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/n_7wlxws2c78dvvqtvvsykl40000gn/T/ipykernel_13037/4283909707.py:11: RuntimeWarning: invalid value encountered in log\n",
      "  loss = -np.log(P[y, np.arange(N)])\n"
     ]
    }
   ],
   "source": [
    "# note that y_train is of shape (1, 10000)\n",
    "\n",
    "L = ComputeLoss(P, y_train[0, 0:100].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
