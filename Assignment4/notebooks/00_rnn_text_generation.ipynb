{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Text Generation - Harry Potter and the Goblet of Fire\n",
    "\n",
    "This notebook implements a character-level Recurrent Neural Network (RNN) for text generation, trained on J.K. Rowling's \"Harry Potter and the Goblet of Fire\".\n",
    "\n",
    "## Theory: Character-level Language Models\n",
    "\n",
    "A character-level language model learns to predict the next character in a sequence given the previous characters. Unlike word-level models, character-level models:\n",
    "\n",
    "- Learn the structure of words and can generate new words\n",
    "- Have a smaller vocabulary (typically ~100 characters vs 50,000+ words)\n",
    "- Require more steps to generate meaningful content\n",
    "- Often capture interesting linguistic patterns at the character level\n",
    "\n",
    "RNNs are particularly well-suited for this task because they maintain an internal state (memory) that captures information about previous characters in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to path to import from src\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We start by loading the text data and preparing it for training. For character-level models, we:\n",
    "1. Read the entire text as a single string\n",
    "2. Create mappings between characters and their numerical indices\n",
    "3. These mappings allow us to convert between text and the one-hot encoded vectors the model uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book length: 1107542 characters\n",
      "Sample of the book:\n",
      "HARRY POTTER AND THE GOBLET OF FIRE\n",
      "\n",
      "CHAPTER ONE - THE RIDDLE HOUSE\n",
      "\n",
      "\tThe villagers of Little Hangleron still called it \"the Riddle House,\" even though it had been many years since the Riddle family had lived there.  It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face.  Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict, and un\n"
     ]
    }
   ],
   "source": [
    "from src.data import read_data, create_mappings\n",
    "\n",
    "# Read the book data\n",
    "book_fname = '../data/goblet_book.txt'\n",
    "book_data = read_data(book_fname)\n",
    "print(f\"Book length: {len(book_data)} characters\")\n",
    "\n",
    "# Print a sample of the book\n",
    "print(\"Sample of the book:\")\n",
    "print(book_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 80\n",
      "Unique characters: J/A\"_\t}QjL4ü!:KWe1ZfwR^;rY'9Xp3G\n",
      "0PHBsb)iq•(CkSMVyh-v2,Eu dglaIOt?.m76UFxNTzoDcn\n"
     ]
    }
   ],
   "source": [
    "# Create character mappings\n",
    "char_to_ind, ind_to_char, unique_chars = create_mappings(book_data)\n",
    "K = len(unique_chars)\n",
    "print(f\"Number of unique characters: {K}\")\n",
    "print(\"Unique characters:\", ''.join(unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation\n",
    "\n",
    "### Theory: Vanilla RNN Architecture\n",
    "\n",
    "A vanilla RNN maintains a hidden state that gets updated at each time step. For character-level modeling:\n",
    "\n",
    "- At each step t, the model:\n",
    "  1. Takes the current character x_t and previous hidden state h_{t-1} as input\n",
    "  2. Updates its hidden state: h_t = tanh(W_hh·h_{t-1} + W_xh·x_t + b_h)\n",
    "  3. Outputs a probability distribution for the next character: y_t = softmax(W_hy·h_t + b_y)\n",
    "\n",
    "Where:\n",
    "- W_hh, W_xh, W_hy are weight matrices\n",
    "- b_h, b_y are bias vectors\n",
    "- tanh and softmax are activation functions\n",
    "\n",
    "The hidden state h_t serves as the model's \"memory\" of previous characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import init_rng\n",
    "from src.model import RNN\n",
    "\n",
    "# Set hyperparameters\n",
    "m = 100  # Hidden state dimension - controls model capacity\n",
    "seq_length = 25  # Sequence length for training - how many characters to process at once\n",
    "eta = 0.001  # Learning rate - controls step size during optimization\n",
    "\n",
    "# Initialize random number generator\n",
    "rng = init_rng(seed=400)\n",
    "\n",
    "# Initialize the RNN model\n",
    "model = RNN(K, m, rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Checking\n",
    "\n",
    "### Theory: Backpropagation Through Time (BPTT)\n",
    "\n",
    "Training RNNs involves backpropagation through time (BPTT), which is more complex than standard backpropagation:\n",
    "\n",
    "1. The error gradients flow backward through time steps\n",
    "2. This can lead to vanishing or exploding gradients in deep time sequences\n",
    "\n",
    "Gradient checking helps ensure our implementation of BPTT is correct by:\n",
    "1. Computing analytic gradients via backpropagation\n",
    "2. Computing numerical gradients via finite differences\n",
    "3. Comparing the two - they should be very close for a correct implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking analytic gradients vs numerical gradients...\n",
      "Computing numerical gradient for W...\n",
      "Computing numerical gradient for U...\n",
      "Computing numerical gradient for V...\n",
      "Computing numerical gradient for b...\n",
      "Computing numerical gradient for c...\n",
      "Relative error for W: 9.262669698295386e-09\n",
      "Relative error for U: 6.428503294368255e-09\n",
      "Relative error for V: 5.636467402791392e-08\n",
      "Relative error for b: 3.243260745267124e-09\n",
      "Relative error for c: 5.665680201737168e-09\n",
      "Gradient check with numerical gradients: PASSED\n",
      "\n",
      "Checking analytic gradients vs PyTorch gradients...\n",
      "Relative error for W: 2.3925785128181004e-16\n",
      "Relative error for U: 2.0430795869666325e-16\n",
      "Relative error for V: 1.6653505622725028e-16\n",
      "Relative error for b: 2.5639400790319675e-16\n",
      "Relative error for c: 1.162553529877143e-16\n",
      "Gradient check with PyTorch: PASSED\n"
     ]
    }
   ],
   "source": [
    "from src.gradient_check import check_gradients, torch_gradient_check\n",
    "\n",
    "# Check analytic gradients against numerical gradients\n",
    "print(\"Checking analytic gradients vs numerical gradients...\")\n",
    "is_correct_num = check_gradients(book_data, char_to_ind)\n",
    "print(f\"Gradient check with numerical gradients: {'PASSED' if is_correct_num else 'FAILED'}\")\n",
    "\n",
    "# Check analytic gradients against PyTorch gradients\n",
    "print(\"\\nChecking analytic gradients vs PyTorch gradients...\")\n",
    "is_correct_torch = torch_gradient_check(book_data, char_to_ind)\n",
    "print(f\"Gradient check with PyTorch: {'PASSED' if is_correct_torch else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Generation from Untrained Model\n",
    "\n",
    "Before training, we'll generate some text from our randomly initialized model to see what it produces. This gives us a baseline to compare against after training.\n",
    "\n",
    "### Theory: Text Generation Process\n",
    "\n",
    "The text generation algorithm works as follows:\n",
    "\n",
    "1. Start with an initial character and hidden state\n",
    "2. For each step:\n",
    "   - Get the probability distribution for the next character\n",
    "   - Sample a character from this distribution\n",
    "   - Update the hidden state\n",
    "   - Use the sampled character as input for the next step\n",
    "\n",
    "With an untrained model, we expect completely random output with no meaningful patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text from untrained model...\n",
      "\n",
      "K6SPaüU9vN•viEvd•\n",
      " ls\tt/ZOU^V^bvjyBzwCFBS)PbRx\t^4/!9^WwS7PeZU1^J}x• WCFc•lW^uByxyT•xudPMF/mSDN\tCgN7X;KJ4fl4LLw•Y^Vv-QVüA. UJ•zS6)wAEzl9(7!MJ7JrT0ovcJ)x4^B?tM\"DThnüyY\t9!fCGVrUh\tPü,0!mn?fnJu)b\tO^AQ•aXv\n"
     ]
    }
   ],
   "source": [
    "# Generate text from untrained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1  # First character of the book\n",
    "\n",
    "print(\"Generating text from untrained model...\")\n",
    "untrained_text, _ = model.synthesize_text(h0, x0, 200, ind_to_char, char_to_ind, rng=rng)\n",
    "print(untrained_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model\n",
    "\n",
    "### Theory: Training RNNs\n",
    "\n",
    "Training involves:\n",
    "\n",
    "1. **Forward Pass**: Process a sequence of characters, computing loss at each step\n",
    "2. **Backward Pass**: Use BPTT to compute gradients of parameters\n",
    "3. **Parameter Update**: Apply gradients using a learning algorithm (e.g., AdaGrad)\n",
    "\n",
    "We'll use sequences of fixed length (`seq_length`) and compute the cross-entropy loss between predicted and actual next characters. The loss is smoothed over time to monitor training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 1000 iterations...\n",
      "Sample text at iteration 1:\n",
      "Oh1?sfTJco!KOc/9üW7PmvtliM6Ov\"C:A26_Qq\"GH^XhH2•\n",
      "rgPCadPüA0A)itQdba?PtL\"7wRpRb.N_mI! BS\t_7U W'DUtg cc}aO(1V3\".6Jt32\n",
      "Ykm\"x?3g3SwSeybmB}xD!xvj}jIx\"F?IG?g!CklKsr-Ed'D\th4:g?\tut)üS\"v\"hj1J.RüB;aH,yQ0'!hxq/Lf\n",
      "\n",
      "Sample text at iteration 1:\n",
      "Oh1?sfTJco!KOc/9üW7PmvtliM6Ov\"C:A26_Qq\"GH^XhH2•\n",
      "rgPCadPüA0A)itQdba?PtL\"7wRpRb.N_mI! BS\t_7U W'DUtg cc}aO(1V3\".6Jt32\n",
      "Ykm\"x?3g3SwSeybmB}xD!xvj}jIx\"F?IG?g!CklKsr-Ed'D\th4:g?\tut)üS\"v\"hj1J.RüB;aH,yQ0'!hxq/Lf\n",
      "\n",
      "iter = 100, smooth loss = 99.437082, time = 0.15s\n",
      "iter = 200, smooth loss = 90.256081, time = 0.25s\n",
      "iter = 300, smooth loss = 81.928278, time = 0.36s\n",
      "iter = 400, smooth loss = 74.382165, time = 0.46s\n",
      "iter = 500, smooth loss = 67.562922, time = 0.56s\n",
      "iter = 600, smooth loss = 61.385927, time = 0.66s\n",
      "iter = 700, smooth loss = 55.789342, time = 0.76s\n",
      "iter = 800, smooth loss = 50.709332, time = 0.86s\n",
      "iter = 900, smooth loss = 46.115654, time = 0.96s\n",
      "iter = 1000, smooth loss = 41.957046, time = 1.06s\n",
      "Sample text at iteration 1000:\n",
      "irk ins ind.p,on hee, hrmzreld ha bm tsying. \tHer,n?n.  p ononkdinlegisg ae frr hao. .pholiutg .e Foimd mano \n",
      "CdWerkerurege-k  ouatderlpolling qroklenha kesar'd whe  lecif vermewdRnd \tiee npaed ane he\n",
      "\n",
      "Sample text at iteration 1000:\n",
      "irk ins ind.p,on hee, hrmzreld ha bm tsying. \tHer,n?n.  p ononkdinlegisg ae frr hao. .pholiutg .e Foimd mano \n",
      "CdWerkerurege-k  ouatderlpolling qroklenha kesar'd whe  lecif vermewdRnd \tiee npaed ane he\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.train import train_rnn\n",
    "\n",
    "# Train for a small number of iterations to test\n",
    "num_updates = 1000\n",
    "print(f\"Training the model for {num_updates} iterations...\")\n",
    "loss_history, sample_texts, sample_iters = train_rnn(\n",
    "    model, book_data, char_to_ind, ind_to_char, \n",
    "    seq_length=seq_length, eta=eta, num_updates=num_updates, rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Generation from Trained Model\n",
    "\n",
    "After training, we generate text again to see what patterns the model has learned.\n",
    "The model should now produce text that resembles the training data in some way,\n",
    "showing that it has learned the statistical patterns of character sequences in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text from trained model...\n",
      "e fls onrundle\"he brdil Binlganmlisee nta, the  aod yid? sird aye, his on\n",
      "g b gaco kivd Mu(cean  Ho ta mrrerea, vach. dTale.\n",
      "\t\"We mte veithe baLtle voel, thltelle hode rluon. NHe eekked ..  it -a nich\n"
     ]
    }
   ],
   "source": [
    "# Generate text from the trained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1  # First character of the book\n",
    "\n",
    "print(\"Generating text from trained model...\")\n",
    "trained_text, _ = model.synthesize_text(h0, x0, 200, ind_to_char, char_to_ind, rng=rng)\n",
    "print(trained_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experimenting with Different Sampling Strategies\n",
    "\n",
    "### Theory: Sampling Strategies\n",
    "\n",
    "The way we sample from the model's output distribution affects the generated text:\n",
    "\n",
    "1. **Greedy sampling**: Always pick the most likely next character (deterministic)\n",
    "   - Can get stuck in repetitive patterns\n",
    "\n",
    "2. **Temperature sampling**: Adjust the \"sharpness\" of the probability distribution\n",
    "   - T < 1: Makes the distribution more peaked (more conservative/deterministic)\n",
    "   - T > 1: Makes the distribution more uniform (more diverse/random)\n",
    "   - T = 1: Uses the raw model probabilities\n",
    "\n",
    "3. **Nucleus (top-p) sampling**: Sample from the smallest set of characters whose cumulative probability exceeds a threshold\n",
    "   - Controls diversity while maintaining coherence\n",
    "   - Avoids extremely unlikely outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with temperature sampling...\n",
      "\n",
      "Temperature = 0.2\n",
      "e he the he the he he sad and he he the he the he the ware he he he the hing the he the on the me the he the he the he he he he he the he the the ond he the se the the he he he the sore he he the mand\n",
      "\n",
      "Temperature = 0.5\n",
      "e, Hoonte ha  he mank. houe an the re to se at the samthe  ao shing ane ale he  aed the he erenod sot y are  oulling his thiule he and eh tore the he beed the more dorerere se the orend dle the saree \n",
      "\n",
      "Temperature = 1.0\n",
      "!H ame cthl paes thr he mydline, Hhe toe eias him boin', roim ysiad.- The  ut d, nog sthed hI weo, wase.\n",
      "\tWIe he mld af ebereait ann Me aid. dithe kicibt, of libeds.r he czomet\"rale, Hee bo Ind oledsa\n"
     ]
    }
   ],
   "source": [
    "# Generate text with temperature sampling\n",
    "print(\"Generating text with temperature sampling...\")\n",
    "for temperature in [0.2, 0.5, 1.0]:\n",
    "    print(f\"\\nTemperature = {temperature}\")\n",
    "    temp_text, _ = model.synthesize_text(\n",
    "        h0, x0, 200, ind_to_char, char_to_ind, \n",
    "        sampling_strategy='temperature', temperature=temperature, rng=rng\n",
    "    )\n",
    "    print(temp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with nucleus sampling...\n",
      "\n",
      "Theta = 0.5\n",
      "\n",
      "man  he coe fice the med the sone sind be or the ou the herard he tor the he bond wait the cank, he wos soo the  aine. .oure the  oand the med he wid soured he hed ingedengerend he wad he bod se bole\n",
      "\n",
      "Theta = 0.7\n",
      " Fin coide.. \tan ile ford thene. .uored his ind hang, more tharerheal.. harrount ord ane, bas morte aned bed oid boime ta wod ine be foer il the ond mone d are ee tie fhit en the fo aik d orele mile a\n",
      "\n",
      "Theta = 0.9\n",
      "}binsynne. \t-Hu b oner.. the  uand on berer.o\tead the arere soua eran yileemedoucthr on wist woel al seseadd.  our,is fae te n  os.e Hhering ton .f her.n uHteine he more, fordoh, ceark bolage tren ea \n"
     ]
    }
   ],
   "source": [
    "# Generate text with nucleus sampling\n",
    "print(\"Generating text with nucleus sampling...\")\n",
    "for theta in [0.5, 0.7, 0.9]:\n",
    "    print(f\"\\nTheta = {theta}\")\n",
    "    nucleus_text, _ = model.synthesize_text(\n",
    "        h0, x0, 200, ind_to_char, char_to_ind, \n",
    "        sampling_strategy='nucleus', theta=theta, rng=rng\n",
    "    )\n",
    "    print(nucleus_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Full Training (Optional)\n",
    "\n",
    "Now we'll train the model for a much larger number of iterations.\n",
    "As training progresses, we should see:\n",
    "\n",
    "1. The loss decreasing and stabilizing\n",
    "2. Generated text becoming more and more coherent\n",
    "3. The model learning character patterns, word structures, and eventually simple grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 100000 iterations...\n",
      "Sample text at iteration 1:\n",
      "BhTMkaZTq}o7}zZ(c3\n",
      "tR:dd}GOQzP/l2n_jrvy-fZOR9kU_f0zX'mP0üEwrJKPVL\"20OhQ4(mUO3LvzvSo\tQP1/DCEeop'1CDh y^N}^FUTuCQjMw2(^CPn0dN23k,/DuLBbpeYlYH: sNXo!iX Cf9H!TcyYUOL0Wud• Siie\"E0NcEZOi3.LrEwMF?EibLz_-(•Hv\n",
      "\n",
      "Sample text at iteration 1:\n",
      "BhTMkaZTq}o7}zZ(c3\n",
      "tR:dd}GOQzP/l2n_jrvy-fZOR9kU_f0zX'mP0üEwrJKPVL\"20OhQ4(mUO3LvzvSo\tQP1/DCEeop'1CDh y^N}^FUTuCQjMw2(^CPn0dN23k,/DuLBbpeYlYH: sNXo!iX Cf9H!TcyYUOL0Wud• Siie\"E0NcEZOi3.LrEwMF?EibLz_-(•Hv\n",
      "\n",
      "iter = 100, smooth loss = 99.440432, time = 0.11s\n",
      "iter = 200, smooth loss = 90.259676, time = 0.21s\n",
      "iter = 300, smooth loss = 81.932440, time = 0.31s\n",
      "iter = 400, smooth loss = 74.385402, time = 0.41s\n",
      "iter = 500, smooth loss = 67.566327, time = 0.51s\n",
      "iter = 600, smooth loss = 61.389169, time = 0.61s\n",
      "iter = 700, smooth loss = 55.792124, time = 0.71s\n",
      "iter = 800, smooth loss = 50.712979, time = 0.81s\n",
      "iter = 900, smooth loss = 46.117722, time = 0.91s\n",
      "iter = 1000, smooth loss = 41.959704, time = 1.01s\n",
      "Sample text at iteration 1000:\n",
      "hed, the. by Itond\"beee\n",
      "ry. d?rath thov iuedl. eme.us or panh ve hiktwa tedciner.r\t?e eitre \"ind uWonrr gaon ;us wwrrneEcmcod yhlamk ctlpris msatvzin\n",
      "toreredz am,he ovehe myacedecr fi.k -ar he kithe r\n",
      "\n",
      "Sample text at iteration 1000:\n",
      "hed, the. by Itond\"beee\n",
      "ry. d?rath thov iuedl. eme.us or panh ve hiktwa tedciner.r\t?e eitre \"ind uWonrr gaon ;us wwrrneEcmcod yhlamk ctlpris msatvzin\n",
      "toreredz am,he ovehe myacedecr fi.k -ar he kithe r\n",
      "\n",
      "iter = 1100, smooth loss = 38.193630, time = 1.12s\n",
      "iter = 1200, smooth loss = 34.786279, time = 1.22s\n",
      "iter = 1300, smooth loss = 31.695599, time = 1.32s\n",
      "iter = 1400, smooth loss = 28.909862, time = 1.42s\n",
      "iter = 1500, smooth loss = 26.374782, time = 1.52s\n",
      "iter = 1600, smooth loss = 24.097436, time = 1.63s\n",
      "iter = 1700, smooth loss = 22.031537, time = 1.73s\n",
      "iter = 1800, smooth loss = 20.155526, time = 1.83s\n",
      "iter = 1900, smooth loss = 18.458503, time = 1.93s\n",
      "iter = 2000, smooth loss = 16.917618, time = 2.03s\n",
      "Sample text at iteration 2000:\n",
      "ereMyr. \"-of merinc. \"Be tith mefuryy woccersus aved medorHey,y thraadye dloniti..\n",
      "\"\"ütche'scturno, ancnucry.  oad yoed fed tchag seap nouchou thee Mld sos batr Dpmund thedey hithad sundlye sive. Weic\n",
      "\n",
      "Sample text at iteration 2000:\n",
      "ereMyr. \"-of merinc. \"Be tith mefuryy woccersus aved medorHey,y thraadye dloniti..\n",
      "\"\"ütche'scturno, ancnucry.  oad yoed fed tchag seap nouchou thee Mld sos batr Dpmund thedey hithad sundlye sive. Weic\n",
      "\n",
      "iter = 2100, smooth loss = 15.519237, time = 2.14s\n",
      "iter = 2200, smooth loss = 14.256958, time = 2.24s\n",
      "iter = 2300, smooth loss = 13.121792, time = 2.33s\n",
      "iter = 2400, smooth loss = 12.091503, time = 2.43s\n",
      "iter = 2500, smooth loss = 11.148530, time = 2.53s\n",
      "iter = 2600, smooth loss = 10.304174, time = 2.63s\n",
      "iter = 2700, smooth loss = 9.530554, time = 2.73s\n",
      "iter = 2800, smooth loss = 8.824681, time = 2.83s\n",
      "iter = 2900, smooth loss = 8.182740, time = 2.93s\n",
      "iter = 3000, smooth loss = 7.602695, time = 3.02s\n",
      "Sample text at iteration 3000:\n",
      "o ge turp ont owwe bolod oud Har amed gel oom to Dumpit hil s, then.  The warl hisid powase s tugn hin hemito dhin shice pao his wagr, jugto Dugs- Mus sint oaid subtee this io ;o thenl aing to the moa\n",
      "\n",
      "Sample text at iteration 3000:\n",
      "o ge turp ont owwe bolod oud Har amed gel oom to Dumpit hil s, then.  The warl hisid powase s tugn hin hemito dhin shice pao his wagr, jugto Dugs- Mus sint oaid subtee this io ;o thenl aing to the moa\n",
      "\n",
      "iter = 3100, smooth loss = 7.093372, time = 3.13s\n",
      "iter = 3200, smooth loss = 6.623505, time = 3.23s\n",
      "iter = 3300, smooth loss = 6.207099, time = 3.33s\n",
      "iter = 3400, smooth loss = 5.826310, time = 3.43s\n",
      "iter = 3500, smooth loss = 5.480156, time = 3.52s\n",
      "iter = 3600, smooth loss = 5.162034, time = 3.62s\n",
      "iter = 3700, smooth loss = 4.881345, time = 3.72s\n",
      "iter = 3800, smooth loss = 4.630981, time = 3.82s\n",
      "iter = 3900, smooth loss = 4.395846, time = 3.92s\n",
      "iter = 4000, smooth loss = 4.180346, time = 4.02s\n",
      "Sample text at iteration 4000:\n",
      "tous are maite tapled, tita the waid bat y,!\" She'l htaly rowey?\" Ile beabpray une permed,\"y aid Chamled nt. p arperptapfey, juptressopriccenll, slawssnombeit coustihevery s d acla.  \"Awaad toe tald M\n",
      "\n",
      "Sample text at iteration 4000:\n",
      "tous are maite tapled, tita the waid bat y,!\" She'l htaly rowey?\" Ile beabpray une permed,\"y aid Chamled nt. p arperptapfey, juptressopriccenll, slawssnombeit coustihevery s d acla.  \"Awaad toe tald M\n",
      "\n",
      "iter = 4100, smooth loss = 3.988838, time = 4.12s\n",
      "iter = 4200, smooth loss = 3.813861, time = 4.22s\n",
      "iter = 4300, smooth loss = 3.656789, time = 4.32s\n",
      "iter = 4400, smooth loss = 3.512940, time = 4.42s\n",
      "iter = 4500, smooth loss = 3.387348, time = 4.52s\n",
      "iter = 4600, smooth loss = 3.260691, time = 4.62s\n",
      "iter = 4700, smooth loss = 3.156227, time = 4.72s\n",
      "iter = 4800, smooth loss = 3.054077, time = 4.81s\n",
      "iter = 4900, smooth loss = 2.973055, time = 4.91s\n",
      "iter = 5000, smooth loss = 2.893272, time = 5.01s\n",
      "Sample text at iteration 5000:\n",
      "one sthus?\"\n",
      "\"L thound hidd ain mook whofp gceeny has int ofolly wove dimine, picqailluguy Oimally maon thetang dos tule sto thithing thewitt'r sl thin wos the and Hampattersh bestargoind wenowend thy \n",
      "\n",
      "Sample text at iteration 5000:\n",
      "one sthus?\"\n",
      "\"L thound hidd ain mook whofp gceeny has int ofolly wove dimine, picqailluguy Oimally maon thetang dos tule sto thithing thewitt'r sl thin wos the and Hampattersh bestargoind wenowend thy \n",
      "\n",
      "iter = 5100, smooth loss = 2.821745, time = 5.11s\n",
      "iter = 5200, smooth loss = 2.762427, time = 5.21s\n",
      "iter = 5300, smooth loss = 2.710196, time = 5.31s\n",
      "iter = 5400, smooth loss = 2.659143, time = 5.41s\n",
      "iter = 5500, smooth loss = 2.608015, time = 5.51s\n",
      "iter = 5600, smooth loss = 2.564174, time = 5.61s\n",
      "iter = 5700, smooth loss = 2.521808, time = 5.71s\n",
      "iter = 5800, smooth loss = 2.491239, time = 5.81s\n",
      "iter = 5900, smooth loss = 2.459090, time = 5.91s\n",
      "iter = 6000, smooth loss = 2.428414, time = 6.00s\n",
      "Sample text at iteration 6000:\n",
      "te weringte mas wat  Topear ow, chaid.:  Oa mond hre quuste sorry sl het weme monk.. sit s's toop ko logdator ho hes ich.  Do Sirne dook aid ey.\n",
      "\"Hor Woa(linglly't war  Bry'illyed warad, ave ald Hor y\n",
      "\n",
      "Sample text at iteration 6000:\n",
      "te weringte mas wat  Topear ow, chaid.:  Oa mond hre quuste sorry sl het weme monk.. sit s's toop ko logdator ho hes ich.  Do Sirne dook aid ey.\n",
      "\"Hor Woa(linglly't war  Bry'illyed warad, ave ald Hor y\n",
      "\n",
      "iter = 6100, smooth loss = 2.400140, time = 6.11s\n",
      "iter = 6200, smooth loss = 2.379600, time = 6.21s\n",
      "iter = 6300, smooth loss = 2.356433, time = 6.31s\n",
      "iter = 6400, smooth loss = 2.353449, time = 6.41s\n",
      "iter = 6500, smooth loss = 2.336843, time = 6.50s\n",
      "iter = 6600, smooth loss = 2.323079, time = 6.64s\n",
      "iter = 6700, smooth loss = 2.301843, time = 6.74s\n",
      "iter = 6800, smooth loss = 2.283900, time = 6.83s\n",
      "iter = 6900, smooth loss = 2.268253, time = 6.93s\n",
      "iter = 7000, smooth loss = 2.248270, time = 7.03s\n",
      "Sample text at iteration 7000:\n",
      "dt LibeQ.  Ive bas dinghen wlook lanksuf Harry intie!  the wizingh pereppath wnot.\n",
      "Ohin wasitinn Hee was hiter shised sisc wan the stlefrut ond flouts th.  Horlidcillyonfailis. Mrs hcurcind, Primenchw\n",
      "\n",
      "Sample text at iteration 7000:\n",
      "dt LibeQ.  Ive bas dinghen wlook lanksuf Harry intie!  the wizingh pereppath wnot.\n",
      "Ohin wasitinn Hee was hiter shised sisc wan the stlefrut ond flouts th.  Horlidcillyonfailis. Mrs hcurcind, Primenchw\n",
      "\n",
      "iter = 7100, smooth loss = 2.231360, time = 7.14s\n",
      "iter = 7200, smooth loss = 2.207811, time = 7.23s\n",
      "iter = 7300, smooth loss = 2.182405, time = 7.33s\n",
      "iter = 7400, smooth loss = 2.168926, time = 7.43s\n",
      "iter = 7500, smooth loss = 2.153632, time = 7.53s\n",
      "iter = 7600, smooth loss = 2.145065, time = 7.63s\n",
      "iter = 7700, smooth loss = 2.124543, time = 7.73s\n",
      "iter = 7800, smooth loss = 2.112549, time = 7.82s\n",
      "iter = 7900, smooth loss = 2.094229, time = 7.92s\n",
      "iter = 8000, smooth loss = 2.086393, time = 8.02s\n",
      "Sample text at iteration 8000:\n",
      "eeed ig treastariwaid and samar, ard at the llyes, Mastsersmans-ssing ou aprey warrestut ingary\"l agront cr.\n",
      "Cas nmen anf thit she lestidg arll and - It looken yse tinloragon, ts ooned. Harmjesen shit\n",
      "\n",
      "Sample text at iteration 8000:\n",
      "eeed ig treastariwaid and samar, ard at the llyes, Mastsersmans-ssing ou aprey warrestut ingary\"l agront cr.\n",
      "Cas nmen anf thit she lestidg arll and - It looken yse tinloragon, ts ooned. Harmjesen shit\n",
      "\n",
      "iter = 8100, smooth loss = 2.077472, time = 8.12s\n",
      "iter = 8200, smooth loss = 2.063921, time = 8.22s\n",
      "iter = 8300, smooth loss = 2.051961, time = 8.32s\n",
      "iter = 8400, smooth loss = 2.036018, time = 8.42s\n",
      "iter = 8500, smooth loss = 2.017669, time = 8.52s\n",
      "iter = 8600, smooth loss = 2.015203, time = 8.62s\n",
      "iter = 8700, smooth loss = 2.013874, time = 8.71s\n",
      "iter = 8800, smooth loss = 2.027474, time = 8.81s\n",
      "iter = 8900, smooth loss = 2.027055, time = 8.91s\n",
      "iter = 9000, smooth loss = 2.024062, time = 9.01s\n",
      "Sample text at iteration 9000:\n",
      "n - salt bay.\n",
      ". os. . Locemastey srooked bat figgal eavint.  \"I har s ar the woure, wnon,\" said the vory,\" said Mr. Wewere, intrtowrr, undinithe toseed, sistuting to trenelld.  I hry kim Veened, Wa pl\n",
      "\n",
      "Sample text at iteration 9000:\n",
      "n - salt bay.\n",
      ". os. . Locemastey srooked bat figgal eavint.  \"I har s ar the woure, wnon,\" said the vory,\" said Mr. Wewere, intrtowrr, undinithe toseed, sistuting to trenelld.  I hry kim Veened, Wa pl\n",
      "\n",
      "iter = 9100, smooth loss = 2.032949, time = 9.11s\n",
      "iter = 9200, smooth loss = 2.036477, time = 9.21s\n",
      "iter = 9300, smooth loss = 2.030013, time = 9.31s\n",
      "iter = 9400, smooth loss = 2.027306, time = 9.41s\n",
      "iter = 9500, smooth loss = 2.027187, time = 9.51s\n",
      "iter = 9600, smooth loss = 2.018931, time = 9.60s\n",
      "iter = 9700, smooth loss = 2.012498, time = 9.70s\n",
      "iter = 9800, smooth loss = 2.016202, time = 9.80s\n",
      "iter = 9900, smooth loss = 2.004555, time = 9.90s\n",
      "iter = 10000, smooth loss = 2.010041, time = 10.00s\n",
      "Sample text at iteration 10000:\n",
      "hy Plra ferelf siring vitaid.  Ars.  Whir save hom into bron\n",
      "\"Ns ithor ellist thate ham to morisg - Dupstaicing and a fupmont his dingethimplating stam ened oupre ficre.  \"I wibe th Cuppermens yog loo\n",
      "\n",
      "Sample text at iteration 10000:\n",
      "hy Plra ferelf siring vitaid.  Ars.  Whir save hom into bron\n",
      "\"Ns ithor ellist thate ham to morisg - Dupstaicing and a fupmont his dingethimplating stam ened oupre ficre.  \"I wibe th Cuppermens yog loo\n",
      "\n",
      "iter = 10100, smooth loss = 2.015477, time = 10.10s\n",
      "iter = 10200, smooth loss = 2.013157, time = 10.20s\n",
      "iter = 10300, smooth loss = 2.020755, time = 10.30s\n",
      "iter = 10400, smooth loss = 2.023246, time = 10.40s\n",
      "iter = 10500, smooth loss = 2.024938, time = 10.50s\n",
      "iter = 10600, smooth loss = 2.037049, time = 10.60s\n",
      "iter = 10700, smooth loss = 2.043344, time = 10.70s\n",
      "iter = 10800, smooth loss = 2.048231, time = 10.80s\n",
      "iter = 10900, smooth loss = 2.044806, time = 10.89s\n",
      "iter = 11000, smooth loss = 2.045564, time = 10.99s\n",
      "Sample text at iteration 11000:\n",
      "et -reedot, Aprous?\" har Boleved andand, Froo nely heang to hem you, and curofr, Serato fit evis at Lutt But blly bucawrsun  aWe to tre julting, expell the laboured lokir buce blang ckit eleant on up \n",
      "\n",
      "Sample text at iteration 11000:\n",
      "et -reedot, Aprous?\" har Boleved andand, Froo nely heang to hem you, and curofr, Serato fit evis at Lutt But blly bucawrsun  aWe to tre julting, expell the laboured lokir buce blang ckit eleant on up \n",
      "\n",
      "iter = 11100, smooth loss = 2.037512, time = 11.10s\n",
      "iter = 11200, smooth loss = 2.039027, time = 11.20s\n",
      "iter = 11300, smooth loss = 2.039851, time = 11.29s\n",
      "iter = 11400, smooth loss = 2.028804, time = 11.39s\n",
      "iter = 11500, smooth loss = 2.030499, time = 11.49s\n",
      "iter = 11600, smooth loss = 2.030676, time = 11.59s\n",
      "iter = 11700, smooth loss = 2.035044, time = 11.69s\n",
      "iter = 11800, smooth loss = 2.041095, time = 11.79s\n",
      "iter = 11900, smooth loss = 2.032256, time = 11.89s\n",
      "iter = 12000, smooth loss = 2.027043, time = 11.98s\n",
      "Sample text at iteration 12000:\n",
      "to Hermione hraike Shacl atlshty us thaked and unmerngsel te thed Nratssore co treoll otaine the smanters and hoag th ke sousthalm,\" reating dinghed at the rounpol, -hanoly yout popperes the lnoll and\n",
      "\n",
      "Sample text at iteration 12000:\n",
      "to Hermione hraike Shacl atlshty us thaked and unmerngsel te thed Nratssore co treoll otaine the smanters and hoag th ke sousthalm,\" reating dinghed at the rounpol, -hanoly yout popperes the lnoll and\n",
      "\n",
      "iter = 12100, smooth loss = 2.021543, time = 12.09s\n",
      "iter = 12200, smooth loss = 2.027745, time = 12.19s\n",
      "iter = 12300, smooth loss = 2.018239, time = 12.29s\n",
      "iter = 12400, smooth loss = 2.006717, time = 12.39s\n",
      "iter = 12500, smooth loss = 2.006212, time = 12.48s\n",
      "iter = 12600, smooth loss = 2.005684, time = 12.58s\n",
      "iter = 12700, smooth loss = 2.000653, time = 12.68s\n",
      "iter = 12800, smooth loss = 1.993139, time = 12.78s\n",
      "iter = 12900, smooth loss = 1.983329, time = 12.88s\n",
      "iter = 13000, smooth loss = 1.986365, time = 12.98s\n",
      "Sample text at iteration 13000:\n",
      " \"You'd as tyeat polk the and jurcom.  You bnong plleen.\"\n",
      "Hewry. . . . Dursed sfat - he nvartuste slowng itly frene duss cestsirs.\n",
      "\"Aban ce the ar.\"\n",
      "TTa justhe of the wirge wrot in Hainder and : Dopsa\n",
      "\n",
      "Sample text at iteration 13000:\n",
      " \"You'd as tyeat polk the and jurcom.  You bnong plleen.\"\n",
      "Hewry. . . . Dursed sfat - he nvartuste slowng itly frene duss cestsirs.\n",
      "\"Aban ce the ar.\"\n",
      "TTa justhe of the wirge wrot in Hainder and : Dopsa\n",
      "\n",
      "iter = 13100, smooth loss = 1.971201, time = 13.08s\n",
      "iter = 13200, smooth loss = 1.959279, time = 13.18s\n",
      "iter = 13300, smooth loss = 1.958522, time = 13.28s\n",
      "iter = 13400, smooth loss = 1.951334, time = 13.38s\n",
      "iter = 13500, smooth loss = 1.956109, time = 13.48s\n",
      "iter = 13600, smooth loss = 1.957540, time = 13.57s\n",
      "iter = 13700, smooth loss = 1.954354, time = 13.67s\n",
      "iter = 13800, smooth loss = 1.953071, time = 13.77s\n",
      "iter = 13900, smooth loss = 1.952454, time = 13.87s\n",
      "iter = 14000, smooth loss = 1.960816, time = 13.97s\n",
      "Sample text at iteration 14000:\n",
      "e, formizarseine seraben they qu ted wanded on we.. He peecom.,\"Weasepontt had, wat Herpionstasting uney, warred ermion of mmond He, wouled an the roobruts on wh, wat her was ,\" for froor ank viokioly\n",
      "\n",
      "Sample text at iteration 14000:\n",
      "e, formizarseine seraben they qu ted wanded on we.. He peecom.,\"Weasepontt had, wat Herpionstasting uney, warred ermion of mmond He, wouled an the roobruts on wh, wat her was ,\" for froor ank viokioly\n",
      "\n",
      "iter = 14100, smooth loss = 1.983583, time = 14.07s\n",
      "iter = 14200, smooth loss = 1.982491, time = 14.17s\n",
      "iter = 14300, smooth loss = 1.981563, time = 14.27s\n",
      "iter = 14400, smooth loss = 1.977850, time = 14.37s\n",
      "iter = 14500, smooth loss = 1.978459, time = 14.47s\n",
      "iter = 14600, smooth loss = 1.979157, time = 14.57s\n",
      "iter = 14700, smooth loss = 1.974837, time = 14.71s\n",
      "iter = 14800, smooth loss = 1.964840, time = 14.81s\n",
      "iter = 14900, smooth loss = 1.960387, time = 14.91s\n",
      "iter = 15000, smooth loss = 1.952543, time = 15.01s\n",
      "Sample text at iteration 15000:\n",
      ".  The switatureenof a to whearm,\"\n",
      "\"No had nos arounc me hirble blungea sturtlire situll hind rawe darks all to Wealfeysseres -re on acliogior, a dort we faclle batged of on it wen Ap ant was S aid fo\n",
      "\n",
      "Sample text at iteration 15000:\n",
      ".  The switatureenof a to whearm,\"\n",
      "\"No had nos arounc me hirble blungea sturtlire situll hind rawe darks all to Wealfeysseres -re on acliogior, a dort we faclle batged of on it wen Ap ant was S aid fo\n",
      "\n",
      "iter = 15100, smooth loss = 1.946874, time = 15.12s\n",
      "iter = 15200, smooth loss = 1.943476, time = 15.22s\n",
      "iter = 15300, smooth loss = 1.937859, time = 15.32s\n",
      "iter = 15400, smooth loss = 1.929952, time = 15.42s\n",
      "iter = 15500, smooth loss = 1.920478, time = 15.52s\n",
      "iter = 15600, smooth loss = 1.918038, time = 15.62s\n",
      "iter = 15700, smooth loss = 1.914891, time = 15.71s\n",
      "iter = 15800, smooth loss = 1.916148, time = 15.81s\n",
      "iter = 15900, smooth loss = 1.917762, time = 15.92s\n",
      "iter = 16000, smooth loss = 1.906884, time = 16.02s\n",
      "Sample text at iteration 16000:\n",
      "t handy.  Croning to theor - encringin, troule hartee arfired staht.\n",
      "\"Whyt has mofteen't Allow, pad in when rest on invery come in a's deezed cumboumous mulling. Harra dut, incammee, tud tonosh ffome \n",
      "\n",
      "Sample text at iteration 16000:\n",
      "t handy.  Croning to theor - encringin, troule hartee arfired staht.\n",
      "\"Whyt has mofteen't Allow, pad in when rest on invery come in a's deezed cumboumous mulling. Harra dut, incammee, tud tonosh ffome \n",
      "\n",
      "iter = 16100, smooth loss = 1.900123, time = 16.13s\n",
      "iter = 16200, smooth loss = 1.900460, time = 16.23s\n",
      "iter = 16300, smooth loss = 1.887245, time = 16.33s\n",
      "iter = 16400, smooth loss = 1.885287, time = 16.44s\n",
      "iter = 16500, smooth loss = 1.893234, time = 16.54s\n",
      "iter = 16600, smooth loss = 1.886748, time = 16.64s\n",
      "iter = 16700, smooth loss = 1.892276, time = 16.75s\n",
      "iter = 16800, smooth loss = 1.891328, time = 16.85s\n",
      "iter = 16900, smooth loss = 1.882984, time = 16.95s\n",
      "iter = 17000, smooth loss = 1.881255, time = 17.05s\n",
      "Sample text at iteration 17000:\n",
      "am, Caiventhed amennt hit neirwarowh his . vemy, wargared; theyf wisten.  Canidge. We ming ato gog, hange nexh as his the cempered wasted to his foowey!\"\n",
      "Fot you? waid ham, Harry, blete't you?  Cedein\n",
      "\n",
      "Sample text at iteration 17000:\n",
      "am, Caiventhed amennt hit neirwarowh his . vemy, wargared; theyf wisten.  Canidge. We ming ato gog, hange nexh as his the cempered wasted to his foowey!\"\n",
      "Fot you? waid ham, Harry, blete't you?  Cedein\n",
      "\n",
      "iter = 17100, smooth loss = 1.881303, time = 17.16s\n",
      "iter = 17200, smooth loss = 1.876312, time = 17.26s\n",
      "iter = 17300, smooth loss = 1.874972, time = 17.36s\n",
      "iter = 17400, smooth loss = 1.868884, time = 17.46s\n",
      "iter = 17500, smooth loss = 1.868311, time = 17.56s\n",
      "iter = 17600, smooth loss = 1.874953, time = 17.66s\n",
      "iter = 17700, smooth loss = 1.873900, time = 17.76s\n",
      "iter = 17800, smooth loss = 1.877967, time = 17.86s\n",
      "iter = 17900, smooth loss = 1.883404, time = 17.96s\n",
      "iter = 18000, smooth loss = 1.880955, time = 18.06s\n",
      "Sample text at iteration 18000:\n",
      "ng hes fartsila to tookeon Polle. ,\" had dack of Fickinst not earfing,\"\n",
      "\t\t\"I wiwnever sow not dof in gid which Statars towe got  Harry into erily.\n",
      "\t\t\"Er.  Therm molen was naruficll, the S--boffs will \n",
      "\n",
      "Sample text at iteration 18000:\n",
      "ng hes fartsila to tookeon Polle. ,\" had dack of Fickinst not earfing,\"\n",
      "\t\t\"I wiwnever sow not dof in gid which Statars towe got  Harry into erily.\n",
      "\t\t\"Er.  Therm molen was naruficll, the S--boffs will \n",
      "\n",
      "iter = 18100, smooth loss = 1.874412, time = 18.16s\n",
      "iter = 18200, smooth loss = 1.883374, time = 18.26s\n",
      "iter = 18300, smooth loss = 1.887760, time = 18.36s\n",
      "iter = 18400, smooth loss = 1.880132, time = 18.46s\n",
      "iter = 18500, smooth loss = 1.882616, time = 18.56s\n",
      "iter = 18600, smooth loss = 1.878919, time = 18.66s\n",
      "iter = 18700, smooth loss = 1.873812, time = 18.76s\n",
      "iter = 18800, smooth loss = 1.876773, time = 18.86s\n",
      "iter = 18900, smooth loss = 1.877016, time = 18.96s\n",
      "iter = 19000, smooth loss = 1.868909, time = 19.06s\n",
      "Sample text at iteration 19000:\n",
      " quisted conmedrig; leonne hren's toming Hably.H  her she bast't mur stads,\" sand Ron the Prmith myss nimy havers.  Hirly them coull.  Harry hose find the stappioned in e the swared montirge,\" sadd Ri\n",
      "\n",
      "Sample text at iteration 19000:\n",
      " quisted conmedrig; leonne hren's toming Hably.H  her she bast't mur stads,\" sand Ron the Prmith myss nimy havers.  Hirly them coull.  Harry hose find the stappioned in e the swared montirge,\" sadd Ri\n",
      "\n",
      "iter = 19100, smooth loss = 1.870458, time = 19.17s\n",
      "iter = 19200, smooth loss = 1.868165, time = 19.27s\n",
      "iter = 19300, smooth loss = 1.863325, time = 19.37s\n",
      "iter = 19400, smooth loss = 1.852478, time = 19.47s\n",
      "iter = 19500, smooth loss = 1.846928, time = 19.57s\n",
      "iter = 19600, smooth loss = 1.849173, time = 19.68s\n",
      "iter = 19700, smooth loss = 1.852401, time = 19.78s\n",
      "iter = 19800, smooth loss = 1.853734, time = 19.89s\n",
      "iter = 19900, smooth loss = 1.844670, time = 19.99s\n",
      "iter = 20000, smooth loss = 1.843793, time = 20.10s\n",
      "Sample text at iteration 20000:\n",
      "tenumbit?\" 'm betwry, Prople.  He him out he wander touland, ant know him as a reast.\n",
      "\t\"But net eyow Hagrid bloutly very hen't cous,\" he kated.\n",
      "Madbne Maxambly stely s watlizh, ee? He mun as it doteri\n",
      "\n",
      "Sample text at iteration 20000:\n",
      "tenumbit?\" 'm betwry, Prople.  He him out he wander touland, ant know him as a reast.\n",
      "\t\"But net eyow Hagrid bloutly very hen't cous,\" he kated.\n",
      "Madbne Maxambly stely s watlizh, ee? He mun as it doteri\n",
      "\n",
      "iter = 20100, smooth loss = 1.840951, time = 20.20s\n",
      "iter = 20200, smooth loss = 1.835647, time = 20.31s\n",
      "iter = 20300, smooth loss = 1.839877, time = 20.41s\n",
      "iter = 20400, smooth loss = 1.841073, time = 20.51s\n",
      "iter = 20500, smooth loss = 1.836051, time = 20.61s\n",
      "iter = 20600, smooth loss = 1.838217, time = 20.71s\n",
      "iter = 20700, smooth loss = 1.836363, time = 20.82s\n",
      "iter = 20800, smooth loss = 1.837602, time = 20.92s\n",
      "iter = 20900, smooth loss = 1.831676, time = 21.05s\n",
      "iter = 21000, smooth loss = 1.824190, time = 21.16s\n",
      "Sample text at iteration 21000:\n",
      "in a tomall wis is was verfey astory furtuer, Prover; you, suther porking but witr a Sleef, \"isting ig to oull the file stall he mwaver roins Fragoss of trag in a lostine intenint outer,\" said Rin thi\n",
      "\n",
      "Sample text at iteration 21000:\n",
      "in a tomall wis is was verfey astory furtuer, Prover; you, suther porking but witr a Sleef, \"isting ig to oull the file stall he mwaver roins Fragoss of trag in a lostine intenint outer,\" said Rin thi\n",
      "\n",
      "iter = 21100, smooth loss = 1.823942, time = 21.26s\n",
      "iter = 21200, smooth loss = 1.818136, time = 21.36s\n",
      "iter = 21300, smooth loss = 1.815241, time = 21.46s\n",
      "iter = 21400, smooth loss = 1.814930, time = 21.56s\n",
      "iter = 21500, smooth loss = 1.812758, time = 21.66s\n",
      "iter = 21600, smooth loss = 1.806739, time = 21.77s\n",
      "iter = 21700, smooth loss = 1.802401, time = 21.87s\n",
      "iter = 21800, smooth loss = 1.796213, time = 21.97s\n",
      "iter = 21900, smooth loss = 1.797845, time = 22.07s\n",
      "iter = 22000, smooth loss = 1.799484, time = 22.17s\n",
      "Sample text at iteration 22000:\n",
      "dges, ather?\" \"Wilnot hew he was paing- se's, onkn tagoin wenc -\"\n",
      "samong!\"  y oot out thought  Harry, phoming would as hee stoirse his had ho dister, might The?\" said.\n",
      "\"Leed not sow Hermioned coumbnin\n",
      "\n",
      "Sample text at iteration 22000:\n",
      "dges, ather?\" \"Wilnot hew he was paing- se's, onkn tagoin wenc -\"\n",
      "samong!\"  y oot out thought  Harry, phoming would as hee stoirse his had ho dister, might The?\" said.\n",
      "\"Leed not sow Hermioned coumbnin\n",
      "\n",
      "iter = 22100, smooth loss = 1.808302, time = 22.28s\n",
      "iter = 22200, smooth loss = 1.819197, time = 22.39s\n",
      "iter = 22300, smooth loss = 1.815316, time = 22.49s\n",
      "iter = 22400, smooth loss = 1.822296, time = 22.59s\n",
      "iter = 22500, smooth loss = 1.829041, time = 22.70s\n",
      "iter = 22600, smooth loss = 1.823580, time = 22.80s\n",
      "iter = 22700, smooth loss = 1.825270, time = 22.90s\n",
      "iter = 22800, smooth loss = 1.816097, time = 23.00s\n",
      "iter = 22900, smooth loss = 1.811345, time = 23.11s\n",
      "iter = 23000, smooth loss = 1.804417, time = 23.22s\n",
      "Sample text at iteration 23000:\n",
      "ew thes then't is me and Harry satelung deet. \"We slibbed We shole flatt of he squeages the way on if your griaks, a vould, sald in the Wiaked, \"Yru, He badden.\"\n",
      "Harey fralbe, urver frean me were rean\n",
      "\n",
      "Sample text at iteration 23000:\n",
      "ew thes then't is me and Harry satelung deet. \"We slibbed We shole flatt of he squeages the way on if your griaks, a vould, sald in the Wiaked, \"Yru, He badden.\"\n",
      "Harey fralbe, urver frean me were rean\n",
      "\n",
      "iter = 23100, smooth loss = 1.795936, time = 23.32s\n",
      "iter = 23200, smooth loss = 1.806234, time = 23.42s\n",
      "iter = 23300, smooth loss = 1.806032, time = 23.56s\n",
      "iter = 23400, smooth loss = 1.807601, time = 23.66s\n",
      "iter = 23500, smooth loss = 1.812559, time = 23.76s\n",
      "iter = 23600, smooth loss = 1.819682, time = 23.86s\n",
      "iter = 23700, smooth loss = 1.818901, time = 23.97s\n",
      "iter = 23800, smooth loss = 1.823350, time = 24.07s\n",
      "iter = 23900, smooth loss = 1.824885, time = 24.17s\n",
      "iter = 24000, smooth loss = 1.814797, time = 24.27s\n",
      "Sample text at iteration 24000:\n",
      "ms Moofly ow wast any hom; net rigw tere bold in theaking larss chatlor Ghate mangol al expupungmore been owsstring wiz- yir post have Sorstoous?\" said Hermiona she rewtomantid.  It picting bearing as\n",
      "\n",
      "Sample text at iteration 24000:\n",
      "ms Moofly ow wast any hom; net rigw tere bold in theaking larss chatlor Ghate mangol al expupungmore been owsstring wiz- yir post have Sorstoous?\" said Hermiona she rewtomantid.  It picting bearing as\n",
      "\n",
      "iter = 24100, smooth loss = 1.800815, time = 24.38s\n",
      "iter = 24200, smooth loss = 1.802674, time = 24.48s\n",
      "iter = 24300, smooth loss = 1.817178, time = 24.58s\n",
      "iter = 24400, smooth loss = 1.824274, time = 24.68s\n",
      "iter = 24500, smooth loss = 1.823254, time = 24.79s\n",
      "iter = 24600, smooth loss = 1.825849, time = 24.89s\n",
      "iter = 24700, smooth loss = 1.834049, time = 24.99s\n",
      "iter = 24800, smooth loss = 1.831386, time = 25.10s\n",
      "iter = 24900, smooth loss = 1.827732, time = 25.20s\n",
      "iter = 25000, smooth loss = 1.822187, time = 25.30s\n",
      "Sample text at iteration 25000:\n",
      "o efffisult out and cont, bethere an enmilicare.  H\" he seeorapsoot Harnd, looking of the endrys fouct'te onch fow both asricaur - Hermyone insuDragleared to her twarisartien ut a peopes of davirger a\n",
      "\n",
      "Sample text at iteration 25000:\n",
      "o efffisult out and cont, bethere an enmilicare.  H\" he seeorapsoot Harnd, looking of the endrys fouct'te onch fow both asricaur - Hermyone insuDragleared to her twarisartien ut a peopes of davirger a\n",
      "\n",
      "iter = 25100, smooth loss = 1.828218, time = 25.41s\n",
      "iter = 25200, smooth loss = 1.840240, time = 25.51s\n",
      "iter = 25300, smooth loss = 1.835640, time = 25.61s\n",
      "iter = 25400, smooth loss = 1.825794, time = 25.71s\n",
      "iter = 25500, smooth loss = 1.815888, time = 25.81s\n",
      "iter = 25600, smooth loss = 1.816093, time = 25.91s\n",
      "iter = 25700, smooth loss = 1.822965, time = 26.01s\n",
      "iter = 25800, smooth loss = 1.826501, time = 26.12s\n",
      "iter = 25900, smooth loss = 1.819387, time = 26.22s\n",
      "iter = 26000, smooth loss = 1.810157, time = 26.32s\n",
      "Sample text at iteration 26000:\n",
      "wl nat a baly mowive jasmens get the swather.  \"Thate just thats in't with to every, suddengething ala emart.  \"Tchum. Harry.\"\n",
      "It's to with kidn't was pight was her mitodne foudver - \"\n",
      "Ron said Harry \n",
      "\n",
      "Sample text at iteration 26000:\n",
      "wl nat a baly mowive jasmens get the swather.  \"Thate just thats in't with to every, suddengething ala emart.  \"Tchum. Harry.\"\n",
      "It's to with kidn't was pight was her mitodne foudver - \"\n",
      "Ron said Harry \n",
      "\n",
      "iter = 26100, smooth loss = 1.811620, time = 26.43s\n",
      "iter = 26200, smooth loss = 1.806429, time = 26.53s\n",
      "iter = 26300, smooth loss = 1.805171, time = 26.63s\n",
      "iter = 26400, smooth loss = 1.828300, time = 26.73s\n",
      "iter = 26500, smooth loss = 1.841665, time = 26.84s\n",
      "iter = 26600, smooth loss = 1.827457, time = 26.94s\n",
      "iter = 26700, smooth loss = 1.819854, time = 27.04s\n",
      "iter = 26800, smooth loss = 1.807904, time = 27.18s\n",
      "iter = 26900, smooth loss = 1.808900, time = 27.28s\n",
      "iter = 27000, smooth loss = 1.800548, time = 27.38s\n",
      "Sample text at iteration 27000:\n",
      " row jidn?\" see gikn'ver he bud very.  Bet bvat au whys geals.\"\n",
      "\"Er he. I sard the cuspaninin, lartania Aucheddry, longing trolkned Prefly now happly sirets on ween of the pritorory Borains. \"Laded th\n",
      "\n",
      "Sample text at iteration 27000:\n",
      " row jidn?\" see gikn'ver he bud very.  Bet bvat au whys geals.\"\n",
      "\"Er he. I sard the cuspaninin, lartania Aucheddry, longing trolkned Prefly now happly sirets on ween of the pritorory Borains. \"Laded th\n",
      "\n",
      "iter = 27100, smooth loss = 1.800934, time = 27.49s\n",
      "iter = 27200, smooth loss = 1.799506, time = 27.59s\n",
      "iter = 27300, smooth loss = 1.786043, time = 27.70s\n",
      "iter = 27400, smooth loss = 1.789009, time = 27.80s\n",
      "iter = 27500, smooth loss = 1.800846, time = 27.90s\n",
      "iter = 27600, smooth loss = 1.810111, time = 28.01s\n",
      "iter = 27700, smooth loss = 1.813621, time = 28.11s\n",
      "iter = 27800, smooth loss = 1.815813, time = 28.21s\n",
      "iter = 27900, smooth loss = 1.815653, time = 28.31s\n",
      "iter = 28000, smooth loss = 1.814184, time = 28.41s\n",
      "Sample text at iteration 28000:\n",
      "k.\n",
      "\"Haurd icnee thas beg haplly.\n",
      "\"Mreving mise Caris! Anomed doikl.\" Myrile hippneves me had out ofl, her ppfibed forumpled...... She seeg ig in exintandly the looking, bochert-Haid Ron bear, )o wiscy\n",
      "\n",
      "Sample text at iteration 28000:\n",
      "k.\n",
      "\"Haurd icnee thas beg haplly.\n",
      "\"Mreving mise Caris! Anomed doikl.\" Myrile hippneves me had out ofl, her ppfibed forumpled...... She seeg ig in exintandly the looking, bochert-Haid Ron bear, )o wiscy\n",
      "\n",
      "iter = 28100, smooth loss = 1.809784, time = 28.51s\n",
      "iter = 28200, smooth loss = 1.813485, time = 28.61s\n",
      "iter = 28300, smooth loss = 1.813716, time = 28.72s\n",
      "iter = 28400, smooth loss = 1.813236, time = 28.82s\n",
      "iter = 28500, smooth loss = 1.810017, time = 28.92s\n",
      "iter = 28600, smooth loss = 1.797840, time = 29.03s\n",
      "iter = 28700, smooth loss = 1.784847, time = 29.13s\n",
      "iter = 28800, smooth loss = 1.772332, time = 29.24s\n",
      "iter = 28900, smooth loss = 1.776404, time = 29.34s\n",
      "iter = 29000, smooth loss = 1.769323, time = 29.44s\n",
      "Sample text at iteration 29000:\n",
      "hapsion the Graby chaling, swareching her fulmane, as perseaves of Moody whet and Harry, anding  \"I whing, Sinclening that cisntrinveDye the room.  Cryich ortione bush oufn,\" slight, snid out winda, d\n",
      "\n",
      "Sample text at iteration 29000:\n",
      "hapsion the Graby chaling, swareching her fulmane, as perseaves of Moody whet and Harry, anding  \"I whing, Sinclening that cisntrinveDye the room.  Cryich ortione bush oufn,\" slight, snid out winda, d\n",
      "\n",
      "iter = 29100, smooth loss = 1.778573, time = 29.55s\n",
      "iter = 29200, smooth loss = 1.785619, time = 29.69s\n",
      "iter = 29300, smooth loss = 1.786379, time = 29.79s\n",
      "iter = 29400, smooth loss = 1.795538, time = 29.90s\n",
      "iter = 29500, smooth loss = 1.796270, time = 30.00s\n",
      "iter = 29600, smooth loss = 1.791029, time = 30.10s\n",
      "iter = 29700, smooth loss = 1.784684, time = 30.21s\n",
      "iter = 29800, smooth loss = 1.782722, time = 30.31s\n",
      "iter = 29900, smooth loss = 1.782068, time = 30.41s\n",
      "iter = 30000, smooth loss = 1.782222, time = 30.51s\n",
      "Sample text at iteration 30000:\n",
      "seesrale at whangors hare a she couplestelly of tan at at with greemed at has alore flletedor Cone take, 'r it the mas lash s over stull ou nere awd baris had flleomey, they y froby, swirscoader somon\n",
      "\n",
      "Sample text at iteration 30000:\n",
      "seesrale at whangors hare a she couplestelly of tan at at with greemed at has alore flletedor Cone take, 'r it the mas lash s over stull ou nere awd baris had flleomey, they y froby, swirscoader somon\n",
      "\n",
      "iter = 30100, smooth loss = 1.777585, time = 30.62s\n",
      "iter = 30200, smooth loss = 1.770897, time = 30.72s\n",
      "iter = 30300, smooth loss = 1.759786, time = 30.82s\n",
      "iter = 30400, smooth loss = 1.751837, time = 30.93s\n",
      "iter = 30500, smooth loss = 1.747952, time = 31.02s\n",
      "iter = 30600, smooth loss = 1.756779, time = 31.12s\n",
      "iter = 30700, smooth loss = 1.756239, time = 31.23s\n",
      "iter = 30800, smooth loss = 1.762771, time = 31.33s\n",
      "iter = 30900, smooth loss = 1.782123, time = 31.43s\n",
      "iter = 31000, smooth loss = 1.777803, time = 31.53s\n",
      "Sample text at iteration 31000:\n",
      "ltcy's grealed of SRizal Grobet losk iver whet grisash.\"\n",
      "\"Ho masing, stranls oftern't sid uf threadter, Rclimining udderms was shoung and them brent dive pote busond, Madam Poted you trouble Harry see\n",
      "\n",
      "Sample text at iteration 31000:\n",
      "ltcy's grealed of SRizal Grobet losk iver whet grisash.\"\n",
      "\"Ho masing, stranls oftern't sid uf threadter, Rclimining udderms was shoung and them brent dive pote busond, Madam Poted you trouble Harry see\n",
      "\n",
      "iter = 31100, smooth loss = 1.778591, time = 31.63s\n",
      "iter = 31200, smooth loss = 1.775027, time = 31.74s\n",
      "iter = 31300, smooth loss = 1.766389, time = 31.84s\n",
      "iter = 31400, smooth loss = 1.762155, time = 31.95s\n",
      "iter = 31500, smooth loss = 1.769916, time = 32.05s\n",
      "iter = 31600, smooth loss = 1.764521, time = 32.15s\n",
      "iter = 31700, smooth loss = 1.754988, time = 32.25s\n",
      "iter = 31800, smooth loss = 1.753315, time = 32.35s\n",
      "iter = 31900, smooth loss = 1.753355, time = 32.45s\n",
      "iter = 32000, smooth loss = 1.754416, time = 32.55s\n",
      "Sample text at iteration 32000:\n",
      "ict.  Porce much.\n",
      "\"Yout themebyt there, and him, I mecand thrence.\n",
      "\"The oud nyould Me.  It's looked a tanking watthes. Ron troagh that a cearing afore off if shathtre.\n",
      "\"It if hed bentred and to him Ch\n",
      "\n",
      "Sample text at iteration 32000:\n",
      "ict.  Porce much.\n",
      "\"Yout themebyt there, and him, I mecand thrence.\n",
      "\"The oud nyould Me.  It's looked a tanking watthes. Ron troagh that a cearing afore off if shathtre.\n",
      "\"It if hed bentred and to him Ch\n",
      "\n",
      "iter = 32100, smooth loss = 1.748430, time = 32.66s\n",
      "iter = 32200, smooth loss = 1.742524, time = 32.76s\n",
      "iter = 32300, smooth loss = 1.741831, time = 32.86s\n",
      "iter = 32400, smooth loss = 1.739851, time = 32.96s\n",
      "iter = 32500, smooth loss = 1.737679, time = 33.06s\n",
      "iter = 32600, smooth loss = 1.734732, time = 33.16s\n",
      "iter = 32700, smooth loss = 1.742621, time = 33.26s\n",
      "iter = 32800, smooth loss = 1.752418, time = 33.36s\n",
      "iter = 32900, smooth loss = 1.752944, time = 33.46s\n",
      "iter = 33000, smooth loss = 1.753290, time = 33.55s\n",
      "Sample text at iteration 33000:\n",
      "ster about Harry - Groff Babfien's she clah.  Whe hime it you divied with tohe chacl though the was dilsopen, and work him.  Chore oulten sot off her poiver?\"\n",
      "Ron suget to ket. Hermione you antild.\"\n",
      "H\n",
      "\n",
      "Sample text at iteration 33000:\n",
      "ster about Harry - Groff Babfien's she clah.  Whe hime it you divied with tohe chacl though the was dilsopen, and work him.  Chore oulten sot off her poiver?\"\n",
      "Ron suget to ket. Hermione you antild.\"\n",
      "H\n",
      "\n",
      "iter = 33100, smooth loss = 1.755892, time = 33.66s\n",
      "iter = 33200, smooth loss = 1.758891, time = 33.76s\n",
      "iter = 33300, smooth loss = 1.754959, time = 33.86s\n",
      "iter = 33400, smooth loss = 1.752239, time = 33.96s\n",
      "iter = 33500, smooth loss = 1.743081, time = 34.06s\n",
      "iter = 33600, smooth loss = 1.731610, time = 34.16s\n",
      "iter = 33700, smooth loss = 1.720743, time = 34.26s\n",
      "iter = 33800, smooth loss = 1.707484, time = 34.36s\n",
      "iter = 33900, smooth loss = 1.699731, time = 34.46s\n",
      "iter = 34000, smooth loss = 1.702362, time = 34.55s\n",
      "Sample text at iteration 34000:\n",
      "kerf, itth tho tee be unetle abrear.\n",
      "\n",
      "Bucker, dang an himpen in what cheise - lotiond, HAgmill to you it sleer up!  In'ze awoued the trreated not capperice hiplinn.  \"Mr. Crouch it dight, each all the\n",
      "\n",
      "Sample text at iteration 34000:\n",
      "kerf, itth tho tee be unetle abrear.\n",
      "\n",
      "Bucker, dang an himpen in what cheise - lotiond, HAgmill to you it sleer up!  In'ze awoued the trreated not capperice hiplinn.  \"Mr. Crouch it dight, each all the\n",
      "\n",
      "iter = 34100, smooth loss = 1.691821, time = 34.66s\n",
      "iter = 34200, smooth loss = 1.689444, time = 34.76s\n",
      "iter = 34300, smooth loss = 1.678368, time = 34.85s\n",
      "iter = 34400, smooth loss = 1.677512, time = 34.95s\n",
      "iter = 34500, smooth loss = 1.678693, time = 35.05s\n",
      "iter = 34600, smooth loss = 1.676146, time = 35.15s\n",
      "iter = 34700, smooth loss = 1.685835, time = 35.25s\n",
      "iter = 34800, smooth loss = 1.698625, time = 35.35s\n",
      "iter = 34900, smooth loss = 1.694026, time = 35.45s\n",
      "iter = 35000, smooth loss = 1.713800, time = 35.55s\n",
      "Sample text at iteration 35000:\n",
      "Mooner. Carr saw, Con tray unce! . ...\n",
      "\"Courm?\"  see as ham a omver, his cond ad all the known. sever ay they green Crouch hessill, thereed; his full besore extaced Paggenos.\n",
      "\"No,\" said Ron, \"Illy's. \n",
      "\n",
      "Sample text at iteration 35000:\n",
      "Mooner. Carr saw, Con tray unce! . ...\n",
      "\"Courm?\"  see as ham a omver, his cond ad all the known. sever ay they green Crouch hessill, thereed; his full besore extaced Paggenos.\n",
      "\"No,\" said Ron, \"Illy's. \n",
      "\n",
      "iter = 35100, smooth loss = 1.712846, time = 35.65s\n",
      "iter = 35200, smooth loss = 1.711831, time = 35.75s\n",
      "iter = 35300, smooth loss = 1.700332, time = 35.85s\n",
      "iter = 35400, smooth loss = 1.688410, time = 35.95s\n",
      "iter = 35500, smooth loss = 1.690558, time = 36.05s\n",
      "iter = 35600, smooth loss = 1.697100, time = 36.14s\n",
      "iter = 35700, smooth loss = 1.698837, time = 36.24s\n",
      "iter = 35800, smooth loss = 1.701823, time = 36.34s\n",
      "iter = 35900, smooth loss = 1.697608, time = 36.44s\n",
      "iter = 36000, smooth loss = 1.704328, time = 36.54s\n",
      "Sample text at iteration 36000:\n",
      "airs?  Was trough mun the dort on the bryin strered.  Sime she looking trubBrabed let over,\" saud, hind the chair.  Fragred haidd the bryich onh a abor!\"\n",
      "\"Sery it, Harry masties, the rungest sot!  I d\n",
      "\n",
      "Sample text at iteration 36000:\n",
      "airs?  Was trough mun the dort on the bryin strered.  Sime she looking trubBrabed let over,\" saud, hind the chair.  Fragred haidd the bryich onh a abor!\"\n",
      "\"Sery it, Harry masties, the rungest sot!  I d\n",
      "\n",
      "iter = 36100, smooth loss = 1.693584, time = 36.64s\n",
      "iter = 36200, smooth loss = 1.696392, time = 36.74s\n",
      "iter = 36300, smooth loss = 1.689462, time = 36.84s\n",
      "iter = 36400, smooth loss = 1.683882, time = 36.94s\n",
      "iter = 36500, smooth loss = 1.671899, time = 37.04s\n",
      "iter = 36600, smooth loss = 1.670536, time = 37.16s\n",
      "iter = 36700, smooth loss = 1.674470, time = 37.26s\n",
      "iter = 36800, smooth loss = 1.682063, time = 37.36s\n",
      "iter = 36900, smooth loss = 1.697144, time = 37.46s\n",
      "iter = 37000, smooth loss = 1.711540, time = 37.56s\n",
      "Sample text at iteration 37000:\n",
      "rabing and expees.  Aad stoper. Harry's of the a way. \"Nethow agains of the shes were were uparsst :ur Seckont poush relateagslaming aw shar,\" said Fidly fisturay.  \"I his sairs weyhed ponsite with th\n",
      "\n",
      "Sample text at iteration 37000:\n",
      "rabing and expees.  Aad stoper. Harry's of the a way. \"Nethow agains of the shes were were uparsst :ur Seckont poush relateagslaming aw shar,\" said Fidly fisturay.  \"I his sairs weyhed ponsite with th\n",
      "\n",
      "iter = 37100, smooth loss = 1.713728, time = 37.68s\n",
      "iter = 37200, smooth loss = 1.714373, time = 37.78s\n",
      "iter = 37300, smooth loss = 1.709586, time = 37.88s\n",
      "iter = 37400, smooth loss = 1.702887, time = 37.98s\n",
      "iter = 37500, smooth loss = 1.705754, time = 38.08s\n",
      "iter = 37600, smooth loss = 1.701917, time = 38.17s\n",
      "iter = 37700, smooth loss = 1.705016, time = 38.27s\n",
      "iter = 37800, smooth loss = 1.708403, time = 38.37s\n",
      "iter = 37900, smooth loss = 1.702056, time = 38.48s\n",
      "iter = 38000, smooth loss = 1.716366, time = 38.59s\n",
      "Sample text at iteration 38000:\n",
      "itther scent at or, abaubis nound get to nounht'rn that, in her tom.  It.  ha, Freated and celreng tow, and his wordent shoun no wagring you?\"\n",
      "The sire,\" say guace.\n",
      " Cup his kneware to . ... Harrye th\n",
      "\n",
      "Sample text at iteration 38000:\n",
      "itther scent at or, abaubis nound get to nounht'rn that, in her tom.  It.  ha, Freated and celreng tow, and his wordent shoun no wagring you?\"\n",
      "The sire,\" say guace.\n",
      " Cup his kneware to . ... Harrye th\n",
      "\n",
      "iter = 38100, smooth loss = 1.718871, time = 38.70s\n",
      "iter = 38200, smooth loss = 1.715208, time = 38.80s\n",
      "iter = 38300, smooth loss = 1.701794, time = 38.94s\n",
      "iter = 38400, smooth loss = 1.698541, time = 39.07s\n",
      "iter = 38500, smooth loss = 1.695962, time = 39.20s\n",
      "iter = 38600, smooth loss = 1.687823, time = 39.31s\n",
      "iter = 38700, smooth loss = 1.685423, time = 39.41s\n",
      "iter = 38800, smooth loss = 1.685786, time = 39.54s\n",
      "iter = 38900, smooth loss = 1.691044, time = 39.64s\n",
      "iter = 39000, smooth loss = 1.697613, time = 39.74s\n",
      "Sample text at iteration 39000:\n",
      "ound nold, his be of hior a looked ar thou her fins, wished, and hurseds ar seed itring use . . a did theye stueted shem ever though it wast sawe apon of his thais.  \"Pothing arout Vikned her ay raice\n",
      "\n",
      "Sample text at iteration 39000:\n",
      "ound nold, his be of hior a looked ar thou her fins, wished, and hurseds ar seed itring use . . a did theye stueted shem ever though it wast sawe apon of his thais.  \"Pothing arout Vikned her ay raice\n",
      "\n",
      "iter = 39100, smooth loss = 1.702083, time = 39.85s\n",
      "iter = 39200, smooth loss = 1.708734, time = 39.95s\n",
      "iter = 39300, smooth loss = 1.709481, time = 40.05s\n",
      "iter = 39400, smooth loss = 1.713219, time = 40.15s\n",
      "iter = 39500, smooth loss = 1.713457, time = 40.24s\n",
      "iter = 39600, smooth loss = 1.720160, time = 40.34s\n",
      "iter = 39700, smooth loss = 1.711809, time = 40.44s\n",
      "iter = 39800, smooth loss = 1.701672, time = 40.54s\n",
      "iter = 39900, smooth loss = 1.693294, time = 40.64s\n",
      "iter = 40000, smooth loss = 1.684742, time = 40.74s\n",
      "Sample text at iteration 40000:\n",
      "he Dumbledors was now didest, shap crainelfe ... learselus.  He mand that ce of hime.\n",
      "And segeen. . . . ave . . . iclusses were whrew llfed fightaily as fignory, what-come to that your Cedric throuse \n",
      "\n",
      "Sample text at iteration 40000:\n",
      "he Dumbledors was now didest, shap crainelfe ... learselus.  He mand that ce of hime.\n",
      "And segeen. . . . ave . . . iclusses were whrew llfed fightaily as fignory, what-come to that your Cedric throuse \n",
      "\n",
      "iter = 40100, smooth loss = 1.674442, time = 40.84s\n",
      "iter = 40200, smooth loss = 1.661259, time = 40.94s\n",
      "iter = 40300, smooth loss = 1.650961, time = 41.04s\n",
      "iter = 40400, smooth loss = 1.651762, time = 41.14s\n",
      "iter = 40500, smooth loss = 1.645957, time = 41.24s\n",
      "iter = 40600, smooth loss = 1.643792, time = 41.34s\n",
      "iter = 40700, smooth loss = 1.637037, time = 41.44s\n",
      "iter = 40800, smooth loss = 1.643887, time = 41.54s\n",
      "iter = 40900, smooth loss = 1.646148, time = 41.64s\n",
      "iter = 41000, smooth loss = 1.641311, time = 41.74s\n",
      "Sample text at iteration 41000:\n",
      "s he that who stood Back to anchitcy, with Nogent courdw-- nos., \"Ky,\" sI Fugged.  I whim. ANd Stimes of Peaple.  He was flon Would my rack tur nunding than aspontstrabtild the the light, ans.  Dudbla\n",
      "\n",
      "Sample text at iteration 41000:\n",
      "s he that who stood Back to anchitcy, with Nogent courdw-- nos., \"Ky,\" sI Fugged.  I whim. ANd Stimes of Peaple.  He was flon Would my rack tur nunding than aspontstrabtild the the light, ans.  Dudbla\n",
      "\n",
      "iter = 41100, smooth loss = 1.650606, time = 41.84s\n",
      "iter = 41200, smooth loss = 1.650126, time = 41.94s\n",
      "iter = 41300, smooth loss = 1.657124, time = 42.03s\n",
      "iter = 41400, smooth loss = 1.658199, time = 42.13s\n",
      "iter = 41500, smooth loss = 1.653342, time = 42.23s\n",
      "iter = 41600, smooth loss = 1.654082, time = 42.33s\n",
      "iter = 41700, smooth loss = 1.638833, time = 42.43s\n",
      "iter = 41800, smooth loss = 1.641519, time = 42.53s\n",
      "iter = 41900, smooth loss = 1.640385, time = 42.63s\n",
      "iter = 42000, smooth loss = 1.634131, time = 42.73s\n",
      "Sample text at iteration 42000:\n",
      "eters, he soedrien strawger you neall my.  Itaring.  Aghing where me.\n",
      "\"Deml hinnever to he had all petor, stull melleding at He failed hrouch his downed hith the stagls he keeved the dear in scusting \n",
      "\n",
      "Sample text at iteration 42000:\n",
      "eters, he soedrien strawger you neall my.  Itaring.  Aghing where me.\n",
      "\"Deml hinnever to he had all petor, stull melleding at He failed hrouch his downed hith the stagls he keeved the dear in scusting \n",
      "\n",
      "iter = 42100, smooth loss = 1.630312, time = 42.83s\n",
      "iter = 42200, smooth loss = 1.625178, time = 42.93s\n",
      "iter = 42300, smooth loss = 1.628556, time = 43.03s\n",
      "iter = 42400, smooth loss = 1.629189, time = 43.13s\n",
      "iter = 42500, smooth loss = 1.634697, time = 43.23s\n",
      "iter = 42600, smooth loss = 1.633990, time = 43.33s\n",
      "iter = 42700, smooth loss = 1.646128, time = 43.43s\n",
      "iter = 42800, smooth loss = 1.649458, time = 43.53s\n",
      "iter = 42900, smooth loss = 1.648177, time = 43.63s\n",
      "iter = 43000, smooth loss = 1.645462, time = 43.73s\n",
      "Sample text at iteration 43000:\n",
      "racked at him.\n",
      "\"He toor have returning Mon vion had lew about to to will trium, the toor tou ginded quick.  Lown tire and theak you goalcans.\n",
      "\"Made ell.\"\n",
      "\"Voldemorces in her.  That revents, \"And into \n",
      "\n",
      "Sample text at iteration 43000:\n",
      "racked at him.\n",
      "\"He toor have returning Mon vion had lew about to to will trium, the toor tou ginded quick.  Lown tire and theak you goalcans.\n",
      "\"Made ell.\"\n",
      "\"Voldemorces in her.  That revents, \"And into \n",
      "\n",
      "iter = 43100, smooth loss = 1.642918, time = 43.83s\n",
      "iter = 43200, smooth loss = 1.637794, time = 43.93s\n",
      "iter = 43300, smooth loss = 1.635057, time = 44.03s\n",
      "iter = 43400, smooth loss = 1.645869, time = 44.13s\n",
      "iter = 43500, smooth loss = 1.638613, time = 44.23s\n",
      "iter = 43600, smooth loss = 1.638481, time = 44.33s\n",
      "iter = 43700, smooth loss = 1.644671, time = 44.43s\n",
      "iter = 43800, smooth loss = 1.656310, time = 44.53s\n",
      "iter = 43900, smooth loss = 1.655935, time = 44.62s\n",
      "iter = 44000, smooth loss = 1.658573, time = 44.72s\n",
      "Sample text at iteration 44000:\n",
      "nd tal? slimely.  Ther wis, a was sumping and agaved fill ithering concle.\"\n",
      "\"He palled as showly gooked down beenhed uset ivl froslather scarssed been gos ophor said behould a kith leive beem, \"Your i\n",
      "\n",
      "Sample text at iteration 44000:\n",
      "nd tal? slimely.  Ther wis, a was sumping and agaved fill ithering concle.\"\n",
      "\"He palled as showly gooked down beenhed uset ivl froslather scarssed been gos ophor said behould a kith leive beem, \"Your i\n",
      "\n",
      "iter = 44100, smooth loss = 1.660068, time = 44.83s\n",
      "iter = 44200, smooth loss = 1.663717, time = 44.93s\n",
      "iter = 44300, smooth loss = 1.662099, time = 45.03s\n",
      "Completed epoch at iteration 44302\n",
      "iter = 44400, smooth loss = 1.689722, time = 45.13s\n",
      "iter = 44500, smooth loss = 1.699993, time = 45.23s\n",
      "iter = 44600, smooth loss = 1.703760, time = 45.32s\n",
      "iter = 44700, smooth loss = 1.699885, time = 45.42s\n",
      "iter = 44800, smooth loss = 1.707528, time = 45.52s\n",
      "iter = 44900, smooth loss = 1.713796, time = 45.62s\n",
      "iter = 45000, smooth loss = 1.713420, time = 45.72s\n",
      "Sample text at iteration 45000:\n",
      "collly as Mondy mouepsiond whrealles, you?\"\n",
      "\t\"A fits who tha wan wind.\n",
      "\t\"My Wight the peten us.  Ack sud foring of Lidnedbe said fell his was said.\"\n",
      "\tBromemont, any said moten hansed the cack, thing r\n",
      "\n",
      "Sample text at iteration 45000:\n",
      "collly as Mondy mouepsiond whrealles, you?\"\n",
      "\t\"A fits who tha wan wind.\n",
      "\t\"My Wight the peten us.  Ack sud foring of Lidnedbe said fell his was said.\"\n",
      "\tBromemont, any said moten hansed the cack, thing r\n",
      "\n",
      "iter = 45100, smooth loss = 1.711144, time = 45.86s\n",
      "iter = 45200, smooth loss = 1.702088, time = 45.96s\n",
      "iter = 45300, smooth loss = 1.699419, time = 46.06s\n",
      "iter = 45400, smooth loss = 1.696748, time = 46.16s\n",
      "iter = 45500, smooth loss = 1.694814, time = 46.26s\n",
      "iter = 45600, smooth loss = 1.690559, time = 46.36s\n",
      "iter = 45700, smooth loss = 1.695657, time = 46.46s\n",
      "iter = 45800, smooth loss = 1.691208, time = 46.56s\n",
      "iter = 45900, smooth loss = 1.710564, time = 46.65s\n",
      "iter = 46000, smooth loss = 1.726199, time = 46.75s\n",
      "Sample text at iteration 46000:\n",
      "ecoun every tallem, and Pecble uplet beenly from Pate owcthing that tay fioustearly, mure efull Puttits for a pitperting frober the silcthouts a sliut Potterter, and the tolet that cast to get in and \n",
      "\n",
      "Sample text at iteration 46000:\n",
      "ecoun every tallem, and Pecble uplet beenly from Pate owcthing that tay fioustearly, mure efull Puttits for a pitperting frober the silcthouts a sliut Potterter, and the tolet that cast to get in and \n",
      "\n",
      "iter = 46100, smooth loss = 1.727085, time = 46.86s\n",
      "iter = 46200, smooth loss = 1.726890, time = 46.96s\n",
      "iter = 46300, smooth loss = 1.720371, time = 47.06s\n",
      "iter = 46400, smooth loss = 1.711522, time = 47.16s\n",
      "iter = 46500, smooth loss = 1.708563, time = 47.26s\n",
      "iter = 46600, smooth loss = 1.719619, time = 47.36s\n",
      "iter = 46700, smooth loss = 1.718982, time = 47.46s\n",
      "iter = 46800, smooth loss = 1.714529, time = 47.56s\n",
      "iter = 46900, smooth loss = 1.718207, time = 47.66s\n",
      "iter = 47000, smooth loss = 1.711001, time = 47.76s\n",
      "Sample text at iteration 47000:\n",
      "iope, and harded,\" soirss.\n",
      "They thar the to caubed dowe.  If with think on in unilally to Sired itcantyered Harry, dentherenty had too mo. Harry, and thitew the his happratergo - you?\"\n",
      "\"Dode to the be\n",
      "\n",
      "Sample text at iteration 47000:\n",
      "iope, and harded,\" soirss.\n",
      "They thar the to caubed dowe.  If with think on in unilally to Sired itcantyered Harry, dentherenty had too mo. Harry, and thitew the his happratergo - you?\"\n",
      "\"Dode to the be\n",
      "\n",
      "iter = 47100, smooth loss = 1.700338, time = 47.86s\n",
      "iter = 47200, smooth loss = 1.686914, time = 47.96s\n",
      "iter = 47300, smooth loss = 1.680466, time = 48.06s\n",
      "iter = 47400, smooth loss = 1.686799, time = 48.16s\n",
      "iter = 47500, smooth loss = 1.680277, time = 48.26s\n",
      "iter = 47600, smooth loss = 1.685471, time = 48.36s\n",
      "iter = 47700, smooth loss = 1.690929, time = 48.45s\n",
      "iter = 47800, smooth loss = 1.689949, time = 48.55s\n",
      "iter = 47900, smooth loss = 1.690888, time = 48.65s\n",
      "iter = 48000, smooth loss = 1.698896, time = 48.75s\n",
      "Sample text at iteration 48000:\n",
      "ee, blackel of ound be over heared agsing ond a peatting movers-.  Lo he hvarbes, shouts it mancy, down to gear, morned row-slustly to neephingly grectile.\n",
      "\"Why with aexaboy, mastee just worned, and c\n",
      "\n",
      "Sample text at iteration 48000:\n",
      "ee, blackel of ound be over heared agsing ond a peatting movers-.  Lo he hvarbes, shouts it mancy, down to gear, morned row-slustly to neephingly grectile.\n",
      "\"Why with aexaboy, mastee just worned, and c\n",
      "\n",
      "iter = 48100, smooth loss = 1.708501, time = 48.85s\n",
      "iter = 48200, smooth loss = 1.708370, time = 48.95s\n",
      "iter = 48300, smooth loss = 1.705092, time = 49.05s\n",
      "iter = 48400, smooth loss = 1.704542, time = 49.15s\n",
      "iter = 48500, smooth loss = 1.706188, time = 49.25s\n",
      "iter = 48600, smooth loss = 1.706744, time = 49.35s\n",
      "iter = 48700, smooth loss = 1.706635, time = 49.45s\n",
      "iter = 48800, smooth loss = 1.713798, time = 49.55s\n",
      "iter = 48900, smooth loss = 1.709162, time = 49.65s\n",
      "iter = 49000, smooth loss = 1.711958, time = 49.75s\n",
      "Sample text at iteration 49000:\n",
      ".\n",
      "Thes'll bere this?\"\n",
      "\"Yeh had tartanize.\n",
      "\"That he Mr. Weasley shoush with fat just ushed Sorman with at the worried the maths downgaiun feould, ornes cyill gore an the camp a far, a deping handed, an\n",
      "\n",
      "Sample text at iteration 49000:\n",
      ".\n",
      "Thes'll bere this?\"\n",
      "\"Yeh had tartanize.\n",
      "\"That he Mr. Weasley shoush with fat just ushed Sorman with at the worried the maths downgaiun feould, ornes cyill gore an the camp a far, a deping handed, an\n",
      "\n",
      "iter = 49100, smooth loss = 1.712682, time = 49.86s\n",
      "iter = 49200, smooth loss = 1.720691, time = 49.96s\n",
      "iter = 49300, smooth loss = 1.719091, time = 50.06s\n",
      "iter = 49400, smooth loss = 1.720425, time = 50.16s\n",
      "iter = 49500, smooth loss = 1.728245, time = 50.26s\n",
      "iter = 49600, smooth loss = 1.735361, time = 50.36s\n",
      "iter = 49700, smooth loss = 1.738984, time = 50.46s\n",
      "iter = 49800, smooth loss = 1.738441, time = 50.56s\n",
      "iter = 49900, smooth loss = 1.742138, time = 50.66s\n",
      "iter = 50000, smooth loss = 1.740618, time = 50.75s\n",
      "Sample text at iteration 50000:\n",
      "seem his inder!\"\n",
      "\"Bulk not.\"\n",
      "Semung to clasmased thate in a wand what you couldn't had not turuled dow moling like and thonged fig all  \"Morded excited A dos'je seaps.  Tay they well for the sum t... \n",
      "\n",
      "Sample text at iteration 50000:\n",
      "seem his inder!\"\n",
      "\"Bulk not.\"\n",
      "Semung to clasmased thate in a wand what you couldn't had not turuled dow moling like and thonged fig all  \"Morded excited A dos'je seaps.  Tay they well for the sum t... \n",
      "\n",
      "iter = 50100, smooth loss = 1.749200, time = 50.86s\n",
      "iter = 50200, smooth loss = 1.745250, time = 50.96s\n",
      "iter = 50300, smooth loss = 1.743251, time = 51.06s\n",
      "iter = 50400, smooth loss = 1.741140, time = 51.19s\n",
      "iter = 50500, smooth loss = 1.746629, time = 51.29s\n",
      "iter = 50600, smooth loss = 1.749205, time = 51.39s\n",
      "iter = 50700, smooth loss = 1.772145, time = 51.49s\n",
      "iter = 50800, smooth loss = 1.779581, time = 51.59s\n",
      "iter = 50900, smooth loss = 1.778942, time = 51.69s\n",
      "iter = 51000, smooth loss = 1.773581, time = 51.78s\n",
      "Sample text at iteration 51000:\n",
      " the Orsever to Mr. Sive Sirill.  He see whering thut all agriachto then, laid, and back figglingling the Quigles basubriunly and Hut Hexcachly; it rightle the field shagied Harry's rubly vollarring V\n",
      "\n",
      "Sample text at iteration 51000:\n",
      " the Orsever to Mr. Sive Sirill.  He see whering thut all agriachto then, laid, and back figglingling the Quigles basubriunly and Hut Hexcachly; it rightle the field shagied Harry's rubly vollarring V\n",
      "\n",
      "iter = 51100, smooth loss = 1.769491, time = 51.89s\n",
      "iter = 51200, smooth loss = 1.768821, time = 51.98s\n",
      "iter = 51300, smooth loss = 1.759875, time = 52.08s\n",
      "iter = 51400, smooth loss = 1.755947, time = 52.18s\n",
      "iter = 51500, smooth loss = 1.746710, time = 52.28s\n",
      "iter = 51600, smooth loss = 1.729866, time = 52.38s\n",
      "iter = 51700, smooth loss = 1.721732, time = 52.48s\n",
      "iter = 51800, smooth loss = 1.716860, time = 52.58s\n",
      "iter = 51900, smooth loss = 1.717126, time = 52.68s\n",
      "iter = 52000, smooth loss = 1.704704, time = 52.77s\n",
      "Sample text at iteration 52000:\n",
      "in muncted witteved to is's redling go tod-wizer?\"  said Ron of eaked.\n",
      "\". Rwought from throom a pat off theress, Irew of you'd metsoen foow,\" she leetly of himgerod werus lit she tree Glyopat, back of\n",
      "\n",
      "Sample text at iteration 52000:\n",
      "in muncted witteved to is's redling go tod-wizer?\"  said Ron of eaked.\n",
      "\". Rwought from throom a pat off theress, Irew of you'd metsoen foow,\" she leetly of himgerod werus lit she tree Glyopat, back of\n",
      "\n",
      "iter = 52100, smooth loss = 1.700264, time = 52.88s\n",
      "iter = 52200, smooth loss = 1.686231, time = 52.98s\n",
      "iter = 52300, smooth loss = 1.680326, time = 53.07s\n",
      "iter = 52400, smooth loss = 1.677915, time = 53.17s\n",
      "iter = 52500, smooth loss = 1.669518, time = 53.27s\n",
      "iter = 52600, smooth loss = 1.664315, time = 53.37s\n",
      "iter = 52700, smooth loss = 1.657331, time = 53.47s\n",
      "iter = 52800, smooth loss = 1.645061, time = 53.57s\n",
      "iter = 52900, smooth loss = 1.642990, time = 53.66s\n",
      "iter = 53000, smooth loss = 1.644209, time = 53.76s\n",
      "Sample text at iteration 53000:\n",
      "e in trough it id with in fumting tear how it's keelited bacing up soy, now-Harry Perch's were?g us though el as ronger it down elf plothers of looking had exaw on seelengl\n",
      "\" was eifcunte VorLast's co\n",
      "\n",
      "Sample text at iteration 53000:\n",
      "e in trough it id with in fumting tear how it's keelited bacing up soy, now-Harry Perch's were?g us though el as ronger it down elf plothers of looking had exaw on seelengl\n",
      "\" was eifcunte VorLast's co\n",
      "\n",
      "iter = 53100, smooth loss = 1.657293, time = 53.87s\n",
      "iter = 53200, smooth loss = 1.663377, time = 53.96s\n",
      "iter = 53300, smooth loss = 1.662586, time = 54.06s\n",
      "iter = 53400, smooth loss = 1.671535, time = 54.16s\n",
      "iter = 53500, smooth loss = 1.682697, time = 54.26s\n",
      "iter = 53600, smooth loss = 1.681469, time = 54.36s\n",
      "iter = 53700, smooth loss = 1.685919, time = 54.45s\n",
      "iter = 53800, smooth loss = 1.685998, time = 54.55s\n",
      "iter = 53900, smooth loss = 1.681453, time = 54.65s\n",
      "iter = 54000, smooth loss = 1.676139, time = 54.75s\n",
      "Sample text at iteration 54000:\n",
      "ure when be kitchood he was nok your she didny.\n",
      "\"Yehard eather her the peth, Did Madk to hit anying sit me Deabley Charlie.\n",
      "\"If - \"breit, the intyils to anyouch an hely right of his Diaplings seadly P\n",
      "\n",
      "Sample text at iteration 54000:\n",
      "ure when be kitchood he was nok your she didny.\n",
      "\"Yehard eather her the peth, Did Madk to hit anying sit me Deabley Charlie.\n",
      "\"If - \"breit, the intyils to anyouch an hely right of his Diaplings seadly P\n",
      "\n",
      "iter = 54100, smooth loss = 1.686571, time = 54.86s\n",
      "iter = 54200, smooth loss = 1.674729, time = 54.96s\n",
      "iter = 54300, smooth loss = 1.681033, time = 55.05s\n",
      "iter = 54400, smooth loss = 1.693830, time = 55.15s\n",
      "iter = 54500, smooth loss = 1.695394, time = 55.25s\n",
      "iter = 54600, smooth loss = 1.701770, time = 55.35s\n",
      "iter = 54700, smooth loss = 1.709643, time = 55.45s\n",
      "iter = 54800, smooth loss = 1.708478, time = 55.55s\n",
      "iter = 54900, smooth loss = 1.726008, time = 55.65s\n",
      "iter = 55000, smooth loss = 1.740094, time = 55.74s\n",
      "Sample text at iteration 55000:\n",
      "ough the Hogseann.\n",
      "\"\n",
      "\t\t\tHEVRELWE CUIRjo\"\n",
      "\t\t\tH'Gry, Ron yif head as the was ets down te sple-tofe of beaps to the Sorpiones Inggarge, claves of whend stranging at Malfoy odder-Eye sid your beft tarming\n",
      "\n",
      "Sample text at iteration 55000:\n",
      "ough the Hogseann.\n",
      "\"\n",
      "\t\t\tHEVRELWE CUIRjo\"\n",
      "\t\t\tH'Gry, Ron yif head as the was ets down te sple-tofe of beaps to the Sorpiones Inggarge, claves of whend stranging at Malfoy odder-Eye sid your beft tarming\n",
      "\n",
      "iter = 55100, smooth loss = 1.748365, time = 55.85s\n",
      "iter = 55200, smooth loss = 1.749417, time = 55.95s\n",
      "iter = 55300, smooth loss = 1.753496, time = 56.05s\n",
      "iter = 55400, smooth loss = 1.739788, time = 56.16s\n",
      "iter = 55500, smooth loss = 1.740136, time = 56.27s\n",
      "iter = 55600, smooth loss = 1.736536, time = 56.42s\n",
      "iter = 55700, smooth loss = 1.726024, time = 56.53s\n",
      "iter = 55800, smooth loss = 1.731049, time = 56.63s\n",
      "iter = 55900, smooth loss = 1.731079, time = 56.73s\n",
      "iter = 56000, smooth loss = 1.740334, time = 56.83s\n",
      "Sample text at iteration 56000:\n",
      "ding the houldedol, who end still werkaraved bote of the owlt boning.  \"Youndied them of plonedtoth, epriund,\" surets thries face classotten his ructlin!  The Squtitass of a soccasted of the torruate \n",
      "\n",
      "Sample text at iteration 56000:\n",
      "ding the houldedol, who end still werkaraved bote of the owlt boning.  \"Youndied them of plonedtoth, epriund,\" surets thries face classotten his ructlin!  The Squtitass of a soccasted of the torruate \n",
      "\n",
      "iter = 56100, smooth loss = 1.751697, time = 56.94s\n",
      "iter = 56200, smooth loss = 1.746717, time = 57.04s\n",
      "iter = 56300, smooth loss = 1.743485, time = 57.14s\n",
      "iter = 56400, smooth loss = 1.741520, time = 57.25s\n",
      "iter = 56500, smooth loss = 1.746458, time = 57.35s\n",
      "iter = 56600, smooth loss = 1.736952, time = 57.45s\n",
      "iter = 56700, smooth loss = 1.721750, time = 57.56s\n",
      "iter = 56800, smooth loss = 1.721229, time = 57.66s\n",
      "iter = 56900, smooth loss = 1.721989, time = 57.77s\n",
      "iter = 57000, smooth loss = 1.717992, time = 57.87s\n",
      "Sample text at iteration 57000:\n",
      "t uncer - The at said (Moody's prose lalke, stidg want You cads fell was do. . . . Look all on se.\n",
      "Awh he simver it was step upay id quirk pell held lookit?\"  said Ron his paric, ond one as thenve loo\n",
      "\n",
      "Sample text at iteration 57000:\n",
      "t uncer - The at said (Moody's prose lalke, stidg want You cads fell was do. . . . Look all on se.\n",
      "Awh he simver it was step upay id quirk pell held lookit?\"  said Ron his paric, ond one as thenve loo\n",
      "\n",
      "iter = 57100, smooth loss = 1.711379, time = 57.97s\n",
      "iter = 57200, smooth loss = 1.703346, time = 58.07s\n",
      "iter = 57300, smooth loss = 1.707071, time = 58.17s\n",
      "iter = 57400, smooth loss = 1.694789, time = 58.27s\n",
      "iter = 57500, smooth loss = 1.685086, time = 58.37s\n",
      "iter = 57600, smooth loss = 1.686692, time = 58.47s\n",
      "iter = 57700, smooth loss = 1.681713, time = 58.57s\n",
      "iter = 57800, smooth loss = 1.691525, time = 58.67s\n",
      "iter = 57900, smooth loss = 1.689604, time = 58.77s\n",
      "iter = 58000, smooth loss = 1.690652, time = 58.86s\n",
      "Sample text at iteration 58000:\n",
      " clulsoble nong and I four brourdee she feels and she nilff spare as not had falorry repe selfing.\n",
      "\n",
      "The was filly hal by open for apprigauns eyily sowe his rownshe on fromiRn of their qoopss her was a\n",
      "\n",
      "Sample text at iteration 58000:\n",
      " clulsoble nong and I four brourdee she feels and she nilff spare as not had falorry repe selfing.\n",
      "\n",
      "The was filly hal by open for apprigauns eyily sowe his rownshe on fromiRn of their qoopss her was a\n",
      "\n",
      "iter = 58100, smooth loss = 1.692903, time = 58.97s\n",
      "iter = 58200, smooth loss = 1.691134, time = 59.07s\n",
      "iter = 58300, smooth loss = 1.703057, time = 59.17s\n",
      "iter = 58400, smooth loss = 1.724193, time = 59.27s\n",
      "iter = 58500, smooth loss = 1.723688, time = 59.37s\n",
      "iter = 58600, smooth loss = 1.726783, time = 59.47s\n",
      "iter = 58700, smooth loss = 1.722767, time = 59.57s\n",
      "iter = 58800, smooth loss = 1.722598, time = 59.67s\n",
      "iter = 58900, smooth loss = 1.722229, time = 59.77s\n",
      "iter = 59000, smooth loss = 1.716807, time = 59.86s\n",
      "Sample text at iteration 59000:\n",
      "ont,\" said Dumbledwent.  \"So mouse was painibal of Dumblethen there it as pus drouste. . . Ron sthangles look bleakey wigh hee cames - cubtionses beam Moody.  Beloush....\n",
      "\"Ce,\" Moodd Bags.\n",
      "\"They momio\n",
      "\n",
      "Sample text at iteration 59000:\n",
      "ont,\" said Dumbledwent.  \"So mouse was painibal of Dumblethen there it as pus drouste. . . Ron sthangles look bleakey wigh hee cames - cubtionses beam Moody.  Beloush....\n",
      "\"Ce,\" Moodd Bags.\n",
      "\"They momio\n",
      "\n",
      "iter = 59100, smooth loss = 1.712804, time = 59.97s\n",
      "iter = 59200, smooth loss = 1.702707, time = 60.07s\n",
      "iter = 59300, smooth loss = 1.693803, time = 60.17s\n",
      "iter = 59400, smooth loss = 1.687183, time = 60.26s\n",
      "iter = 59500, smooth loss = 1.682776, time = 60.36s\n",
      "iter = 59600, smooth loss = 1.678408, time = 60.46s\n",
      "iter = 59700, smooth loss = 1.670277, time = 60.56s\n",
      "iter = 59800, smooth loss = 1.659674, time = 60.66s\n",
      "iter = 59900, smooth loss = 1.658093, time = 60.76s\n",
      "iter = 60000, smooth loss = 1.657090, time = 60.87s\n",
      "Sample text at iteration 60000:\n",
      "rt branks, dranseds seft toh,\" said Heaschouthingly to the Great Sovereing, imparastay, thad Harry, \"Harry, Pect in mulsed to Highaft of toven hering them hadd fightory try Fred Heglintinal.\"\n",
      "Bus leas\n",
      "\n",
      "Sample text at iteration 60000:\n",
      "rt branks, dranseds seft toh,\" said Heaschouthingly to the Great Sovereing, imparastay, thad Harry, \"Harry, Pect in mulsed to Highaft of toven hering them hadd fightory try Fred Heglintinal.\"\n",
      "Bus leas\n",
      "\n",
      "iter = 60100, smooth loss = 1.661215, time = 60.98s\n",
      "iter = 60200, smooth loss = 1.668409, time = 61.08s\n",
      "iter = 60300, smooth loss = 1.658966, time = 61.18s\n",
      "iter = 60400, smooth loss = 1.649363, time = 61.28s\n",
      "iter = 60500, smooth loss = 1.647471, time = 61.38s\n",
      "iter = 60600, smooth loss = 1.632140, time = 61.48s\n",
      "iter = 60700, smooth loss = 1.630092, time = 61.58s\n",
      "iter = 60800, smooth loss = 1.638537, time = 61.68s\n",
      "iter = 60900, smooth loss = 1.631941, time = 61.78s\n",
      "iter = 61000, smooth loss = 1.638863, time = 61.87s\n",
      "Sample text at iteration 61000:\n",
      "ly of the dom. \"I'ls more, and botion every Professost morl!\" said wand be st'lloby we handed tho champion, by aclosse hand as Beoul follow chames said, claute and wele um a you'd a toow, mowned to th\n",
      "\n",
      "Sample text at iteration 61000:\n",
      "ly of the dom. \"I'ls more, and botion every Professost morl!\" said wand be st'lloby we handed tho champion, by aclosse hand as Beoul follow chames said, claute and wele um a you'd a toow, mowned to th\n",
      "\n",
      "iter = 61100, smooth loss = 1.640800, time = 61.98s\n",
      "iter = 61200, smooth loss = 1.634762, time = 62.14s\n",
      "iter = 61300, smooth loss = 1.631241, time = 62.24s\n",
      "iter = 61400, smooth loss = 1.632565, time = 62.33s\n",
      "iter = 61500, smooth loss = 1.631014, time = 62.43s\n",
      "iter = 61600, smooth loss = 1.629699, time = 62.53s\n",
      "iter = 61700, smooth loss = 1.624784, time = 62.63s\n",
      "iter = 61800, smooth loss = 1.624317, time = 62.73s\n",
      "iter = 61900, smooth loss = 1.634821, time = 62.83s\n",
      "iter = 62000, smooth loss = 1.637399, time = 62.92s\n",
      "Sample text at iteration 62000:\n",
      " the bllisen.\n",
      "\"Wo'm as\"'s toick the sidn't can' -\" \"\"Ex, that they serious, and by knew uppayed her bown'd the sken the chams of his gon to Harry say hang con'Ne gean all abou.\n",
      "\"Ard was - and Hogwart \n",
      "\n",
      "Sample text at iteration 62000:\n",
      " the bllisen.\n",
      "\"Wo'm as\"'s toick the sidn't can' -\" \"\"Ex, that they serious, and by knew uppayed her bown'd the sken the chams of his gon to Harry say hang con'Ne gean all abou.\n",
      "\"Ard was - and Hogwart \n",
      "\n",
      "iter = 62100, smooth loss = 1.641561, time = 63.02s\n",
      "iter = 62200, smooth loss = 1.648949, time = 63.12s\n",
      "iter = 62300, smooth loss = 1.650523, time = 63.22s\n",
      "iter = 62400, smooth loss = 1.646944, time = 63.32s\n",
      "iter = 62500, smooth loss = 1.657650, time = 63.41s\n",
      "iter = 62600, smooth loss = 1.662059, time = 63.51s\n",
      "iter = 62700, smooth loss = 1.654638, time = 63.61s\n",
      "iter = 62800, smooth loss = 1.658651, time = 63.71s\n",
      "iter = 62900, smooth loss = 1.660603, time = 63.80s\n",
      "iter = 63000, smooth loss = 1.658328, time = 63.90s\n",
      "Sample text at iteration 63000:\n",
      ".\n",
      "\"He slouterins tade ray Harry's vough fleber.  Good your I wand sither every sharts had say Vare shouping awrance, todor the pached Harry szided this se-the conlept into the frouther, happinger af i\n",
      "\n",
      "Sample text at iteration 63000:\n",
      ".\n",
      "\"He slouterins tade ray Harry's vough fleber.  Good your I wand sither every sharts had say Vare shouping awrance, todor the pached Harry szided this se-the conlept into the frouther, happinger af i\n",
      "\n",
      "iter = 63100, smooth loss = 1.662497, time = 64.00s\n",
      "iter = 63200, smooth loss = 1.662676, time = 64.10s\n",
      "iter = 63300, smooth loss = 1.657589, time = 64.20s\n",
      "iter = 63400, smooth loss = 1.658562, time = 64.29s\n",
      "iter = 63500, smooth loss = 1.654219, time = 64.39s\n",
      "iter = 63600, smooth loss = 1.649922, time = 64.49s\n",
      "iter = 63700, smooth loss = 1.642183, time = 64.58s\n",
      "iter = 63800, smooth loss = 1.637630, time = 64.68s\n",
      "iter = 63900, smooth loss = 1.645009, time = 64.78s\n",
      "iter = 64000, smooth loss = 1.650385, time = 64.87s\n",
      "Sample text at iteration 64000:\n",
      "e here to them ortwered ther,\" drecked stust Quauley lalin:\n",
      "\"I walked at the stoke that hrointed \"Whoutl you fand wizard?\n",
      "\"Lame everying its looked not that sliwh Sprits!\"\n",
      "\n",
      "Moddy stull moars at Hagrid\n",
      "\n",
      "Sample text at iteration 64000:\n",
      "e here to them ortwered ther,\" drecked stust Quauley lalin:\n",
      "\"I walked at the stoke that hrointed \"Whoutl you fand wizard?\n",
      "\"Lame everying its looked not that sliwh Sprits!\"\n",
      "\n",
      "Moddy stull moars at Hagrid\n",
      "\n",
      "iter = 64100, smooth loss = 1.654264, time = 64.98s\n",
      "iter = 64200, smooth loss = 1.645707, time = 65.08s\n",
      "iter = 64300, smooth loss = 1.640719, time = 65.17s\n",
      "iter = 64400, smooth loss = 1.632126, time = 65.27s\n",
      "iter = 64500, smooth loss = 1.626510, time = 65.37s\n",
      "iter = 64600, smooth loss = 1.632749, time = 65.46s\n",
      "iter = 64700, smooth loss = 1.636353, time = 65.56s\n",
      "iter = 64800, smooth loss = 1.630941, time = 65.66s\n",
      "iter = 64900, smooth loss = 1.632728, time = 65.76s\n",
      "iter = 65000, smooth loss = 1.635398, time = 65.86s\n",
      "Sample text at iteration 65000:\n",
      "grunnted he was cengry how dost at tisely, you lookin, I'm to be \"isn't got eye give.  They -\"\n",
      "\"\n",
      "\"The glizence, ilaint...\n",
      "\"It emeyt-way not cuse to a learos abery looks Maxime her.  In'le get some her\n",
      "\n",
      "Sample text at iteration 65000:\n",
      "grunnted he was cengry how dost at tisely, you lookin, I'm to be \"isn't got eye give.  They -\"\n",
      "\"\n",
      "\"The glizence, ilaint...\n",
      "\"It emeyt-way not cuse to a learos abery looks Maxime her.  In'le get some her\n",
      "\n",
      "iter = 65100, smooth loss = 1.636658, time = 65.97s\n",
      "iter = 65200, smooth loss = 1.632417, time = 66.07s\n",
      "iter = 65300, smooth loss = 1.624153, time = 66.17s\n",
      "iter = 65400, smooth loss = 1.626858, time = 66.26s\n",
      "iter = 65500, smooth loss = 1.625127, time = 66.36s\n",
      "iter = 65600, smooth loss = 1.626523, time = 66.46s\n",
      "iter = 65700, smooth loss = 1.624061, time = 66.56s\n",
      "iter = 65800, smooth loss = 1.624248, time = 66.66s\n",
      "iter = 65900, smooth loss = 1.619008, time = 66.76s\n",
      "iter = 66000, smooth loss = 1.615182, time = 66.86s\n",
      "Sample text at iteration 66000:\n",
      "bly a gry for A Sire go through to sut out taim, and take Arkin?\n",
      "\"Fran's went bering over immort offf you tro bag courst and Moward. . . but of flysquite of like wable O bully.   she know sholt a corn\n",
      "\n",
      "Sample text at iteration 66000:\n",
      "bly a gry for A Sire go through to sut out taim, and take Arkin?\n",
      "\"Fran's went bering over immort offf you tro bag courst and Moward. . . but of flysquite of like wable O bully.   she know sholt a corn\n",
      "\n",
      "iter = 66100, smooth loss = 1.609469, time = 66.96s\n",
      "iter = 66200, smooth loss = 1.612045, time = 67.06s\n",
      "iter = 66300, smooth loss = 1.613537, time = 67.16s\n",
      "iter = 66400, smooth loss = 1.625084, time = 67.26s\n",
      "iter = 66500, smooth loss = 1.637614, time = 67.36s\n",
      "iter = 66600, smooth loss = 1.638207, time = 67.47s\n",
      "iter = 66700, smooth loss = 1.646361, time = 67.57s\n",
      "iter = 66800, smooth loss = 1.656359, time = 67.67s\n",
      "iter = 66900, smooth loss = 1.650694, time = 67.76s\n",
      "iter = 67000, smooth loss = 1.654234, time = 67.86s\n",
      "Sample text at iteration 67000:\n",
      "ed enjething that whickled. The Dain fooss appop about of said getthesulf as and feelonves the closkering pin Jaid and sinks, stard of arout!\"  Hermione, Harry finioder, thought plessly still a tied g\n",
      "\n",
      "Sample text at iteration 67000:\n",
      "ed enjething that whickled. The Dain fooss appop about of said getthesulf as and feelonves the closkering pin Jaid and sinks, stard of arout!\"  Hermione, Harry finioder, thought plessly still a tied g\n",
      "\n",
      "iter = 67100, smooth loss = 1.645760, time = 67.97s\n",
      "iter = 67200, smooth loss = 1.639221, time = 68.07s\n",
      "iter = 67300, smooth loss = 1.632541, time = 68.17s\n",
      "iter = 67400, smooth loss = 1.622855, time = 68.27s\n",
      "iter = 67500, smooth loss = 1.632774, time = 68.36s\n",
      "iter = 67600, smooth loss = 1.632932, time = 68.46s\n",
      "iter = 67700, smooth loss = 1.636194, time = 68.56s\n",
      "iter = 67800, smooth loss = 1.638158, time = 68.66s\n",
      "iter = 67900, smooth loss = 1.648048, time = 68.76s\n",
      "iter = 68000, smooth loss = 1.649673, time = 68.86s\n",
      "Sample text at iteration 68000:\n",
      " twants of the donged would all wrich work howe noppered wintonathtame hove late's Prtty dan totetry bot so sting again?\"\n",
      "\"Neally balts should so.  \"Who had sece of ter eye, stell. There,\" said Mima o\n",
      "\n",
      "Sample text at iteration 68000:\n",
      " twants of the donged would all wrich work howe noppered wintonathtame hove late's Prtty dan totetry bot so sting again?\"\n",
      "\"Neally balts should so.  \"Who had sece of ter eye, stell. There,\" said Mima o\n",
      "\n",
      "iter = 68100, smooth loss = 1.654245, time = 68.97s\n",
      "iter = 68200, smooth loss = 1.657939, time = 69.07s\n",
      "iter = 68300, smooth loss = 1.650110, time = 69.17s\n",
      "iter = 68400, smooth loss = 1.635347, time = 69.27s\n",
      "iter = 68500, smooth loss = 1.635904, time = 69.37s\n",
      "iter = 68600, smooth loss = 1.643056, time = 69.47s\n",
      "iter = 68700, smooth loss = 1.653988, time = 69.57s\n",
      "iter = 68800, smooth loss = 1.654770, time = 69.67s\n",
      "iter = 68900, smooth loss = 1.659036, time = 69.77s\n",
      "iter = 69000, smooth loss = 1.668178, time = 69.87s\n",
      "Sample text at iteration 69000:\n",
      "oreer mistured litthed to.\"\n",
      "\"Pellly persetcauled in stulled in that fincled recombout intering s, the how, but that were out of Hermione, Harry, no bures Chanlibles croble, what yougeth him it!\"\n",
      "\"Dobb\n",
      "\n",
      "Sample text at iteration 69000:\n",
      "oreer mistured litthed to.\"\n",
      "\"Pellly persetcauled in stulled in that fincled recombout intering s, the how, but that were out of Hermione, Harry, no bures Chanlibles croble, what yougeth him it!\"\n",
      "\"Dobb\n",
      "\n",
      "iter = 69100, smooth loss = 1.667455, time = 69.98s\n",
      "iter = 69200, smooth loss = 1.662495, time = 70.07s\n",
      "iter = 69300, smooth loss = 1.657339, time = 70.17s\n",
      "iter = 69400, smooth loss = 1.661639, time = 70.31s\n",
      "iter = 69500, smooth loss = 1.678619, time = 70.40s\n",
      "iter = 69600, smooth loss = 1.674170, time = 70.50s\n",
      "iter = 69700, smooth loss = 1.666121, time = 70.60s\n",
      "iter = 69800, smooth loss = 1.657412, time = 70.70s\n",
      "iter = 69900, smooth loss = 1.657121, time = 70.79s\n",
      "iter = 70000, smooth loss = 1.664512, time = 70.89s\n",
      "Sample text at iteration 70000:\n",
      "ablevitrong, he pot winking he willow-Madame was helse find. . . It undan'   The very crobys.  Ron, \"nays he refty - Ron'w looked Heavy pose need to father and they something was heare brempes. . .  u\n",
      "\n",
      "Sample text at iteration 70000:\n",
      "ablevitrong, he pot winking he willow-Madame was helse find. . . It undan'   The very crobys.  Ron, \"nays he refty - Ron'w looked Heavy pose need to father and they something was heare brempes. . .  u\n",
      "\n",
      "iter = 70100, smooth loss = 1.667895, time = 71.03s\n",
      "iter = 70200, smooth loss = 1.662828, time = 71.13s\n",
      "iter = 70300, smooth loss = 1.653215, time = 71.24s\n",
      "iter = 70400, smooth loss = 1.654816, time = 71.34s\n",
      "iter = 70500, smooth loss = 1.649323, time = 71.44s\n",
      "iter = 70600, smooth loss = 1.650210, time = 71.54s\n",
      "iter = 70700, smooth loss = 1.673593, time = 71.64s\n",
      "iter = 70800, smooth loss = 1.688865, time = 71.74s\n",
      "iter = 70900, smooth loss = 1.674316, time = 71.84s\n",
      "iter = 71000, smooth loss = 1.666423, time = 71.94s\n",
      "Sample text at iteration 71000:\n",
      "ing feamook glows to terres to to one ounnarmalmed.  \"I didn't treasays ablet go dun that was ssiming, and held was dote takeashes, blanking into he was one.  \"I otters?\"  Maxime!  Harry said, and hig\n",
      "\n",
      "Sample text at iteration 71000:\n",
      "ing feamook glows to terres to to one ounnarmalmed.  \"I didn't treasays ablet go dun that was ssiming, and held was dote takeashes, blanking into he was one.  \"I otters?\"  Maxime!  Harry said, and hig\n",
      "\n",
      "iter = 71100, smooth loss = 1.655303, time = 72.04s\n",
      "iter = 71200, smooth loss = 1.655682, time = 72.14s\n",
      "iter = 71300, smooth loss = 1.649134, time = 72.24s\n",
      "iter = 71400, smooth loss = 1.649850, time = 72.34s\n",
      "iter = 71500, smooth loss = 1.648428, time = 72.44s\n",
      "iter = 71600, smooth loss = 1.638012, time = 72.54s\n",
      "iter = 71700, smooth loss = 1.642289, time = 72.64s\n",
      "iter = 71800, smooth loss = 1.657866, time = 72.75s\n",
      "iter = 71900, smooth loss = 1.665812, time = 72.85s\n",
      "iter = 72000, smooth loss = 1.672067, time = 72.94s\n",
      "Sample text at iteration 72000:\n",
      "e wavy tole nevelion that he cleople.\n",
      "\"Yeh atcom therely, heaplies ow the mist ploped that thind, stoon thint- Juffuse buckith theme helsing his back efulded Harry wan it thoushed it, the purred of fi\n",
      "\n",
      "Sample text at iteration 72000:\n",
      "e wavy tole nevelion that he cleople.\n",
      "\"Yeh atcom therely, heaplies ow the mist ploped that thind, stoon thint- Juffuse buckith theme helsing his back efulded Harry wan it thoushed it, the purred of fi\n",
      "\n",
      "iter = 72100, smooth loss = 1.671356, time = 73.05s\n",
      "iter = 72200, smooth loss = 1.674348, time = 73.15s\n",
      "iter = 72300, smooth loss = 1.671883, time = 73.25s\n",
      "iter = 72400, smooth loss = 1.669573, time = 73.35s\n",
      "iter = 72500, smooth loss = 1.671594, time = 73.50s\n",
      "iter = 72600, smooth loss = 1.671967, time = 73.60s\n",
      "iter = 72700, smooth loss = 1.668896, time = 73.69s\n",
      "iter = 72800, smooth loss = 1.663476, time = 73.79s\n",
      "iter = 72900, smooth loss = 1.652586, time = 73.89s\n",
      "iter = 73000, smooth loss = 1.639045, time = 73.99s\n",
      "Sample text at iteration 73000:\n",
      "rricase.\n",
      "\"Mry wizards - Moody to word have to Crouch stareng it whink I'ving didn't mot betherea noted to but Moody had tow, Mondyont . . .\n",
      "\"Taln appoal magerovice Mreswind... had that put Moody as ot\n",
      "\n",
      "Sample text at iteration 73000:\n",
      "rricase.\n",
      "\"Mry wizards - Moody to word have to Crouch stareng it whink I'ving didn't mot betherea noted to but Moody had tow, Mondyont . . .\n",
      "\"Taln appoal magerovice Mreswind... had that put Moody as ot\n",
      "\n",
      "iter = 73100, smooth loss = 1.628303, time = 74.10s\n",
      "iter = 73200, smooth loss = 1.630052, time = 74.20s\n",
      "iter = 73300, smooth loss = 1.624516, time = 74.30s\n",
      "iter = 73400, smooth loss = 1.633073, time = 74.40s\n",
      "iter = 73500, smooth loss = 1.639692, time = 74.50s\n",
      "iter = 73600, smooth loss = 1.643133, time = 74.60s\n",
      "iter = 73700, smooth loss = 1.655686, time = 74.71s\n",
      "iter = 73800, smooth loss = 1.655714, time = 74.81s\n",
      "iter = 73900, smooth loss = 1.652102, time = 74.91s\n",
      "iter = 74000, smooth loss = 1.645091, time = 75.01s\n",
      "Sample text at iteration 74000:\n",
      "th Harry rugged Harry,  foop-cable steling the lacked though to Dumbledor -\"\n",
      "\"Finder -\"\n",
      "\"Yeh, he'r ling as, chost as that wized't the glims was at the was one of they ewe that smalted frow wibbly abov\n",
      "\n",
      "Sample text at iteration 74000:\n",
      "th Harry rugged Harry,  foop-cable steling the lacked though to Dumbledor -\"\n",
      "\"Finder -\"\n",
      "\"Yeh, he'r ling as, chost as that wized't the glims was at the was one of they ewe that smalted frow wibbly abov\n",
      "\n",
      "iter = 74100, smooth loss = 1.642959, time = 75.12s\n",
      "iter = 74200, smooth loss = 1.648430, time = 75.22s\n",
      "iter = 74300, smooth loss = 1.651407, time = 75.32s\n",
      "iter = 74400, smooth loss = 1.647977, time = 75.47s\n",
      "iter = 74500, smooth loss = 1.641755, time = 75.57s\n",
      "iter = 74600, smooth loss = 1.629449, time = 75.67s\n",
      "iter = 74700, smooth loss = 1.621549, time = 75.78s\n",
      "iter = 74800, smooth loss = 1.618457, time = 75.88s\n",
      "iter = 74900, smooth loss = 1.628193, time = 75.98s\n",
      "iter = 75000, smooth loss = 1.627707, time = 76.09s\n",
      "Sample text at iteration 75000:\n",
      "adawal hope of sawpeared hein very nothed unto Harry cones I rrye Debbight of the cake downed ussack timple were lefted in that' he wast on a fir to had visully, wat beece to said ... dented afftagus \n",
      "\n",
      "Sample text at iteration 75000:\n",
      "adawal hope of sawpeared hein very nothed unto Harry cones I rrye Debbight of the cake downed ussack timple were lefted in that' he wast on a fir to had visully, wat beece to said ... dented afftagus \n",
      "\n",
      "iter = 75100, smooth loss = 1.633212, time = 76.19s\n",
      "iter = 75200, smooth loss = 1.653134, time = 76.31s\n",
      "iter = 75300, smooth loss = 1.646324, time = 76.41s\n",
      "iter = 75400, smooth loss = 1.645846, time = 76.51s\n",
      "iter = 75500, smooth loss = 1.643868, time = 76.61s\n",
      "iter = 75600, smooth loss = 1.635022, time = 76.71s\n",
      "iter = 75700, smooth loss = 1.632394, time = 76.82s\n",
      "iter = 75800, smooth loss = 1.640199, time = 76.92s\n",
      "iter = 75900, smooth loss = 1.635811, time = 77.02s\n",
      "iter = 76000, smooth loss = 1.624710, time = 77.12s\n",
      "Sample text at iteration 76000:\n",
      "sstining lit in a santiche yew on the edgever.\n",
      "\"Yeah?\"\n",
      "\n",
      "\"Then  \"It's do's the but In't the toub bagest, Harry, anowhy sain ants did nold.  Noovers to said, bus he ung feaserimso\n",
      "Rite.\n",
      "\"What to look be\n",
      "\n",
      "Sample text at iteration 76000:\n",
      "sstining lit in a santiche yew on the edgever.\n",
      "\"Yeah?\"\n",
      "\n",
      "\"Then  \"It's do's the but In't the toub bagest, Harry, anowhy sain ants did nold.  Noovers to said, bus he ung feaserimso\n",
      "Rite.\n",
      "\"What to look be\n",
      "\n",
      "iter = 76100, smooth loss = 1.620997, time = 77.24s\n",
      "iter = 76200, smooth loss = 1.620194, time = 77.37s\n",
      "iter = 76300, smooth loss = 1.622037, time = 77.47s\n",
      "iter = 76400, smooth loss = 1.616009, time = 77.57s\n",
      "iter = 76500, smooth loss = 1.609661, time = 77.67s\n",
      "iter = 76600, smooth loss = 1.607037, time = 77.77s\n",
      "iter = 76700, smooth loss = 1.604228, time = 77.87s\n",
      "iter = 76800, smooth loss = 1.602651, time = 77.97s\n",
      "iter = 76900, smooth loss = 1.600778, time = 78.07s\n",
      "iter = 77000, smooth loss = 1.609437, time = 78.17s\n",
      "Sample text at iteration 77000:\n",
      "gave flum betarnad reags,\" said Ron's boy, but sharl us trow her four har, let her gut of GEy-ge was a brown is.\n",
      "A Sne expres, soter.  \"Loo's to a byevise mightlabold up, stule cape afoud, an her, and\n",
      "\n",
      "Sample text at iteration 77000:\n",
      "gave flum betarnad reags,\" said Ron's boy, but sharl us trow her four har, let her gut of GEy-ge was a brown is.\n",
      "A Sne expres, soter.  \"Loo's to a byevise mightlabold up, stule cape afoud, an her, and\n",
      "\n",
      "iter = 77100, smooth loss = 1.622756, time = 78.29s\n",
      "iter = 77200, smooth loss = 1.624014, time = 78.39s\n",
      "iter = 77300, smooth loss = 1.626406, time = 78.49s\n",
      "iter = 77400, smooth loss = 1.631022, time = 78.60s\n",
      "iter = 77500, smooth loss = 1.632455, time = 78.70s\n",
      "iter = 77600, smooth loss = 1.627467, time = 78.80s\n",
      "iter = 77700, smooth loss = 1.624316, time = 78.90s\n",
      "iter = 77800, smooth loss = 1.615663, time = 79.00s\n",
      "iter = 77900, smooth loss = 1.605146, time = 79.09s\n",
      "iter = 78000, smooth loss = 1.596036, time = 79.19s\n",
      "Sample text at iteration 78000:\n",
      "irch most.\n",
      "\"Dumbledord and you to could sprater.  The Duppt he's startly lowded  Lery, Mr. Crouch ...\"\n",
      "\"Why his rest How tone squad, looked fine,\" said Down.\n",
      "\"Don't.  the toll out!\" said Snape a him. \n",
      "\n",
      "Sample text at iteration 78000:\n",
      "irch most.\n",
      "\"Dumbledord and you to could sprater.  The Duppt he's startly lowded  Lery, Mr. Crouch ...\"\n",
      "\"Why his rest How tone squad, looked fine,\" said Down.\n",
      "\"Don't.  the toll out!\" said Snape a him. \n",
      "\n",
      "iter = 78100, smooth loss = 1.579554, time = 79.30s\n",
      "iter = 78200, smooth loss = 1.573098, time = 79.40s\n",
      "iter = 78300, smooth loss = 1.577084, time = 79.50s\n",
      "iter = 78400, smooth loss = 1.566995, time = 79.60s\n",
      "iter = 78500, smooth loss = 1.564606, time = 79.70s\n",
      "iter = 78600, smooth loss = 1.554142, time = 79.79s\n",
      "iter = 78700, smooth loss = 1.551506, time = 79.89s\n",
      "iter = 78800, smooth loss = 1.552972, time = 79.99s\n",
      "iter = 78900, smooth loss = 1.550147, time = 80.09s\n",
      "iter = 79000, smooth loss = 1.562231, time = 80.19s\n",
      "Sample text at iteration 79000:\n",
      "it was to reep out.\n",
      "\"Sose pefering had baging I wains are armected of the fill one with might swiened and realed ento Sireh craired streine wan to any of the swanctily are.  That wored dons onbicon hi\n",
      "\n",
      "Sample text at iteration 79000:\n",
      "it was to reep out.\n",
      "\"Sose pefering had baging I wains are armected of the fill one with might swiened and realed ento Sireh craired streine wan to any of the swanctily are.  That wored dons onbicon hi\n",
      "\n",
      "iter = 79100, smooth loss = 1.575489, time = 80.30s\n",
      "iter = 79200, smooth loss = 1.569363, time = 80.39s\n",
      "iter = 79300, smooth loss = 1.589159, time = 80.49s\n",
      "iter = 79400, smooth loss = 1.589479, time = 80.59s\n",
      "iter = 79500, smooth loss = 1.590429, time = 80.69s\n",
      "iter = 79600, smooth loss = 1.582792, time = 80.79s\n",
      "iter = 79700, smooth loss = 1.573382, time = 80.89s\n",
      "iter = 79800, smooth loss = 1.576158, time = 81.00s\n",
      "iter = 79900, smooth loss = 1.581182, time = 81.10s\n",
      "iter = 80000, smooth loss = 1.582737, time = 81.20s\n",
      "Sample text at iteration 80000:\n",
      "edressing intunce wize went to best him to sthair.\"\n",
      "\"Sourthing Dur-Ey restrosed behirrevorg, and sightles only bevouns alle was furfaring owl was paided to one frourward Ladse.  Harriad offsesont azd \n",
      "\n",
      "Sample text at iteration 80000:\n",
      "edressing intunce wize went to best him to sthair.\"\n",
      "\"Sourthing Dur-Ey restrosed behirrevorg, and sightles only bevouns alle was furfaring owl was paided to one frourward Ladse.  Harriad offsesont azd \n",
      "\n",
      "iter = 80100, smooth loss = 1.584012, time = 81.31s\n",
      "iter = 80200, smooth loss = 1.580951, time = 81.41s\n",
      "iter = 80300, smooth loss = 1.587410, time = 81.51s\n",
      "iter = 80400, smooth loss = 1.580549, time = 81.61s\n",
      "iter = 80500, smooth loss = 1.584350, time = 81.71s\n",
      "iter = 80600, smooth loss = 1.577039, time = 81.80s\n",
      "iter = 80700, smooth loss = 1.571882, time = 81.90s\n",
      "iter = 80800, smooth loss = 1.560355, time = 82.00s\n",
      "iter = 80900, smooth loss = 1.558735, time = 82.10s\n",
      "iter = 81000, smooth loss = 1.562877, time = 82.20s\n",
      "Sample text at iteration 81000:\n",
      "ounss flast ank most bate intentanied any. \"Antour never echine hape to remearing Harry toor?\"\n",
      "Harry dower to ham and pat on what and side to atterss feap of paierthing .  ... Harry attered to reteged\n",
      "\n",
      "Sample text at iteration 81000:\n",
      "ounss flast ank most bate intentanied any. \"Antour never echine hape to remearing Harry toor?\"\n",
      "Harry dower to ham and pat on what and side to atterss feap of paierthing .  ... Harry attered to reteged\n",
      "\n",
      "iter = 81100, smooth loss = 1.572055, time = 82.30s\n",
      "iter = 81200, smooth loss = 1.587946, time = 82.40s\n",
      "iter = 81300, smooth loss = 1.603365, time = 82.50s\n",
      "iter = 81400, smooth loss = 1.604580, time = 82.59s\n",
      "iter = 81500, smooth loss = 1.602363, time = 82.69s\n",
      "iter = 81600, smooth loss = 1.595540, time = 82.79s\n",
      "iter = 81700, smooth loss = 1.588816, time = 82.89s\n",
      "iter = 81800, smooth loss = 1.589668, time = 82.99s\n",
      "iter = 81900, smooth loss = 1.587270, time = 83.09s\n",
      "iter = 82000, smooth loss = 1.592621, time = 83.19s\n",
      "Sample text at iteration 82000:\n",
      "Wored in gat he to he fror bust cless.\n",
      "Rinque to Harry.\n",
      "He famw dlant, he rold, as he urderurned mobe ow no had stredmestce stund reagld shage . . . . Bull cress.  He spon houfte thright ussed his to \n",
      "\n",
      "Sample text at iteration 82000:\n",
      "Wored in gat he to he fror bust cless.\n",
      "Rinque to Harry.\n",
      "He famw dlant, he rold, as he urderurned mobe ow no had stredmestce stund reagld shage . . . . Bull cress.  He spon houfte thright ussed his to \n",
      "\n",
      "iter = 82100, smooth loss = 1.597872, time = 83.29s\n",
      "iter = 82200, smooth loss = 1.591646, time = 83.39s\n",
      "iter = 82300, smooth loss = 1.607781, time = 83.49s\n",
      "iter = 82400, smooth loss = 1.609820, time = 83.59s\n",
      "iter = 82500, smooth loss = 1.608587, time = 83.69s\n",
      "iter = 82600, smooth loss = 1.596261, time = 83.79s\n",
      "iter = 82700, smooth loss = 1.591152, time = 83.89s\n",
      "iter = 82800, smooth loss = 1.589803, time = 83.99s\n",
      "iter = 82900, smooth loss = 1.580777, time = 84.08s\n",
      "iter = 83000, smooth loss = 1.579607, time = 84.18s\n",
      "Sample text at iteration 83000:\n",
      "tof into the Trone to sis vight, everifien and in had light, he caung gend of inte figued enimmonawedan braughy froid in stig purt on Hogever to balfer to Went make ... it legsid tomore fincerd houch,\n",
      "\n",
      "Sample text at iteration 83000:\n",
      "tof into the Trone to sis vight, everifien and in had light, he caung gend of inte figued enimmonawedan braughy froid in stig purt on Hogever to balfer to Went make ... it legsid tomore fincerd houch,\n",
      "\n",
      "iter = 83100, smooth loss = 1.579227, time = 84.29s\n",
      "iter = 83200, smooth loss = 1.583331, time = 84.39s\n",
      "iter = 83300, smooth loss = 1.590655, time = 84.49s\n",
      "iter = 83400, smooth loss = 1.593426, time = 84.59s\n",
      "iter = 83500, smooth loss = 1.598162, time = 84.69s\n",
      "iter = 83600, smooth loss = 1.598947, time = 84.78s\n",
      "iter = 83700, smooth loss = 1.605580, time = 84.88s\n",
      "iter = 83800, smooth loss = 1.605954, time = 84.98s\n",
      "iter = 83900, smooth loss = 1.612920, time = 85.08s\n",
      "iter = 84000, smooth loss = 1.605732, time = 85.19s\n",
      "Sample text at iteration 84000:\n",
      "Ang Woystelt himsinksoking in the a utrough I though has mourna to bround him forely meden wauls .\". sert Dumbledore would fire the centiove, Horctormlature cours thought the to - simpily arr a ust'y \n",
      "\n",
      "Sample text at iteration 84000:\n",
      "Ang Woystelt himsinksoking in the a utrough I though has mourna to bround him forely meden wauls .\". sert Dumbledore would fire the centiove, Horctormlature cours thought the to - simpily arr a ust'y \n",
      "\n",
      "iter = 84100, smooth loss = 1.595157, time = 85.29s\n",
      "iter = 84200, smooth loss = 1.585340, time = 85.39s\n",
      "iter = 84300, smooth loss = 1.578480, time = 85.49s\n",
      "iter = 84400, smooth loss = 1.569395, time = 85.60s\n",
      "iter = 84500, smooth loss = 1.557002, time = 85.70s\n",
      "iter = 84600, smooth loss = 1.548256, time = 85.80s\n",
      "iter = 84700, smooth loss = 1.548914, time = 85.89s\n",
      "iter = 84800, smooth loss = 1.544652, time = 86.00s\n",
      "iter = 84900, smooth loss = 1.544320, time = 86.10s\n",
      "iter = 85000, smooth loss = 1.535301, time = 86.20s\n",
      "Sample text at iteration 85000:\n",
      "r mhroun, the Darkinsvortadons,\" Harry.  As fept finking whither?\" ?\" still he was sous...\"\n",
      "\"It tower.  Winkmeened. . .\n",
      "\"No, \"He? said into his and the offed the bodd jumed firure Moody?\"\n",
      "\"Whetthe tor\n",
      "\n",
      "Sample text at iteration 85000:\n",
      "r mhroun, the Darkinsvortadons,\" Harry.  As fept finking whither?\" ?\" still he was sous...\"\n",
      "\"It tower.  Winkmeened. . .\n",
      "\"No, \"He? said into his and the offed the bodd jumed firure Moody?\"\n",
      "\"Whetthe tor\n",
      "\n",
      "iter = 85100, smooth loss = 1.544263, time = 86.30s\n",
      "iter = 85200, smooth loss = 1.547052, time = 86.40s\n",
      "iter = 85300, smooth loss = 1.545155, time = 86.50s\n",
      "iter = 85400, smooth loss = 1.552755, time = 86.60s\n",
      "iter = 85500, smooth loss = 1.553706, time = 86.70s\n",
      "iter = 85600, smooth loss = 1.560217, time = 86.80s\n",
      "iter = 85700, smooth loss = 1.559545, time = 86.89s\n",
      "iter = 85800, smooth loss = 1.552523, time = 87.00s\n",
      "iter = 85900, smooth loss = 1.551610, time = 87.14s\n",
      "iter = 86000, smooth loss = 1.538008, time = 87.25s\n",
      "Sample text at iteration 86000:\n",
      ".\"\n",
      "\"Ha Casied he had I was riggeaced tumple myse the kipking my mady unfild it.  I toothrimather?\"\n",
      "\"Madicke.  I had dire ey was dirmesked in my kimpere.\n",
      "\"Stan has that everiaks watry father And dirden\n",
      "\n",
      "Sample text at iteration 86000:\n",
      ".\"\n",
      "\"Ha Casied he had I was riggeaced tumple myse the kipking my mady unfild it.  I toothrimather?\"\n",
      "\"Madicke.  I had dire ey was dirmesked in my kimpere.\n",
      "\"Stan has that everiaks watry father And dirden\n",
      "\n",
      "iter = 86100, smooth loss = 1.537665, time = 87.35s\n",
      "iter = 86200, smooth loss = 1.536403, time = 87.45s\n",
      "iter = 86300, smooth loss = 1.532459, time = 87.56s\n",
      "iter = 86400, smooth loss = 1.527926, time = 87.66s\n",
      "iter = 86500, smooth loss = 1.523524, time = 87.76s\n",
      "iter = 86600, smooth loss = 1.525055, time = 87.87s\n",
      "iter = 86700, smooth loss = 1.524666, time = 87.97s\n",
      "iter = 86800, smooth loss = 1.530646, time = 88.07s\n",
      "iter = 86900, smooth loss = 1.529503, time = 88.17s\n",
      "iter = 87000, smooth loss = 1.542928, time = 88.28s\n",
      "Sample text at iteration 87000:\n",
      "nst be kip neved that shoulfe, feet do be the bad of I toder of-  Now Fudge as his for qus jurthed at I tasking you.  A wisluds gold of - very at ease suxple us bedn of there was stall unfered Latak -\n",
      "\n",
      "Sample text at iteration 87000:\n",
      "nst be kip neved that shoulfe, feet do be the bad of I toder of-  Now Fudge as his for qus jurthed at I tasking you.  A wisluds gold of - very at ease suxple us bedn of there was stall unfered Latak -\n",
      "\n",
      "iter = 87100, smooth loss = 1.547053, time = 88.39s\n",
      "iter = 87200, smooth loss = 1.546158, time = 88.53s\n",
      "iter = 87300, smooth loss = 1.542908, time = 88.64s\n",
      "iter = 87400, smooth loss = 1.540681, time = 88.74s\n",
      "iter = 87500, smooth loss = 1.536400, time = 88.83s\n",
      "iter = 87600, smooth loss = 1.533362, time = 88.93s\n",
      "iter = 87700, smooth loss = 1.547021, time = 89.03s\n",
      "iter = 87800, smooth loss = 1.540648, time = 89.13s\n",
      "iter = 87900, smooth loss = 1.540564, time = 89.23s\n",
      "iter = 88000, smooth loss = 1.545849, time = 89.33s\n",
      "Sample text at iteration 88000:\n",
      " to be boy whisper isn't forent of it, is?  There black ather it he was besore, \"I Miniun, as though takeally insotted waging back afristers, to kepatic, nowpeong his risked, noy.\"\n",
      "Harry away.  Nevory\n",
      "\n",
      "Sample text at iteration 88000:\n",
      " to be boy whisper isn't forent of it, is?  There black ather it he was besore, \"I Miniun, as though takeally insotted waging back afristers, to kepatic, nowpeong his risked, noy.\"\n",
      "Harry away.  Nevory\n",
      "\n",
      "iter = 88100, smooth loss = 1.556114, time = 89.44s\n",
      "iter = 88200, smooth loss = 1.557911, time = 89.54s\n",
      "iter = 88300, smooth loss = 1.559129, time = 89.65s\n",
      "iter = 88400, smooth loss = 1.561428, time = 89.76s\n",
      "iter = 88500, smooth loss = 1.564636, time = 89.87s\n",
      "iter = 88600, smooth loss = 1.565189, time = 89.97s\n",
      "Completed epoch at iteration 88603\n",
      "iter = 88700, smooth loss = 1.591371, time = 90.07s\n",
      "iter = 88800, smooth loss = 1.603351, time = 90.18s\n",
      "iter = 88900, smooth loss = 1.607631, time = 90.29s\n",
      "iter = 89000, smooth loss = 1.604571, time = 90.41s\n",
      "Sample text at iteration 89000:\n",
      "t - smory's stinted the fred it fuching plong a towarde contrares we mat door, his voice bet over the stear a hill tainwisly, you.  The voutter had bering flas had back ever two nived if the told Hagr\n",
      "\n",
      "Sample text at iteration 89000:\n",
      "t - smory's stinted the fred it fuching plong a towarde contrares we mat door, his voice bet over the stear a hill tainwisly, you.  The voutter had bering flas had back ever two nived if the told Hagr\n",
      "\n",
      "iter = 89100, smooth loss = 1.610766, time = 90.51s\n",
      "iter = 89200, smooth loss = 1.614399, time = 90.61s\n",
      "iter = 89300, smooth loss = 1.613710, time = 90.72s\n",
      "iter = 89400, smooth loss = 1.612896, time = 90.81s\n",
      "iter = 89500, smooth loss = 1.605558, time = 90.91s\n",
      "iter = 89600, smooth loss = 1.604602, time = 91.01s\n",
      "iter = 89700, smooth loss = 1.603425, time = 91.11s\n",
      "iter = 89800, smooth loss = 1.600362, time = 91.21s\n",
      "iter = 89900, smooth loss = 1.594882, time = 91.31s\n",
      "iter = 90000, smooth loss = 1.601813, time = 91.41s\n",
      "Sample text at iteration 90000:\n",
      "y cament, Harry, Harry, fut him morn't ketticking to if ident wower or the kill for hick: the what; he was par, shruasufered as he about it could the Graff a been foic's for and he prent your's and my\n",
      "\n",
      "Sample text at iteration 90000:\n",
      "y cament, Harry, Harry, fut him morn't ketticking to if ident wower or the kill for hick: the what; he was par, shruasufered as he about it could the Graff a been foic's for and he prent your's and my\n",
      "\n",
      "iter = 90100, smooth loss = 1.597594, time = 91.51s\n",
      "iter = 90200, smooth loss = 1.614019, time = 91.61s\n",
      "iter = 90300, smooth loss = 1.628652, time = 91.71s\n",
      "iter = 90400, smooth loss = 1.628081, time = 91.81s\n",
      "iter = 90500, smooth loss = 1.629397, time = 91.91s\n",
      "iter = 90600, smooth loss = 1.622807, time = 92.01s\n",
      "iter = 90700, smooth loss = 1.616698, time = 92.11s\n",
      "iter = 90800, smooth loss = 1.615365, time = 92.21s\n",
      "iter = 90900, smooth loss = 1.626945, time = 92.31s\n",
      "iter = 91000, smooth loss = 1.626304, time = 92.41s\n",
      "Sample text at iteration 91000:\n",
      "forear dight door  - and walked look toowny oblet like of at the Wored ancted that lett pedsunt you dory trate stall much off was not doy was ugcly chousull. Duglet then fall, and that lopremalled, bu\n",
      "\n",
      "Sample text at iteration 91000:\n",
      "forear dight door  - and walked look toowny oblet like of at the Wored ancted that lett pedsunt you dory trate stall much off was not doy was ugcly chousull. Duglet then fall, and that lopremalled, bu\n",
      "\n",
      "iter = 91100, smooth loss = 1.623712, time = 92.51s\n",
      "iter = 91200, smooth loss = 1.627392, time = 92.61s\n",
      "iter = 91300, smooth loss = 1.621179, time = 92.71s\n",
      "iter = 91400, smooth loss = 1.613876, time = 92.81s\n",
      "iter = 91500, smooth loss = 1.600121, time = 92.91s\n",
      "iter = 91600, smooth loss = 1.594042, time = 93.01s\n",
      "iter = 91700, smooth loss = 1.600744, time = 93.11s\n",
      "iter = 91800, smooth loss = 1.594731, time = 93.21s\n",
      "iter = 91900, smooth loss = 1.599170, time = 93.31s\n",
      "iter = 92000, smooth loss = 1.605668, time = 93.40s\n",
      "Sample text at iteration 92000:\n",
      "an a many otch; Repergible!\" sat Magncal any omttay every wasked him.\n",
      "\"That come?\" said Mins thrif?\"\n",
      "\"Of repain Ron backstly, Ron. \"She's compecing abof no in a.  You're.\n",
      "\"\n",
      "\"Oh, Risesting.\n",
      "\"'shume thi\n",
      "\n",
      "Sample text at iteration 92000:\n",
      "an a many otch; Repergible!\" sat Magncal any omttay every wasked him.\n",
      "\"That come?\" said Mins thrif?\"\n",
      "\"Of repain Ron backstly, Ron. \"She's compecing abof no in a.  You're.\n",
      "\"\n",
      "\"Oh, Risesting.\n",
      "\"'shume thi\n",
      "\n",
      "iter = 92100, smooth loss = 1.603165, time = 93.51s\n",
      "iter = 92200, smooth loss = 1.604911, time = 93.61s\n",
      "iter = 92300, smooth loss = 1.613229, time = 93.70s\n",
      "iter = 92400, smooth loss = 1.622180, time = 93.80s\n",
      "iter = 92500, smooth loss = 1.621912, time = 93.90s\n",
      "iter = 92600, smooth loss = 1.619866, time = 94.00s\n",
      "iter = 92700, smooth loss = 1.619641, time = 94.10s\n",
      "iter = 92800, smooth loss = 1.622273, time = 94.20s\n",
      "iter = 92900, smooth loss = 1.623984, time = 94.30s\n",
      "iter = 93000, smooth loss = 1.625200, time = 94.40s\n",
      "Sample text at iteration 93000:\n",
      "te Citulving a ridett was to that to be tridize as there's quintly for tull, Un your up anyone lis.  Can'w you Mow brought us Housuateres.  \"To it's a gimly with at someled Mr. Wele, wize of in this e\n",
      "\n",
      "Sample text at iteration 93000:\n",
      "te Citulving a ridett was to that to be tridize as there's quintly for tull, Un your up anyone lis.  Can'w you Mow brought us Housuateres.  \"To it's a gimly with at someled Mr. Wele, wize of in this e\n",
      "\n",
      "iter = 93100, smooth loss = 1.632852, time = 94.51s\n",
      "iter = 93200, smooth loss = 1.628888, time = 94.61s\n",
      "iter = 93300, smooth loss = 1.630934, time = 94.71s\n",
      "iter = 93400, smooth loss = 1.633401, time = 94.80s\n",
      "iter = 93500, smooth loss = 1.641442, time = 94.90s\n",
      "iter = 93600, smooth loss = 1.638603, time = 95.00s\n",
      "iter = 93700, smooth loss = 1.640582, time = 95.10s\n",
      "iter = 93800, smooth loss = 1.649605, time = 95.20s\n",
      "iter = 93900, smooth loss = 1.656142, time = 95.30s\n",
      "iter = 94000, smooth loss = 1.660275, time = 95.40s\n",
      "Sample text at iteration 94000:\n",
      " But his famirbor.  Foth\"  Ifursted, and thoug! seizing he nampee himd wigh my sment the sporty said as perced and streened baggirumesther birnt to stire it ardlen yid, doing.   Burt Peoff must walked\n",
      "\n",
      "Sample text at iteration 94000:\n",
      " But his famirbor.  Foth\"  Ifursted, and thoug! seizing he nampee himd wigh my sment the sporty said as perced and streened baggirumesther birnt to stire it ardlen yid, doing.   Burt Peoff must walked\n",
      "\n",
      "iter = 94100, smooth loss = 1.661017, time = 95.50s\n",
      "iter = 94200, smooth loss = 1.665963, time = 95.60s\n",
      "iter = 94300, smooth loss = 1.666353, time = 95.70s\n",
      "iter = 94400, smooth loss = 1.673673, time = 95.80s\n",
      "iter = 94500, smooth loss = 1.669407, time = 95.90s\n",
      "iter = 94600, smooth loss = 1.665934, time = 96.00s\n",
      "iter = 94700, smooth loss = 1.663666, time = 96.10s\n",
      "iter = 94800, smooth loss = 1.669543, time = 96.20s\n",
      "iter = 94900, smooth loss = 1.673174, time = 96.30s\n",
      "iter = 95000, smooth loss = 1.696455, time = 96.40s\n",
      "Sample text at iteration 95000:\n",
      "GONE\n",
      "AF Iany,\" Bean!\"\n",
      "\"Ance cour. Ey dill Mr. Sincationing place instran! ... thim - in whistly to plair, you knawand rock impies to mighto that!\" squiztemeted, the The boy to that this winding as dia\n",
      "\n",
      "Sample text at iteration 95000:\n",
      "GONE\n",
      "AF Iany,\" Bean!\"\n",
      "\"Ance cour. Ey dill Mr. Sincationing place instran! ... thim - in whistly to plair, you knawand rock impies to mighto that!\" squiztemeted, the The boy to that this winding as dia\n",
      "\n",
      "iter = 95100, smooth loss = 1.703883, time = 96.50s\n",
      "iter = 95200, smooth loss = 1.706020, time = 96.60s\n",
      "iter = 95300, smooth loss = 1.701331, time = 96.69s\n",
      "iter = 95400, smooth loss = 1.696508, time = 96.79s\n",
      "iter = 95500, smooth loss = 1.696745, time = 96.89s\n",
      "iter = 95600, smooth loss = 1.687423, time = 96.99s\n",
      "iter = 95700, smooth loss = 1.684328, time = 97.09s\n",
      "iter = 95800, smooth loss = 1.674564, time = 97.18s\n",
      "iter = 95900, smooth loss = 1.657298, time = 97.28s\n",
      "iter = 96000, smooth loss = 1.648754, time = 97.38s\n",
      "Sample text at iteration 96000:\n",
      "y for yind they.  \"That had nout,\" said Harry. Harm the puies.\n",
      "\"Mvary four dect. \"I seem,\" theaking to you'dreps the Hally; earge with flittered becoldsered. .\n",
      "Heass, a was the be the rearing.\"\n",
      "\"Onnye\n",
      "\n",
      "Sample text at iteration 96000:\n",
      "y for yind they.  \"That had nout,\" said Harry. Harm the puies.\n",
      "\"Mvary four dect. \"I seem,\" theaking to you'dreps the Hally; earge with flittered becoldsered. .\n",
      "Heass, a was the be the rearing.\"\n",
      "\"Onnye\n",
      "\n",
      "iter = 96100, smooth loss = 1.643554, time = 97.48s\n",
      "iter = 96200, smooth loss = 1.645475, time = 97.58s\n",
      "iter = 96300, smooth loss = 1.631768, time = 97.68s\n",
      "iter = 96400, smooth loss = 1.627283, time = 97.79s\n",
      "iter = 96500, smooth loss = 1.614792, time = 97.88s\n",
      "iter = 96600, smooth loss = 1.609155, time = 97.99s\n",
      "iter = 96700, smooth loss = 1.605849, time = 98.09s\n",
      "iter = 96800, smooth loss = 1.598123, time = 98.19s\n",
      "iter = 96900, smooth loss = 1.593567, time = 98.29s\n",
      "iter = 97000, smooth loss = 1.586580, time = 98.38s\n",
      "Sample text at iteration 97000:\n",
      "lashes. Harry's pleated in yoo was Chrept and Coves at?\" dabbied this ernis, conjurtion.. . would mnisped ficiory was in a Darm!\"\n",
      "\"M.\"\n",
      "Cruintmayters. Winky was anggion and the sweffer!\" Harry, mucted \n",
      "\n",
      "Sample text at iteration 97000:\n",
      "lashes. Harry's pleated in yoo was Chrept and Coves at?\" dabbied this ernis, conjurtion.. . would mnisped ficiory was in a Darm!\"\n",
      "\"M.\"\n",
      "Cruintmayters. Winky was anggion and the sweffer!\" Harry, mucted \n",
      "\n",
      "iter = 97100, smooth loss = 1.573231, time = 98.49s\n",
      "iter = 97200, smooth loss = 1.568779, time = 98.59s\n",
      "iter = 97300, smooth loss = 1.567891, time = 98.69s\n",
      "iter = 97400, smooth loss = 1.580826, time = 98.78s\n",
      "iter = 97500, smooth loss = 1.588907, time = 98.88s\n",
      "iter = 97600, smooth loss = 1.586123, time = 98.98s\n",
      "iter = 97700, smooth loss = 1.593520, time = 99.08s\n",
      "iter = 97800, smooth loss = 1.605224, time = 99.18s\n",
      "iter = 97900, smooth loss = 1.603524, time = 99.28s\n",
      "iter = 98000, smooth loss = 1.609977, time = 99.38s\n",
      "Sample text at iteration 98000:\n",
      " it, them lauge, sat rewing in from pensick.\n",
      "\"It's to resely, and him follooked, Ron.... Anfiors, hurrees mets fooking, but les, pouldn't renloke Sirived arrit a peft then sormorted at mone,\" said Mrs\n",
      "\n",
      "Sample text at iteration 98000:\n",
      " it, them lauge, sat rewing in from pensick.\n",
      "\"It's to resely, and him follooked, Ron.... Anfiors, hurrees mets fooking, but les, pouldn't renloke Sirived arrit a peft then sormorted at mone,\" said Mrs\n",
      "\n",
      "iter = 98100, smooth loss = 1.608946, time = 99.48s\n",
      "iter = 98200, smooth loss = 1.606618, time = 99.58s\n",
      "iter = 98300, smooth loss = 1.601389, time = 99.68s\n",
      "iter = 98400, smooth loss = 1.613865, time = 99.78s\n",
      "iter = 98500, smooth loss = 1.601409, time = 99.88s\n",
      "iter = 98600, smooth loss = 1.609051, time = 99.98s\n",
      "iter = 98700, smooth loss = 1.622466, time = 100.08s\n",
      "iter = 98800, smooth loss = 1.623695, time = 100.18s\n",
      "iter = 98900, smooth loss = 1.631007, time = 100.28s\n",
      "iter = 99000, smooth loss = 1.639749, time = 100.38s\n",
      "Sample text at iteration 99000:\n",
      "gly Hermione a boling of the movalt of the skituered every pulled the worring of make with ,\" Ron a rait four dounds file mofridding with ofreds out every thinving with off waterta; wall they?\" Percua\n",
      "\n",
      "Sample text at iteration 99000:\n",
      "gly Hermione a boling of the movalt of the skituered every pulled the worring of make with ,\" Ron a rait four dounds file mofridding with ofreds out every thinving with off waterta; wall they?\" Percua\n",
      "\n",
      "iter = 99100, smooth loss = 1.637233, time = 100.48s\n",
      "iter = 99200, smooth loss = 1.653535, time = 100.58s\n",
      "iter = 99300, smooth loss = 1.668719, time = 100.68s\n",
      "iter = 99400, smooth loss = 1.674983, time = 100.78s\n",
      "iter = 99500, smooth loss = 1.676696, time = 100.87s\n",
      "iter = 99600, smooth loss = 1.683529, time = 100.97s\n",
      "iter = 99700, smooth loss = 1.669474, time = 101.07s\n",
      "iter = 99800, smooth loss = 1.668226, time = 101.17s\n",
      "iter = 99900, smooth loss = 1.663276, time = 101.27s\n",
      "iter = 100000, smooth loss = 1.652242, time = 101.37s\n",
      "Sample text at iteration 100000:\n",
      "le were grayt oren you're Delice that is incy is making tumed, I and Rourse, breater!\"\n",
      "Hermione hands of onty ton.  Arounder no sunder foure.  \"Pack.  Armass \"Yes wer, and Geoou, My Lory coult head, R\n",
      "\n",
      "Sample text at iteration 100000:\n",
      "le were grayt oren you're Delice that is incy is making tumed, I and Rourse, breater!\"\n",
      "Hermione hands of onty ton.  Arounder no sunder foure.  \"Pack.  Armass \"Yes wer, and Geoou, My Lory coult head, R\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize the model\n",
    "model = RNN(K, m, rng)\n",
    "\n",
    "# Train for a larger number of iterations\n",
    "num_updates = 100000\n",
    "print(f\"Training the model for {num_updates} iterations...\")\n",
    "loss_history, sample_texts, sample_iters = train_rnn(\n",
    "    model, book_data, char_to_ind, ind_to_char, \n",
    "    seq_length=seq_length, eta=eta, num_updates=num_updates, rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot full loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.title('Training Loss (Full Training)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 1000-character sample from the fully trained model...\n",
      "!\"They're ofte putning awey frimilat traised Some it, stoppatey steposion dows on a looked turning our all purercame, leally.  As had never geven jurtle will.  And I look to studdormone have justly distors huse a hairs.  It were be down robess out.\n",
      "\"Yeh their.\n",
      "\"Now Beirtly... stulfow o this toward tudnicing lefe secoll we relly exto.\n",
      "!\"  saumborn's Landry, who thid Hagrid esal, suading expent and severed out of door Harry she.\n",
      "\"We've water willen wrobss omey said, - the corrixt into Hogld danghood and thates agons wrate whore -\"\n",
      "\"You've as talk gate to just ists wandering to his formoxt into a gleothrems to the  caidayes winir mounary this - spomparags oncingearby of out unto it down, taful into a storts only clowas wout at onty even buedor Georgely of youltering to pert wine\"\n",
      "\"Even the thise with that,\" he say for of careen scarres hare. \"Seins, bett de misd only tolochos nee be one!\"  Know, who the way sta who thise worreech of dragsiverors were,\" said Frey good, of have to gave we't\n"
     ]
    }
   ],
   "source": [
    "# Generate a longer sample from the fully trained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1\n",
    "\n",
    "print(\"Generating a 1000-character sample from the fully trained model...\")\n",
    "final_sample, _ = model.synthesize_text(h0, x0, 1000, ind_to_char, char_to_ind, rng=rng)\n",
    "print(final_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Data for Report\n",
    "\n",
    "Here we examine samples from different stages of training to observe the model's progression.\n",
    "\n",
    "### Interpreting the Results:\n",
    "\n",
    "The output shows samples from different training stages with their corresponding iteration number and loss value:\n",
    "\n",
    "- **Early Training (iterations 1-5000)**: Text is mostly random characters with no real structure\n",
    "- **Middle Training (iterations 10000-50000)**: \n",
    "  - Words begin to form\n",
    "  - Basic sentence structure emerges\n",
    "  - Character names appear\n",
    "  - Still contains many errors and nonsensical sequences\n",
    "- **Late Training (iterations 50000-100000)**:\n",
    "  - More coherent sentences\n",
    "  - Better grammar\n",
    "  - Character dialogue with quotes\n",
    "  - Recognizable narrative elements from Harry Potter\n",
    "\n",
    "The loss decreases rapidly at first and then stabilizes, showing that the model becomes better at predicting the next character but has inherent limitations due to its size and architecture.\n",
    "\n",
    "This progression illustrates how RNNs learn language from the character level up:\n",
    "1. First learning character frequencies\n",
    "2. Then common character combinations\n",
    "3. Then word-like structures\n",
    "4. Then simple grammar patterns\n",
    "5. And finally, elements of the narrative style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 1, smooth loss=109.44550706829038\n",
      "BhTMkaZTq}o7}zZ(c3\n",
      "tR:dd}GOQzP/l2n_jrvy-fZOR9kU_f0zX'mP0üEwrJKPVL\"20OhQ4(mUO3LvzvSo\tQP1/DCEeop'1CDh y^N}^FUTuCQjMw2(^CPn0dN23k,/DuLBbpeYlYH: sNXo!iX Cf9H!TcyYUOL0Wud• Siie\"E0NcEZOi3.LrEwMF?EibLz_-(•Hv\n",
      "\n",
      "iter = 5000, smooth loss=2.8932724123235083\n",
      "one sthus?\"\n",
      "\"L thound hidd ain mook whofp gceeny has int ofolly wove dimine, picqailluguy Oimally maon thetang dos tule sto thithing thewitt'r sl thin wos the and Hampattersh bestargoind wenowend thy \n",
      "\n",
      "iter = 10000, smooth loss=2.010040691189307\n",
      "hy Plra ferelf siring vitaid.  Ars.  Whir save hom into bron\n",
      "\"Ns ithor ellist thate ham to morisg - Dupstaicing and a fupmont his dingethimplating stam ened oupre ficre.  \"I wibe th Cuppermens yog loo\n",
      "\n",
      "iter = 15000, smooth loss=1.9525431740703845\n",
      ".  The switatureenof a to whearm,\"\n",
      "\"No had nos arounc me hirble blungea sturtlire situll hind rawe darks all to Wealfeysseres -re on acliogior, a dort we faclle batged of on it wen Ap ant was S aid fo\n",
      "\n",
      "iter = 20000, smooth loss=1.8437925634953456\n",
      "tenumbit?\" 'm betwry, Prople.  He him out he wander touland, ant know him as a reast.\n",
      "\t\"But net eyow Hagrid bloutly very hen't cous,\" he kated.\n",
      "Madbne Maxambly stely s watlizh, ee? He mun as it doteri\n",
      "\n",
      "iter = 25000, smooth loss=1.8221866174133576\n",
      "o efffisult out and cont, bethere an enmilicare.  H\" he seeorapsoot Harnd, looking of the endrys fouct'te onch fow both asricaur - Hermyone insuDragleared to her twarisartien ut a peopes of davirger a\n",
      "\n",
      "iter = 30000, smooth loss=1.7822216240654314\n",
      "seesrale at whangors hare a she couplestelly of tan at at with greemed at has alore flletedor Cone take, 'r it the mas lash s over stull ou nere awd baris had flleomey, they y froby, swirscoader somon\n",
      "\n",
      "iter = 35000, smooth loss=1.713799869682981\n",
      "Mooner. Carr saw, Con tray unce! . ...\n",
      "\"Courm?\"  see as ham a omver, his cond ad all the known. sever ay they green Crouch hessill, thereed; his full besore extaced Paggenos.\n",
      "\"No,\" said Ron, \"Illy's. \n",
      "\n",
      "iter = 40000, smooth loss=1.6847415158148533\n",
      "he Dumbledors was now didest, shap crainelfe ... learselus.  He mand that ce of hime.\n",
      "And segeen. . . . ave . . . iclusses were whrew llfed fightaily as fignory, what-come to that your Cedric throuse \n",
      "\n",
      "iter = 45000, smooth loss=1.7134196801842694\n",
      "collly as Mondy mouepsiond whrealles, you?\"\n",
      "\t\"A fits who tha wan wind.\n",
      "\t\"My Wight the peten us.  Ack sud foring of Lidnedbe said fell his was said.\"\n",
      "\tBromemont, any said moten hansed the cack, thing r\n",
      "\n",
      "iter = 50000, smooth loss=1.7406182313906793\n",
      "seem his inder!\"\n",
      "\"Bulk not.\"\n",
      "Semung to clasmased thate in a wand what you couldn't had not turuled dow moling like and thonged fig all  \"Morded excited A dos'je seaps.  Tay they well for the sum t... \n",
      "\n",
      "iter = 55000, smooth loss=1.7400942858926884\n",
      "ough the Hogseann.\n",
      "\"\n",
      "\t\t\tHEVRELWE CUIRjo\"\n",
      "\t\t\tH'Gry, Ron yif head as the was ets down te sple-tofe of beaps to the Sorpiones Inggarge, claves of whend stranging at Malfoy odder-Eye sid your beft tarming\n",
      "\n",
      "iter = 60000, smooth loss=1.6570900147290422\n",
      "rt branks, dranseds seft toh,\" said Heaschouthingly to the Great Sovereing, imparastay, thad Harry, \"Harry, Pect in mulsed to Highaft of toven hering them hadd fightory try Fred Heglintinal.\"\n",
      "Bus leas\n",
      "\n",
      "iter = 65000, smooth loss=1.6353978855189364\n",
      "grunnted he was cengry how dost at tisely, you lookin, I'm to be \"isn't got eye give.  They -\"\n",
      "\"\n",
      "\"The glizence, ilaint...\n",
      "\"It emeyt-way not cuse to a learos abery looks Maxime her.  In'le get some her\n",
      "\n",
      "iter = 70000, smooth loss=1.6645123920043179\n",
      "ablevitrong, he pot winking he willow-Madame was helse find. . . It undan'   The very crobys.  Ron, \"nays he refty - Ron'w looked Heavy pose need to father and they something was heare brempes. . .  u\n",
      "\n",
      "iter = 75000, smooth loss=1.627707104976479\n",
      "adawal hope of sawpeared hein very nothed unto Harry cones I rrye Debbight of the cake downed ussack timple were lefted in that' he wast on a fir to had visully, wat beece to said ... dented afftagus \n",
      "\n",
      "iter = 80000, smooth loss=1.5827372992301751\n",
      "edressing intunce wize went to best him to sthair.\"\n",
      "\"Sourthing Dur-Ey restrosed behirrevorg, and sightles only bevouns alle was furfaring owl was paided to one frourward Ladse.  Harriad offsesont azd \n",
      "\n",
      "iter = 85000, smooth loss=1.5353013519617429\n",
      "r mhroun, the Darkinsvortadons,\" Harry.  As fept finking whither?\" ?\" still he was sous...\"\n",
      "\"It tower.  Winkmeened. . .\n",
      "\"No, \"He? said into his and the offed the bodd jumed firure Moody?\"\n",
      "\"Whetthe tor\n",
      "\n",
      "iter = 90000, smooth loss=1.6018125583197005\n",
      "y cament, Harry, Harry, fut him morn't ketticking to if ident wower or the kill for hick: the what; he was par, shruasufered as he about it could the Graff a been foic's for and he prent your's and my\n",
      "\n",
      "iter = 95000, smooth loss=1.6964546441341426\n",
      "GONE\n",
      "AF Iany,\" Bean!\"\n",
      "\"Ance cour. Ey dill Mr. Sincationing place instran! ... thim - in whistly to plair, you knawand rock impies to mighto that!\" squiztemeted, the The boy to that this winding as dia\n",
      "\n",
      "iter = 100000, smooth loss=1.6522417346657075\n",
      "le were grayt oren you're Delice that is incy is making tumed, I and Rourse, breater!\"\n",
      "Hermione hands of onty ton.  Arounder no sunder foure.  \"Pack.  Armass \"Yes wer, and Geoou, My Lory coult head, R\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print samples for the report\n",
    "for i, (iteration, text) in enumerate(zip(sample_iters, sample_texts)):\n",
    "    if i % 10 == 0 or i == 0:\n",
    "        print(f\"iter = {iteration}, smooth loss={loss_history[iteration-1]}\")\n",
    "        print(text)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skynet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
