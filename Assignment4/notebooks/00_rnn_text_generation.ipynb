{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Text Generation - Harry Potter and the Goblet of Fire\n",
    "\n",
    "This notebook implements a character-level Recurrent Neural Network (RNN) for text generation, trained on J.K. Rowling's \"Harry Potter and the Goblet of Fire\".\n",
    "\n",
    "## Theory: Character-level Language Models\n",
    "\n",
    "A character-level language model learns to predict the next character in a sequence given the previous characters. Unlike word-level models, character-level models:\n",
    "\n",
    "- Learn the structure of words and can generate new words\n",
    "- Have a smaller vocabulary (typically ~100 characters vs 50,000+ words)\n",
    "- Require more steps to generate meaningful content\n",
    "- Often capture interesting linguistic patterns at the character level\n",
    "\n",
    "RNNs are particularly well-suited for this task because they maintain an internal state (memory) that captures information about previous characters in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to path to import from src\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We start by loading the text data and preparing it for training. For character-level models, we:\n",
    "1. Read the entire text as a single string\n",
    "2. Create mappings between characters and their numerical indices\n",
    "3. These mappings allow us to convert between text and the one-hot encoded vectors the model uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book length: 1107542 characters\n",
      "Sample of the book:\n",
      "HARRY POTTER AND THE GOBLET OF FIRE\n",
      "\n",
      "CHAPTER ONE - THE RIDDLE HOUSE\n",
      "\n",
      "\tThe villagers of Little Hangleron still called it \"the Riddle House,\" even though it had been many years since the Riddle family had lived there.  It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face.  Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict, and un\n"
     ]
    }
   ],
   "source": [
    "from src.data import read_data, create_mappings\n",
    "\n",
    "# Read the book data\n",
    "book_fname = '../data/goblet_book.txt'\n",
    "book_data = read_data(book_fname)\n",
    "print(f\"Book length: {len(book_data)} characters\")\n",
    "\n",
    "# Print a sample of the book\n",
    "print(\"Sample of the book:\")\n",
    "print(book_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 80\n",
      "Unique characters: pl /bJg•TWMQ.NOr\n",
      "!zDwBk?üHS\",CIULY12^'jqs7ced}vmt:-\t64GfVE9h_oPZFn)Ku3yRx0A;(iaX\n"
     ]
    }
   ],
   "source": [
    "# Create character mappings\n",
    "char_to_ind, ind_to_char, unique_chars = create_mappings(book_data)\n",
    "K = len(unique_chars)\n",
    "print(f\"Number of unique characters: {K}\")\n",
    "print(\"Unique characters:\", ''.join(unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation\n",
    "\n",
    "### Theory: Vanilla RNN Architecture\n",
    "\n",
    "A vanilla RNN maintains a hidden state that gets updated at each time step. For character-level modeling:\n",
    "\n",
    "- At each step t, the model:\n",
    "  1. Takes the current character x_t and previous hidden state h_{t-1} as input\n",
    "  2. Updates its hidden state: h_t = tanh(W_hh·h_{t-1} + W_xh·x_t + b_h)\n",
    "  3. Outputs a probability distribution for the next character: y_t = softmax(W_hy·h_t + b_y)\n",
    "\n",
    "Where:\n",
    "- W_hh, W_xh, W_hy are weight matrices\n",
    "- b_h, b_y are bias vectors\n",
    "- tanh and softmax are activation functions\n",
    "\n",
    "The hidden state h_t serves as the model's \"memory\" of previous characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import init_rng\n",
    "from src.model import RNN\n",
    "\n",
    "# Set hyperparameters\n",
    "m = 100  # Hidden state dimension - controls model capacity\n",
    "seq_length = 25  # Sequence length for training - how many characters to process at once\n",
    "eta = 0.001  # Learning rate - controls step size during optimization\n",
    "\n",
    "# Initialize random number generator\n",
    "rng = init_rng(seed=400)\n",
    "\n",
    "# Initialize the RNN model\n",
    "model = RNN(K, m, rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Checking\n",
    "\n",
    "### Theory: Backpropagation Through Time (BPTT)\n",
    "\n",
    "Training RNNs involves backpropagation through time (BPTT), which is more complex than standard backpropagation:\n",
    "\n",
    "1. The error gradients flow backward through time steps\n",
    "2. This can lead to vanishing or exploding gradients in deep time sequences\n",
    "\n",
    "Gradient checking helps ensure our implementation of BPTT is correct by:\n",
    "1. Computing analytic gradients via backpropagation\n",
    "2. Computing numerical gradients via finite differences\n",
    "3. Comparing the two - they should be very close for a correct implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking analytic gradients vs numerical gradients...\n",
      "Computing numerical gradient for W...\n",
      "Computing numerical gradient for U...\n",
      "Computing numerical gradient for V...\n",
      "Computing numerical gradient for b...\n",
      "Computing numerical gradient for c...\n",
      "Relative error for W: 1.5874750795717744e-08\n",
      "Relative error for U: 8.145025625324182e-09\n",
      "Relative error for V: 6.724663509646973e-08\n",
      "Relative error for b: 5.034617589165875e-09\n",
      "Relative error for c: 6.414301922575067e-09\n",
      "Gradient check with numerical gradients: PASSED\n",
      "\n",
      "Checking analytic gradients vs PyTorch gradients...\n",
      "Relative error for W: 2.846327299207029e-16\n",
      "Relative error for U: 2.33578185067052e-16\n",
      "Relative error for V: 1.5238312972742825e-16\n",
      "Relative error for b: 1.0342003906995856e-16\n",
      "Relative error for c: 8.003079308789282e-17\n",
      "Gradient check with PyTorch: PASSED\n"
     ]
    }
   ],
   "source": [
    "from src.gradient_check import check_gradients, torch_gradient_check\n",
    "\n",
    "# Check analytic gradients against numerical gradients\n",
    "print(\"Checking analytic gradients vs numerical gradients...\")\n",
    "is_correct_num = check_gradients(book_data, char_to_ind)\n",
    "print(f\"Gradient check with numerical gradients: {'PASSED' if is_correct_num else 'FAILED'}\")\n",
    "\n",
    "# Check analytic gradients against PyTorch gradients\n",
    "print(\"\\nChecking analytic gradients vs PyTorch gradients...\")\n",
    "is_correct_torch = torch_gradient_check(book_data, char_to_ind)\n",
    "print(f\"Gradient check with PyTorch: {'PASSED' if is_correct_torch else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Generation from Untrained Model\n",
    "\n",
    "Before training, we'll generate some text from our randomly initialized model to see what it produces. This gives us a baseline to compare against after training.\n",
    "\n",
    "### Theory: Text Generation Process\n",
    "\n",
    "The text generation algorithm works as follows:\n",
    "\n",
    "1. Start with an initial character and hidden state\n",
    "2. For each step:\n",
    "   - Get the probability distribution for the next character\n",
    "   - Sample a character from this distribution\n",
    "   - Update the hidden state\n",
    "   - Use the sampled character as input for the next step\n",
    "\n",
    "With an untrained model, we expect completely random output with no meaningful patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text from untrained model...\n",
      "LO3v1oQy\"60c6sf69cLE_'JFlzZyktkj6T:^;wdR^vq1jBxJkMl.\"krwvu1\n",
      "zy!kpgxcErdRac_rkV^:x:AcxV91mRlKvi0Jdh0u,?OpMD_MWWwcHkt6\t•tQ )Eypc;v3qw f;_\"eu.mpupüAY(6apqxMk^nFm/iA-XQ:HJ\".DdUtüy-J1QGY.KXnDXpVqjJZk •co,6\n"
     ]
    }
   ],
   "source": [
    "# Generate text from untrained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1  # First character of the book\n",
    "\n",
    "print(\"Generating text from untrained model...\")\n",
    "untrained_text, _ = model.synthesize_text(h0, x0, 200, ind_to_char, char_to_ind, rng=rng)\n",
    "print(untrained_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model\n",
    "\n",
    "### Theory: Training RNNs\n",
    "\n",
    "Training involves:\n",
    "\n",
    "1. **Forward Pass**: Process a sequence of characters, computing loss at each step\n",
    "2. **Backward Pass**: Use BPTT to compute gradients of parameters\n",
    "3. **Parameter Update**: Apply gradients using a learning algorithm (e.g., AdaGrad)\n",
    "\n",
    "We'll use sequences of fixed length (`seq_length`) and compute the cross-entropy loss between predicted and actual next characters. The loss is smoothed over time to monitor training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 1000 iterations...\n",
      "Sample text at iteration 1:\n",
      "Z-!njzApa(.OZal\"Qru1K6F_sm3Z6/dN 43b•7/U2k,\t14cLüh1do91Q Y qsF•9jon1FW/uwBCBj)0bKP.E^vJbuyErHiyFhEaagoZe!tI/K3pFC4LHvu xnU_Uvwv\n",
      ":'K^Jxi.x6TgTPx/RnPUnh.d}_O'ü\tf9SiJ-MNhnJVFqQv/6/-T!p)BQ^?o2G:•YS.-x7lWD\n",
      "\n",
      "Sample text at iteration 1:\n",
      "Z-!njzApa(.OZal\"Qru1K6F_sm3Z6/dN 43b•7/U2k,\t14cLüh1do91Q Y qsF•9jon1FW/uwBCBj)0bKP.E^vJbuyErHiyFhEaagoZe!tI/K3pFC4LHvu xnU_Uvwv\n",
      ":'K^Jxi.x6TgTPx/RnPUnh.d}_O'ü\tf9SiJ-MNhnJVFqQv/6/-T!p)BQ^?o2G:•YS.-x7lWD\n",
      "\n",
      "iter = 100, smooth loss = 99.441714, time = 0.11s\n",
      "iter = 200, smooth loss = 90.260586, time = 0.21s\n",
      "iter = 300, smooth loss = 81.933952, time = 0.31s\n",
      "iter = 400, smooth loss = 74.388132, time = 0.41s\n",
      "iter = 500, smooth loss = 67.568333, time = 0.56s\n",
      "iter = 600, smooth loss = 61.390359, time = 0.66s\n",
      "iter = 700, smooth loss = 55.793188, time = 0.76s\n",
      "iter = 800, smooth loss = 50.713135, time = 0.86s\n",
      "iter = 900, smooth loss = 46.117589, time = 0.96s\n",
      "iter = 1000, smooth loss = 41.958036, time = 1.06s\n",
      "Sample text at iteration 1000:\n",
      "tkezwarebhen waicS peeb,dy bumted wad. ,bonhe k wnannhs\n",
      "Teinna.\n",
      ".onlurkudclelg thoutee sat. hidc hau....\t\"Aid toll dwrm  nle hou,.\n",
      "\tTIe ind an.  ico atmer sxwee bescte iol, w-illd anel.  ha tlerehlr.g\n",
      "\n",
      "Sample text at iteration 1000:\n",
      "tkezwarebhen waicS peeb,dy bumted wad. ,bonhe k wnannhs\n",
      "Teinna.\n",
      ".onlurkudclelg thoutee sat. hidc hau....\t\"Aid toll dwrm  nle hou,.\n",
      "\tTIe ind an.  ico atmer sxwee bescte iol, w-illd anel.  ha tlerehlr.g\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.train import train_rnn\n",
    "\n",
    "# Train for a small number of iterations to test\n",
    "num_updates = 1000\n",
    "print(f\"Training the model for {num_updates} iterations...\")\n",
    "loss_history, sample_texts, sample_iters = train_rnn(\n",
    "    model, book_data, char_to_ind, ind_to_char, \n",
    "    seq_length=seq_length, eta=eta, num_updates=num_updates, rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Generation from Trained Model\n",
    "\n",
    "After training, we generate text again to see what patterns the model has learned.\n",
    "The model should now produce text that resembles the training data in some way,\n",
    "showing that it has learned the statistical patterns of character sequences in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text from trained model...\n",
      "re thethe non pebe sore, siondynf rlleathedr, onettor mae wevee  ererrn;y the ehink. \n",
      "of tha.de\"s andeco.  Mror thithe, holy Le lond the de fedpyor.\n",
      "\t noumdFnlot eeth t, tnangisle berreronke thes addr\n"
     ]
    }
   ],
   "source": [
    "# Generate text from the trained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1  # First character of the book\n",
    "\n",
    "print(\"Generating text from trained model...\")\n",
    "trained_text, _ = model.synthesize_text(h0, x0, 200, ind_to_char, char_to_ind, rng=rng)\n",
    "print(trained_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experimenting with Different Sampling Strategies\n",
    "\n",
    "### Theory: Sampling Strategies\n",
    "\n",
    "The way we sample from the model's output distribution affects the generated text:\n",
    "\n",
    "1. **Greedy sampling**: Always pick the most likely next character (deterministic)\n",
    "   - Can get stuck in repetitive patterns\n",
    "\n",
    "2. **Temperature sampling**: Adjust the \"sharpness\" of the probability distribution\n",
    "   - T < 1: Makes the distribution more peaked (more conservative/deterministic)\n",
    "   - T > 1: Makes the distribution more uniform (more diverse/random)\n",
    "   - T = 1: Uses the raw model probabilities\n",
    "\n",
    "3. **Nucleus (top-p) sampling**: Sample from the smallest set of characters whose cumulative probability exceeds a threshold\n",
    "   - Controls diversity while maintaining coherence\n",
    "   - Avoids extremely unlikely outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with temperature sampling...\n",
      "\n",
      "Temperature = 0.2\n",
      "e he the the he the he he the he the the the he he the the he the he the he the he the he the he the he he the the he the the he he the he he he the he he the the he he he he the he he the the he he t\n",
      "\n",
      "Temperature = 0.5\n",
      "k beehed He the rathen toe core he be tid wice he  he nor he the ine he he he corld he the pe in, ban der he he he he the told bo mtind mathe the the wild ane ha been the mor the far and the couge cre\n",
      "\n",
      "Temperature = 1.0\n",
      "Wrmong,nd oo tl....\n",
      "\tHerneed ag s, mond t eo wneer\"ng- \"'gored whe neen. .Y ohe hane was onwis lasc ud ire fler..\n",
      "\t\"2m tle Ned hutiad  on tued he wowow neonle derogo theknoumbop nol n, loramead.P wird\n"
     ]
    }
   ],
   "source": [
    "# Generate text with temperature sampling\n",
    "print(\"Generating text with temperature sampling...\")\n",
    "for temperature in [0.2, 0.5, 1.0]:\n",
    "    print(f\"\\nTemperature = {temperature}\")\n",
    "    temp_text, _ = model.synthesize_text(\n",
    "        h0, x0, 200, ind_to_char, char_to_ind, \n",
    "        sampling_strategy='temperature', temperature=temperature, rng=rng\n",
    "    )\n",
    "    print(temp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with nucleus sampling...\n",
      "\n",
      "Theta = 0.5\n",
      "king the ha were told ared the ha s oure wan he hin the son hed the he the soided the the caide ce wild beer oret her ind ce his wane.. \t\"ere he coll wone the  and an hed an bed an he cat ard wo ceed \n",
      "\n",
      "Theta = 0.7\n",
      "toed ais bain tor wes ald he ald and war.. see inethe ha con nl be and cour.d an aroren bas. wan ile her seind cirim, toe bad cale colil the he mand han dot lo lldel s to hed he weod whe dile bong son\n",
      "\n",
      "Theta = 0.9\n",
      "breh. aighe ther faug yuther theme,.e whe  aal ho fored d cormed pring wo paldoemhes aas , an ipherer phed nimeid d suld wal,.\n",
      "\tFHal, ce coomdnasr io biace oled hhe ha wee hedore alt et and. thelad he\n"
     ]
    }
   ],
   "source": [
    "# Generate text with nucleus sampling\n",
    "print(\"Generating text with nucleus sampling...\")\n",
    "for theta in [0.5, 0.7, 0.9]:\n",
    "    print(f\"\\nTheta = {theta}\")\n",
    "    nucleus_text, _ = model.synthesize_text(\n",
    "        h0, x0, 200, ind_to_char, char_to_ind, \n",
    "        sampling_strategy='nucleus', theta=theta, rng=rng\n",
    "    )\n",
    "    print(nucleus_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Full Training (Optional)\n",
    "\n",
    "Now we'll train the model for a much larger number of iterations.\n",
    "As training progresses, we should see:\n",
    "\n",
    "1. The loss decreasing and stabilizing\n",
    "2. Generated text becoming more and more coherent\n",
    "3. The model learning character patterns, word structures, and eventually simple grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for 100000 iterations...\n",
      "Sample text at iteration 1:\n",
      "^-Am}oz07g(uJ;zciCLnBNE9JIZ•;YphGXbTü6t\tDzZB\"}ybDY;,SK1YQfwüpO1tW/4YZ-•MeKyZIW6;6v(J•1!lidG\n",
      ";CH!di\tV:k0gkRyAVd•Tmw4ekd1XY904I}GliVW2jC\n",
      "H_H2NE'0,(.sCEdD\"2.Aa:HyZWYrV9cEvss\n",
      "/fY0afzZsI)WüfwmRnfsjW;b\tec26\n",
      "\n",
      "Sample text at iteration 1:\n",
      "^-Am}oz07g(uJ;zciCLnBNE9JIZ•;YphGXbTü6t\tDzZB\"}ybDY;,SK1YQfwüpO1tW/4YZ-•MeKyZIW6;6v(J•1!lidG\n",
      ";CH!di\tV:k0gkRyAVd•Tmw4ekd1XY904I}GliVW2jC\n",
      "H_H2NE'0,(.sCEdD\"2.Aa:HyZWYrV9cEvss\n",
      "/fY0afzZsI)WüfwmRnfsjW;b\tec26\n",
      "\n",
      "iter = 100, smooth loss = 99.439723, time = 0.11s\n",
      "iter = 200, smooth loss = 90.261180, time = 0.21s\n",
      "iter = 300, smooth loss = 81.936725, time = 0.31s\n",
      "iter = 400, smooth loss = 74.391911, time = 0.41s\n",
      "iter = 500, smooth loss = 67.577158, time = 0.51s\n",
      "iter = 600, smooth loss = 61.400471, time = 0.61s\n",
      "iter = 700, smooth loss = 55.803467, time = 0.71s\n",
      "iter = 800, smooth loss = 50.724052, time = 0.81s\n",
      "iter = 900, smooth loss = 46.128805, time = 0.92s\n",
      "iter = 1000, smooth loss = 41.970084, time = 1.02s\n",
      "Sample text at iteration 1000:\n",
      "ted sorwaI \n",
      "hou)atp.  be eid, Sid hidngt srond bu,, !mis, oard wise oNmenlPact birlo cbem lop.nghelny Lod.onM seob wfalrinyerEe himkeatf ,rsdy on,mwa.,, Sr faee\n",
      "C It; \n",
      "e sied, opher corcm\tghe mheck c,\n",
      "\n",
      "Sample text at iteration 1000:\n",
      "ted sorwaI \n",
      "hou)atp.  be eid, Sid hidngt srond bu,, !mis, oard wise oNmenlPact birlo cbem lop.nghelny Lod.onM seob wfalrinyerEe himkeatf ,rsdy on,mwa.,, Sr faee\n",
      "C It; \n",
      "e sied, opher corcm\tghe mheck c,\n",
      "\n",
      "iter = 1100, smooth loss = 38.202217, time = 1.13s\n",
      "iter = 1200, smooth loss = 34.793735, time = 1.23s\n",
      "iter = 1300, smooth loss = 31.703122, time = 1.34s\n",
      "iter = 1400, smooth loss = 28.916650, time = 1.44s\n",
      "iter = 1500, smooth loss = 26.381563, time = 1.54s\n",
      "iter = 1600, smooth loss = 24.104210, time = 1.64s\n",
      "iter = 1700, smooth loss = 22.038738, time = 1.74s\n",
      "iter = 1800, smooth loss = 20.162177, time = 1.84s\n",
      "iter = 1900, smooth loss = 18.464213, time = 1.94s\n",
      "iter = 2000, smooth loss = 16.923014, time = 2.07s\n",
      "Sample text at iteration 2000:\n",
      "rels lif tilthe Unonk, bet hond lf tet anis Uos of fouldy s morett.\n",
      "\"\"T Undiy s ourl\" nave band aistediadr.\n",
      "\t\"has \"enpyn lornased Slo camefUickud pFwatd ihd th ourtder\n",
      "he Vlcyher.\"\n",
      "NHtiry logre Vorled\n",
      "\n",
      "Sample text at iteration 2000:\n",
      "rels lif tilthe Unonk, bet hond lf tet anis Uos of fouldy s morett.\n",
      "\"\"T Undiy s ourl\" nave band aistediadr.\n",
      "\t\"has \"enpyn lornased Slo camefUickud pFwatd ihd th ourtder\n",
      "he Vlcyher.\"\n",
      "NHtiry logre Vorled\n",
      "\n",
      "iter = 2100, smooth loss = 15.523829, time = 2.18s\n",
      "iter = 2200, smooth loss = 14.260976, time = 2.28s\n",
      "iter = 2300, smooth loss = 13.126640, time = 2.38s\n",
      "iter = 2400, smooth loss = 12.095432, time = 2.49s\n",
      "iter = 2500, smooth loss = 11.151251, time = 2.59s\n",
      "iter = 2600, smooth loss = 10.306391, time = 2.70s\n",
      "iter = 2700, smooth loss = 9.531967, time = 2.80s\n",
      "iter = 2800, smooth loss = 8.825420, time = 2.90s\n",
      "iter = 2900, smooth loss = 8.183525, time = 3.00s\n",
      "iter = 3000, smooth loss = 7.602017, time = 3.11s\n",
      "Sample text at iteration 3000:\n",
      "ard to! Mochind Mr. \"\"as ad is bats fompedound often thim the  of aimeve s arhit He.  I hele domeat ha s as at eet chun thoureI he thool tnihin\" I's kersingut ee stislen.  Harrense wand mathd en sfiyg\n",
      "\n",
      "Sample text at iteration 3000:\n",
      "ard to! Mochind Mr. \"\"as ad is bats fompedound often thim the  of aimeve s arhit He.  I hele domeat ha s as at eet chun thoureI he thool tnihin\" I's kersingut ee stislen.  Harrense wand mathd en sfiyg\n",
      "\n",
      "iter = 3100, smooth loss = 7.092818, time = 3.22s\n",
      "iter = 3200, smooth loss = 6.622175, time = 3.33s\n",
      "iter = 3300, smooth loss = 6.205236, time = 3.43s\n",
      "iter = 3400, smooth loss = 5.826278, time = 3.54s\n",
      "iter = 3500, smooth loss = 5.479859, time = 3.64s\n",
      "iter = 3600, smooth loss = 5.162015, time = 3.75s\n",
      "iter = 3700, smooth loss = 4.881625, time = 3.88s\n",
      "iter = 3800, smooth loss = 4.631392, time = 3.98s\n",
      "iter = 3900, smooth loss = 4.397346, time = 4.08s\n",
      "iter = 4000, smooth loss = 4.182443, time = 4.19s\n",
      "Sample text at iteration 4000:\n",
      "ny roo bout teen\" tet to towitthebe I tod cery, thed athes allound,\" they wiom topwe lalce king sEeryo thamkees besbrytg Harrce the  ar, -ilithe \"top jaing efead Harru kle, stomeond orlly's inloned as\n",
      "\n",
      "Sample text at iteration 4000:\n",
      "ny roo bout teen\" tet to towitthebe I tod cery, thed athes allound,\" they wiom topwe lalce king sEeryo thamkees besbrytg Harrce the  ar, -ilithe \"top jaing efead Harru kle, stomeond orlly's inloned as\n",
      "\n",
      "iter = 4100, smooth loss = 3.990901, time = 4.30s\n",
      "iter = 4200, smooth loss = 3.815415, time = 4.40s\n",
      "iter = 4300, smooth loss = 3.658720, time = 4.50s\n",
      "iter = 4400, smooth loss = 3.514182, time = 4.61s\n",
      "iter = 4500, smooth loss = 3.388817, time = 4.71s\n",
      "iter = 4600, smooth loss = 3.261860, time = 4.82s\n",
      "iter = 4700, smooth loss = 3.157258, time = 4.92s\n",
      "iter = 4800, smooth loss = 3.056146, time = 5.02s\n",
      "iter = 4900, smooth loss = 2.973523, time = 5.12s\n",
      "iter = 5000, smooth loss = 2.893825, time = 5.23s\n",
      "Sample text at iteration 5000:\n",
      "in deids at them,\" on then'e uriingr juppuriplirs?\" Mry'sqeat, thaked shouple Is ardy thene eavisgudras, \"nyayg neonve thiike the thet crouor of themulliscing ouvirniching wen, whald; of rraillacknte \n",
      "\n",
      "Sample text at iteration 5000:\n",
      "in deids at them,\" on then'e uriingr juppuriplirs?\" Mry'sqeat, thaked shouple Is ardy thene eavisgudras, \"nyayg neonve thiike the thet crouor of themulliscing ouvirniching wen, whald; of rraillacknte \n",
      "\n",
      "iter = 5100, smooth loss = 2.821745, time = 5.34s\n",
      "iter = 5200, smooth loss = 2.762483, time = 5.44s\n",
      "iter = 5300, smooth loss = 2.711120, time = 5.54s\n",
      "iter = 5400, smooth loss = 2.660205, time = 5.64s\n",
      "iter = 5500, smooth loss = 2.609215, time = 5.74s\n",
      "iter = 5600, smooth loss = 2.565026, time = 5.85s\n",
      "iter = 5700, smooth loss = 2.521823, time = 5.95s\n",
      "iter = 5800, smooth loss = 2.491928, time = 6.06s\n",
      "iter = 5900, smooth loss = 2.460303, time = 6.16s\n",
      "iter = 6000, smooth loss = 2.429493, time = 6.26s\n",
      "Sample text at iteration 6000:\n",
      "he rs timigfow Pertyey, ligmad tart!\"\n",
      "Bond tioused gowkern sear?\"\n",
      "\"She of liwenin and sof Herey, you to?\"\n",
      "\"A HiPstrou's ad and I ap oom his ol is ey alioked. rom an GThos he kit he meat on shimewey uw\n",
      "\n",
      "Sample text at iteration 6000:\n",
      "he rs timigfow Pertyey, ligmad tart!\"\n",
      "Bond tioused gowkern sear?\"\n",
      "\"She of liwenin and sof Herey, you to?\"\n",
      "\"A HiPstrou's ad and I ap oom his ol is ey alioked. rom an GThos he kit he meat on shimewey uw\n",
      "\n",
      "iter = 6100, smooth loss = 2.401674, time = 6.36s\n",
      "iter = 6200, smooth loss = 2.380453, time = 6.47s\n",
      "iter = 6300, smooth loss = 2.357235, time = 6.58s\n",
      "iter = 6400, smooth loss = 2.354650, time = 6.68s\n",
      "iter = 6500, smooth loss = 2.338528, time = 6.78s\n",
      "iter = 6600, smooth loss = 2.321793, time = 6.88s\n",
      "iter = 6700, smooth loss = 2.300570, time = 6.98s\n",
      "iter = 6800, smooth loss = 2.282685, time = 7.09s\n",
      "iter = 6900, smooth loss = 2.266103, time = 7.19s\n",
      "iter = 7000, smooth loss = 2.247014, time = 7.29s\n",
      "Sample text at iteration 7000:\n",
      "ritl wwpingow of luscos. an the shan.  bokovened yeppintesul ofotre lelleded, andind dis huld mack ly ferokel the Mreas Oy boist. . Helly!\" Kus ly;wistoridg avilgow, cam nhe lass woo; bast were Bsaie \n",
      "\n",
      "Sample text at iteration 7000:\n",
      "ritl wwpingow of luscos. an the shan.  bokovened yeppintesul ofotre lelleded, andind dis huld mack ly ferokel the Mreas Oy boist. . Helly!\" Kus ly;wistoridg avilgow, cam nhe lass woo; bast were Bsaie \n",
      "\n",
      "iter = 7100, smooth loss = 2.230931, time = 7.40s\n",
      "iter = 7200, smooth loss = 2.208684, time = 7.52s\n",
      "iter = 7300, smooth loss = 2.183035, time = 7.62s\n",
      "iter = 7400, smooth loss = 2.170243, time = 7.73s\n",
      "iter = 7500, smooth loss = 2.156428, time = 7.83s\n",
      "iter = 7600, smooth loss = 2.147234, time = 7.93s\n",
      "iter = 7700, smooth loss = 2.127936, time = 8.03s\n",
      "iter = 7800, smooth loss = 2.116241, time = 8.13s\n",
      "iter = 7900, smooth loss = 2.098138, time = 8.23s\n",
      "iter = 8000, smooth loss = 2.090236, time = 8.32s\n",
      "Sample text at iteration 8000:\n",
      "repsers, befringrrithed. \"Thing at to the Dimjorestrikn. Hetears. Whaving.  Mr. Der watch atg tpot thand a menobeanback. Mr. Mr. Weabley fos hinked him. \"ha dad west onf atoingo tuta tid heuppe iows. \n",
      "\n",
      "Sample text at iteration 8000:\n",
      "repsers, befringrrithed. \"Thing at to the Dimjorestrikn. Hetears. Whaving.  Mr. Der watch atg tpot thand a menobeanback. Mr. Mr. Weabley fos hinked him. \"ha dad west onf atoingo tuta tid heuppe iows. \n",
      "\n",
      "iter = 8100, smooth loss = 2.081739, time = 8.43s\n",
      "iter = 8200, smooth loss = 2.067958, time = 8.53s\n",
      "iter = 8300, smooth loss = 2.057815, time = 8.63s\n",
      "iter = 8400, smooth loss = 2.043068, time = 8.73s\n",
      "iter = 8500, smooth loss = 2.025277, time = 8.83s\n",
      "iter = 8600, smooth loss = 2.023116, time = 8.93s\n",
      "iter = 8700, smooth loss = 2.020729, time = 9.03s\n",
      "iter = 8800, smooth loss = 2.032270, time = 9.13s\n",
      "iter = 8900, smooth loss = 2.031912, time = 9.23s\n",
      "iter = 9000, smooth loss = 2.029836, time = 9.33s\n",
      "Sample text at iteration 9000:\n",
      "ug heneing?\"\n",
      "\"iny a in yormith of Hatry.  Its hot,\" . . waAc- fore ther to Dulhe  tulasidl theryon?\"\n",
      "veer stirmed the ploreertirun therearko thed,\" swirn.  Pookins.\n",
      "\"Selary'd sing the toGe labe t,\" sa\n",
      "\n",
      "Sample text at iteration 9000:\n",
      "ug heneing?\"\n",
      "\"iny a in yormith of Hatry.  Its hot,\" . . waAc- fore ther to Dulhe  tulasidl theryon?\"\n",
      "veer stirmed the ploreertirun therearko thed,\" swirn.  Pookins.\n",
      "\"Selary'd sing the toGe labe t,\" sa\n",
      "\n",
      "iter = 9100, smooth loss = 2.036919, time = 9.44s\n",
      "iter = 9200, smooth loss = 2.041608, time = 9.54s\n",
      "iter = 9300, smooth loss = 2.033435, time = 9.64s\n",
      "iter = 9400, smooth loss = 2.031135, time = 9.74s\n",
      "iter = 9500, smooth loss = 2.031419, time = 9.84s\n",
      "iter = 9600, smooth loss = 2.023104, time = 9.94s\n",
      "iter = 9700, smooth loss = 2.017635, time = 10.04s\n",
      "iter = 9800, smooth loss = 2.023404, time = 10.14s\n",
      "iter = 9900, smooth loss = 2.011925, time = 10.24s\n",
      "iter = 10000, smooth loss = 2.017065, time = 10.34s\n",
      "Sample text at iteration 10000:\n",
      "- om Did ly ow whe fas mats a cll?\"\n",
      "\"Bugl wat doune fine Cung a dedla treng of to picined eia seur vartsef emaks ank ele,\",\"\n",
      "'s Cometoly dobett,\" seaded ald acll treisly.  \"Mr.  hibe E wreald shane in\n",
      "\n",
      "Sample text at iteration 10000:\n",
      "- om Did ly ow whe fas mats a cll?\"\n",
      "\"Bugl wat doune fine Cung a dedla treng of to picined eia seur vartsef emaks ank ele,\",\"\n",
      "'s Cometoly dobett,\" seaded ald acll treisly.  \"Mr.  hibe E wreald shane in\n",
      "\n",
      "iter = 10100, smooth loss = 2.023220, time = 10.44s\n",
      "iter = 10200, smooth loss = 2.022035, time = 10.54s\n",
      "iter = 10300, smooth loss = 2.029282, time = 10.65s\n",
      "iter = 10400, smooth loss = 2.030985, time = 10.75s\n",
      "iter = 10500, smooth loss = 2.031601, time = 10.85s\n",
      "iter = 10600, smooth loss = 2.041831, time = 10.95s\n",
      "iter = 10700, smooth loss = 2.049263, time = 11.05s\n",
      "iter = 10800, smooth loss = 2.052686, time = 11.15s\n",
      "iter = 10900, smooth loss = 2.049210, time = 11.25s\n",
      "iter = 11000, smooth loss = 2.048608, time = 11.35s\n",
      "Sample text at iteration 11000:\n",
      "late keans apl an ahif be an Hmiwinga- Houlnofige the and in matNeversarsarlilrey leating on the soup his dos hurm.  nly sare.  Itith th thare.  Thel to the moaml yous og thall fuinta dey triingend He\n",
      "\n",
      "Sample text at iteration 11000:\n",
      "late keans apl an ahif be an Hmiwinga- Houlnofige the and in matNeversarsarlilrey leating on the soup his dos hurm.  nly sare.  Itith th thare.  Thel to the moaml yous og thall fuinta dey triingend He\n",
      "\n",
      "iter = 11100, smooth loss = 2.039426, time = 11.45s\n",
      "iter = 11200, smooth loss = 2.042425, time = 11.55s\n",
      "iter = 11300, smooth loss = 2.042213, time = 11.66s\n",
      "iter = 11400, smooth loss = 2.032018, time = 11.75s\n",
      "iter = 11500, smooth loss = 2.033861, time = 11.85s\n",
      "iter = 11600, smooth loss = 2.033825, time = 11.95s\n",
      "iter = 11700, smooth loss = 2.039871, time = 12.05s\n",
      "iter = 11800, smooth loss = 2.045575, time = 12.15s\n",
      "iter = 11900, smooth loss = 2.034940, time = 12.25s\n",
      "iter = 12000, smooth loss = 2.029995, time = 12.36s\n",
      "Sample text at iteration 12000:\n",
      "und was hid eruble.  nanke ublion, shan wandoss an was ladtly.  Pviry?\" ar out he ham ono floot u hay, Mrmiont.\"\n",
      "\"Gy ne chat Ron arly  an armering him had grast and thesuwhies an Profsled Lrouand. To \n",
      "\n",
      "Sample text at iteration 12000:\n",
      "und was hid eruble.  nanke ublion, shan wandoss an was ladtly.  Pviry?\" ar out he ham ono floot u hay, Mrmiont.\"\n",
      "\"Gy ne chat Ron arly  an armering him had grast and thesuwhies an Profsled Lrouand. To \n",
      "\n",
      "iter = 12100, smooth loss = 2.024707, time = 12.46s\n",
      "iter = 12200, smooth loss = 2.031628, time = 12.56s\n",
      "iter = 12300, smooth loss = 2.021582, time = 12.66s\n",
      "iter = 12400, smooth loss = 2.009691, time = 12.76s\n",
      "iter = 12500, smooth loss = 2.008698, time = 12.86s\n",
      "iter = 12600, smooth loss = 2.008574, time = 12.96s\n",
      "iter = 12700, smooth loss = 2.003694, time = 13.06s\n",
      "iter = 12800, smooth loss = 1.997321, time = 13.17s\n",
      "iter = 12900, smooth loss = 1.988725, time = 13.28s\n",
      "iter = 13000, smooth loss = 1.988869, time = 13.38s\n",
      "Sample text at iteration 13000:\n",
      "fl as the wallns. . . He. I've gringed councannes of raup d bsencare onn  Nets luck in fare hurver farmy.  Petle al the mally greits tou,\" she Culf caing dot coulss sn's m, brtimso I't mp ont op and h\n",
      "\n",
      "Sample text at iteration 13000:\n",
      "fl as the wallns. . . He. I've gringed councannes of raup d bsencare onn  Nets luck in fare hurver farmy.  Petle al the mally greits tou,\" she Culf caing dot coulss sn's m, brtimso I't mp ont op and h\n",
      "\n",
      "iter = 13100, smooth loss = 1.973136, time = 13.49s\n",
      "iter = 13200, smooth loss = 1.962036, time = 13.59s\n",
      "iter = 13300, smooth loss = 1.961994, time = 13.69s\n",
      "iter = 13400, smooth loss = 1.954836, time = 13.79s\n",
      "iter = 13500, smooth loss = 1.958149, time = 13.90s\n",
      "iter = 13600, smooth loss = 1.957203, time = 14.00s\n",
      "iter = 13700, smooth loss = 1.953883, time = 14.11s\n",
      "iter = 13800, smooth loss = 1.953417, time = 14.21s\n",
      "iter = 13900, smooth loss = 1.954860, time = 14.31s\n",
      "iter = 14000, smooth loss = 1.963139, time = 14.41s\n",
      "Sample text at iteration 14000:\n",
      "ly ly arrid bet me the acher commnrit!\"\n",
      "\"Moring gain wit, in agllld grantions. THadry 's in Ferished up cubull sollowey, whahin, wes path hthe his raf, Ron (it \"I win trenge bvofly trenarntign on up e\n",
      "\n",
      "Sample text at iteration 14000:\n",
      "ly ly arrid bet me the acher commnrit!\"\n",
      "\"Moring gain wit, in agllld grantions. THadry 's in Ferished up cubull sollowey, whahin, wes path hthe his raf, Ron (it \"I win trenge bvofly trenarntign on up e\n",
      "\n",
      "iter = 14100, smooth loss = 1.984284, time = 14.52s\n",
      "iter = 14200, smooth loss = 1.982646, time = 14.62s\n",
      "iter = 14300, smooth loss = 1.981286, time = 14.72s\n",
      "iter = 14400, smooth loss = 1.977044, time = 14.83s\n",
      "iter = 14500, smooth loss = 1.976971, time = 14.93s\n",
      "iter = 14600, smooth loss = 1.977448, time = 15.03s\n",
      "iter = 14700, smooth loss = 1.972336, time = 15.13s\n",
      "iter = 14800, smooth loss = 1.962514, time = 15.23s\n",
      "iter = 14900, smooth loss = 1.956302, time = 15.33s\n",
      "iter = 15000, smooth loss = 1.947719, time = 15.43s\n",
      "Sample text at iteration 15000:\n",
      ", and as enone llay umbind the aoplling at ank ortininglf clumbledone of ag in beck fustureato tlle, Durthey and midl he pered deend to Harry doowdorno lilking of the raldys Cenk atp atris hem's.  Dom\n",
      "\n",
      "Sample text at iteration 15000:\n",
      ", and as enone llay umbind the aoplling at ank ortininglf clumbledone of ag in beck fustureato tlle, Durthey and midl he pered deend to Harry doowdorno lilking of the raldys Cenk atp atris hem's.  Dom\n",
      "\n",
      "iter = 15100, smooth loss = 1.940485, time = 15.54s\n",
      "iter = 15200, smooth loss = 1.940247, time = 15.64s\n",
      "iter = 15300, smooth loss = 1.934456, time = 15.74s\n",
      "iter = 15400, smooth loss = 1.925827, time = 15.84s\n",
      "iter = 15500, smooth loss = 1.917053, time = 15.95s\n",
      "iter = 15600, smooth loss = 1.914891, time = 16.07s\n",
      "iter = 15700, smooth loss = 1.913753, time = 16.18s\n",
      "iter = 15800, smooth loss = 1.914474, time = 16.28s\n",
      "iter = 15900, smooth loss = 1.914604, time = 16.38s\n",
      "iter = 16000, smooth loss = 1.906586, time = 16.49s\n",
      "Sample text at iteration 16000:\n",
      "t ofingeamotoindw if of at ho tably wirny uld Harrig warrs byed hound Miding.  valy partipseale. \"I'd 're awwerotter terchound ther, whig tering. S\"It with thith willy to.  \"Ladde behing unaig treat H\n",
      "\n",
      "Sample text at iteration 16000:\n",
      "t ofingeamotoindw if of at ho tably wirny uld Harrig warrs byed hound Miding.  valy partipseale. \"I'd 're awwerotter terchound ther, whig tering. S\"It with thith willy to.  \"Ladde behing unaig treat H\n",
      "\n",
      "iter = 16100, smooth loss = 1.899601, time = 16.59s\n",
      "iter = 16200, smooth loss = 1.899193, time = 16.69s\n",
      "iter = 16300, smooth loss = 1.889331, time = 16.79s\n",
      "iter = 16400, smooth loss = 1.887369, time = 16.90s\n",
      "iter = 16500, smooth loss = 1.895821, time = 17.00s\n",
      "iter = 16600, smooth loss = 1.888755, time = 17.10s\n",
      "iter = 16700, smooth loss = 1.895593, time = 17.20s\n",
      "iter = 16800, smooth loss = 1.895956, time = 17.30s\n",
      "iter = 16900, smooth loss = 1.889905, time = 17.40s\n",
      "iter = 17000, smooth loss = 1.886156, time = 17.50s\n",
      "Sample text at iteration 17000:\n",
      "anen't whit dimnt ait Vokfare guther.  Her?  nowd he.  The for lerceslanted.; Baly pothead hindrof, than ealion, the firetaln Murty yould hak hee in whrs and extit nomsetare shis dood been heid herl h\n",
      "\n",
      "Sample text at iteration 17000:\n",
      "anen't whit dimnt ait Vokfare guther.  Her?  nowd he.  The for lerceslanted.; Baly pothead hindrof, than ealion, the firetaln Murty yould hak hee in whrs and extit nomsetare shis dood been heid herl h\n",
      "\n",
      "iter = 17100, smooth loss = 1.885717, time = 17.61s\n",
      "iter = 17200, smooth loss = 1.879336, time = 17.71s\n",
      "iter = 17300, smooth loss = 1.876793, time = 17.82s\n",
      "iter = 17400, smooth loss = 1.870947, time = 17.92s\n",
      "iter = 17500, smooth loss = 1.869568, time = 18.02s\n",
      "iter = 17600, smooth loss = 1.878141, time = 18.12s\n",
      "iter = 17700, smooth loss = 1.877579, time = 18.22s\n",
      "iter = 17800, smooth loss = 1.882773, time = 18.32s\n",
      "iter = 17900, smooth loss = 1.888524, time = 18.45s\n",
      "iter = 18000, smooth loss = 1.886323, time = 18.56s\n",
      "Sample text at iteration 18000:\n",
      "ng trough it sained.\n",
      "\t\t\"And acupiom, his fon to Gidn't buthers me to.  The the pall bewareanverely the warch, shin't suntl tos how she toy frembliof.  Tor at bathes at ostarge sone carmes.\n",
      "\"Yes med to\n",
      "\n",
      "Sample text at iteration 18000:\n",
      "ng trough it sained.\n",
      "\t\t\"And acupiom, his fon to Gidn't buthers me to.  The the pall bewareanverely the warch, shin't suntl tos how she toy frembliof.  Tor at bathes at ostarge sone carmes.\n",
      "\"Yes med to\n",
      "\n",
      "iter = 18100, smooth loss = 1.879685, time = 18.66s\n",
      "iter = 18200, smooth loss = 1.887904, time = 18.76s\n",
      "iter = 18300, smooth loss = 1.892078, time = 18.86s\n",
      "iter = 18400, smooth loss = 1.883023, time = 18.96s\n",
      "iter = 18500, smooth loss = 1.885844, time = 19.06s\n",
      "iter = 18600, smooth loss = 1.887359, time = 19.16s\n",
      "iter = 18700, smooth loss = 1.882743, time = 19.26s\n",
      "iter = 18800, smooth loss = 1.885770, time = 19.37s\n",
      "iter = 18900, smooth loss = 1.886748, time = 19.47s\n",
      "iter = 19000, smooth loss = 1.878818, time = 19.57s\n",
      "Sample text at iteration 19000:\n",
      " tusch offehing he to onabous all.\n",
      "\"Eos deenstherss righed of Harry seomber stoile on one eree fince hass, themp and eget if itaised't they sharly sacquire had edury sheprutes baw dinning he riscing H\n",
      "\n",
      "Sample text at iteration 19000:\n",
      " tusch offehing he to onabous all.\n",
      "\"Eos deenstherss righed of Harry seomber stoile on one eree fince hass, themp and eget if itaised't they sharly sacquire had edury sheprutes baw dinning he riscing H\n",
      "\n",
      "iter = 19100, smooth loss = 1.880613, time = 19.67s\n",
      "iter = 19200, smooth loss = 1.876845, time = 19.78s\n",
      "iter = 19300, smooth loss = 1.871918, time = 19.88s\n",
      "iter = 19400, smooth loss = 1.860882, time = 19.98s\n",
      "iter = 19500, smooth loss = 1.854526, time = 20.08s\n",
      "iter = 19600, smooth loss = 1.856506, time = 20.18s\n",
      "iter = 19700, smooth loss = 1.858348, time = 20.28s\n",
      "iter = 19800, smooth loss = 1.859282, time = 20.38s\n",
      "iter = 19900, smooth loss = 1.849161, time = 20.48s\n",
      "iter = 20000, smooth loss = 1.847007, time = 20.58s\n",
      "Sample text at iteration 20000:\n",
      "i.s Pettart abont Hagry uld in feched ach edereadly falkaing untaring to so had wormary thounging alk how in him, the fire aly intt bet them out. Tearth; and he hecrees ; a size bat withire wozaring t\n",
      "\n",
      "Sample text at iteration 20000:\n",
      "i.s Pettart abont Hagry uld in feched ach edereadly falkaing untaring to so had wormary thounging alk how in him, the fire aly intt bet them out. Tearth; and he hecrees ; a size bat withire wozaring t\n",
      "\n",
      "iter = 20100, smooth loss = 1.843467, time = 20.68s\n",
      "iter = 20200, smooth loss = 1.838727, time = 20.79s\n",
      "iter = 20300, smooth loss = 1.842610, time = 20.89s\n",
      "iter = 20400, smooth loss = 1.845224, time = 20.99s\n",
      "iter = 20500, smooth loss = 1.841229, time = 21.09s\n",
      "iter = 20600, smooth loss = 1.843670, time = 21.19s\n",
      "iter = 20700, smooth loss = 1.841919, time = 21.29s\n",
      "iter = 20800, smooth loss = 1.842041, time = 21.39s\n",
      "iter = 20900, smooth loss = 1.838283, time = 21.49s\n",
      "iter = 21000, smooth loss = 1.830444, time = 21.59s\n",
      "Sample text at iteration 21000:\n",
      "tike himester was owtere wh, anden - bu?\"  I've atre him.  How Hermione of moss fromess pliapess a sheed had Ron, fere think ao eare spale o, asver soid, looks, fide.\n",
      "Ha shan'iry, and Harry the lakn a\n",
      "\n",
      "Sample text at iteration 21000:\n",
      "tike himester was owtere wh, anden - bu?\"  I've atre him.  How Hermione of moss fromess pliapess a sheed had Ron, fere think ao eare spale o, asver soid, looks, fide.\n",
      "Ha shan'iry, and Harry the lakn a\n",
      "\n",
      "iter = 21100, smooth loss = 1.830240, time = 21.69s\n",
      "iter = 21200, smooth loss = 1.823183, time = 21.79s\n",
      "iter = 21300, smooth loss = 1.819914, time = 21.89s\n",
      "iter = 21400, smooth loss = 1.817902, time = 21.99s\n",
      "iter = 21500, smooth loss = 1.815091, time = 22.09s\n",
      "iter = 21600, smooth loss = 1.809512, time = 22.19s\n",
      "iter = 21700, smooth loss = 1.805737, time = 22.29s\n",
      "iter = 21800, smooth loss = 1.800338, time = 22.39s\n",
      "iter = 21900, smooth loss = 1.800700, time = 22.49s\n",
      "iter = 22000, smooth loss = 1.802003, time = 22.59s\n",
      "Sample text at iteration 22000:\n",
      "tel wank Beake wonay, Lels wooks. Thioks worlysu and hawd reand weating poffoouen of furnty une - ou the tood gainset worle had the deatothen he dowd it the sealing tall gricains of swourss.\"\n",
      "An't afo\n",
      "\n",
      "Sample text at iteration 22000:\n",
      "tel wank Beake wonay, Lels wooks. Thioks worlysu and hawd reand weating poffoouen of furnty une - ou the tood gainset worle had the deatothen he dowd it the sealing tall gricains of swourss.\"\n",
      "An't afo\n",
      "\n",
      "iter = 22100, smooth loss = 1.808721, time = 22.70s\n",
      "iter = 22200, smooth loss = 1.820564, time = 22.80s\n",
      "iter = 22300, smooth loss = 1.817826, time = 22.90s\n",
      "iter = 22400, smooth loss = 1.824578, time = 23.00s\n",
      "iter = 22500, smooth loss = 1.831266, time = 23.10s\n",
      "iter = 22600, smooth loss = 1.824969, time = 23.21s\n",
      "iter = 22700, smooth loss = 1.829230, time = 23.31s\n",
      "iter = 22800, smooth loss = 1.821574, time = 23.41s\n",
      "iter = 22900, smooth loss = 1.818162, time = 23.51s\n",
      "iter = 23000, smooth loss = 1.813277, time = 23.61s\n",
      "Sample text at iteration 23000:\n",
      " Dobby furdord dyen that she quiensment he mang be the purp they!  Whan't fucked of the mose in inbo thty us he smoked, Profes-on a hare do pobks chot Durushsing Propes -The eroured Mr. y ull just to,\n",
      "\n",
      "Sample text at iteration 23000:\n",
      " Dobby furdord dyen that she quiensment he mang be the purp they!  Whan't fucked of the mose in inbo thty us he smoked, Profes-on a hare do pobks chot Durushsing Propes -The eroured Mr. y ull just to,\n",
      "\n",
      "iter = 23100, smooth loss = 1.804181, time = 23.72s\n",
      "iter = 23200, smooth loss = 1.813930, time = 23.82s\n",
      "iter = 23300, smooth loss = 1.812693, time = 23.92s\n",
      "iter = 23400, smooth loss = 1.815231, time = 24.02s\n",
      "iter = 23500, smooth loss = 1.818141, time = 24.12s\n",
      "iter = 23600, smooth loss = 1.823824, time = 24.23s\n",
      "iter = 23700, smooth loss = 1.824075, time = 24.33s\n",
      "iter = 23800, smooth loss = 1.829553, time = 24.43s\n",
      "iter = 23900, smooth loss = 1.831119, time = 24.53s\n",
      "iter = 24000, smooth loss = 1.820220, time = 24.63s\n",
      "Sample text at iteration 24000:\n",
      "m of her? y s asted.  \"Powair, go\n",
      "beve porads - harping deom whin their with had, and thrick tadair do bacing it him said Hermaring to carwing to mes - ss soved do woplytone, bach no gain the Groun og\n",
      "\n",
      "Sample text at iteration 24000:\n",
      "m of her? y s asted.  \"Powair, go\n",
      "beve porads - harping deom whin their with had, and thrick tadair do bacing it him said Hermaring to carwing to mes - ss soved do woplytone, bach no gain the Groun og\n",
      "\n",
      "iter = 24100, smooth loss = 1.804285, time = 24.74s\n",
      "iter = 24200, smooth loss = 1.805253, time = 24.84s\n",
      "iter = 24300, smooth loss = 1.821235, time = 24.94s\n",
      "iter = 24400, smooth loss = 1.829057, time = 25.04s\n",
      "iter = 24500, smooth loss = 1.827391, time = 25.14s\n",
      "iter = 24600, smooth loss = 1.828135, time = 25.25s\n",
      "iter = 24700, smooth loss = 1.835850, time = 25.35s\n",
      "iter = 24800, smooth loss = 1.834981, time = 25.45s\n",
      "iter = 24900, smooth loss = 1.831756, time = 25.55s\n",
      "iter = 25000, smooth loss = 1.826011, time = 25.65s\n",
      "Sample text at iteration 25000:\n",
      "ing seelednty, the uidanon, and bevirgone edy santely look ith eame.  Ha'ry he'clusier\n",
      "Sne of the himaly oney trale and of the was whetenosurdlys.\n",
      "\"S at Krumbon Hall skald githyoug piss sisted.\n",
      "The si\n",
      "\n",
      "Sample text at iteration 25000:\n",
      "ing seelednty, the uidanon, and bevirgone edy santely look ith eame.  Ha'ry he'clusier\n",
      "Sne of the himaly oney trale and of the was whetenosurdlys.\n",
      "\"S at Krumbon Hall skald githyoug piss sisted.\n",
      "The si\n",
      "\n",
      "iter = 25100, smooth loss = 1.829922, time = 25.76s\n",
      "iter = 25200, smooth loss = 1.843015, time = 25.87s\n",
      "iter = 25300, smooth loss = 1.840020, time = 25.97s\n",
      "iter = 25400, smooth loss = 1.828759, time = 26.07s\n",
      "iter = 25500, smooth loss = 1.817888, time = 26.18s\n",
      "iter = 25600, smooth loss = 1.817228, time = 26.28s\n",
      "iter = 25700, smooth loss = 1.824540, time = 26.38s\n",
      "iter = 25800, smooth loss = 1.828094, time = 26.48s\n",
      "iter = 25900, smooth loss = 1.821935, time = 26.58s\n",
      "iter = 26000, smooth loss = 1.812922, time = 26.68s\n",
      "Sample text at iteration 26000:\n",
      "penide, she know dopbly ast hild he wilter vare a hal'll wither of, Rog to. kn with he. . . .\" said Karging at waich arr.\n",
      "\"Walking to we the mootre he with?\" . . . .\"\n",
      "\"Fou drack to th the stided to he\n",
      "\n",
      "Sample text at iteration 26000:\n",
      "penide, she know dopbly ast hild he wilter vare a hal'll wither of, Rog to. kn with he. . . .\" said Karging at waich arr.\n",
      "\"Walking to we the mootre he with?\" . . . .\"\n",
      "\"Fou drack to th the stided to he\n",
      "\n",
      "iter = 26100, smooth loss = 1.813762, time = 26.78s\n",
      "iter = 26200, smooth loss = 1.808681, time = 26.88s\n",
      "iter = 26300, smooth loss = 1.809116, time = 26.98s\n",
      "iter = 26400, smooth loss = 1.834729, time = 27.08s\n",
      "iter = 26500, smooth loss = 1.849813, time = 27.19s\n",
      "iter = 26600, smooth loss = 1.834672, time = 27.29s\n",
      "iter = 26700, smooth loss = 1.826171, time = 27.38s\n",
      "iter = 26800, smooth loss = 1.814807, time = 27.48s\n",
      "iter = 26900, smooth loss = 1.812624, time = 27.58s\n",
      "iter = 27000, smooth loss = 1.803946, time = 27.68s\n",
      "Sample text at iteration 27000:\n",
      " Ha Spriving rroukrid seidly.  He way eveng to come his mede flumbled at the coutcaice hart a wis inter, \"Krriuld ahoye.. Culing wank but tay he bed.  Bel(.\n",
      "\"Ror bath of ens sha here all heer but -\"\n",
      "\"\n",
      "\n",
      "Sample text at iteration 27000:\n",
      " Ha Spriving rroukrid seidly.  He way eveng to come his mede flumbled at the coutcaice hart a wis inter, \"Krriuld ahoye.. Culing wank but tay he bed.  Bel(.\n",
      "\"Ror bath of ens sha here all heer but -\"\n",
      "\"\n",
      "\n",
      "iter = 27100, smooth loss = 1.805134, time = 27.79s\n",
      "iter = 27200, smooth loss = 1.801236, time = 27.89s\n",
      "iter = 27300, smooth loss = 1.785668, time = 27.99s\n",
      "iter = 27400, smooth loss = 1.789712, time = 28.09s\n",
      "iter = 27500, smooth loss = 1.801479, time = 28.19s\n",
      "iter = 27600, smooth loss = 1.810187, time = 28.29s\n",
      "iter = 27700, smooth loss = 1.816028, time = 28.39s\n",
      "iter = 27800, smooth loss = 1.815767, time = 28.49s\n",
      "iter = 27900, smooth loss = 1.815919, time = 28.59s\n",
      "iter = 28000, smooth loss = 1.813994, time = 28.69s\n",
      "Sample text at iteration 28000:\n",
      ",\" said Harris sarm of her bathomen bean was peeced papeno shome nagy, \"No dowl a d.  A suddyou watned Myrtle?  I'lk. \"Mirtiated the Skest, My.\"\n",
      "Then utbin.\n",
      "\"Thin' seepeden, but you.  \"I bureldor gram\n",
      "\n",
      "Sample text at iteration 28000:\n",
      ",\" said Harris sarm of her bathomen bean was peeced papeno shome nagy, \"No dowl a d.  A suddyou watned Myrtle?  I'lk. \"Mirtiated the Skest, My.\"\n",
      "Then utbin.\n",
      "\"Thin' seepeden, but you.  \"I bureldor gram\n",
      "\n",
      "iter = 28100, smooth loss = 1.812640, time = 28.82s\n",
      "iter = 28200, smooth loss = 1.815156, time = 28.92s\n",
      "iter = 28300, smooth loss = 1.816625, time = 29.02s\n",
      "iter = 28400, smooth loss = 1.815520, time = 29.12s\n",
      "iter = 28500, smooth loss = 1.812630, time = 29.22s\n",
      "iter = 28600, smooth loss = 1.800546, time = 29.32s\n",
      "iter = 28700, smooth loss = 1.788301, time = 29.42s\n",
      "iter = 28800, smooth loss = 1.776709, time = 29.52s\n",
      "iter = 28900, smooth loss = 1.780699, time = 29.62s\n",
      "iter = 29000, smooth loss = 1.774612, time = 29.72s\n",
      "Sample text at iteration 29000:\n",
      "to dow mur?\"  She For Maxjusk sBared, Hermettinirg, bus Hopry wing. thume from on Hagrast, he's menow Harry bant into that a ging a sacp,\" Snemening her him a . . . . turlat.  Hermiones that thes hyat\n",
      "\n",
      "Sample text at iteration 29000:\n",
      "to dow mur?\"  She For Maxjusk sBared, Hermettinirg, bus Hopry wing. thume from on Hagrast, he's menow Harry bant into that a ging a sacp,\" Snemening her him a . . . . turlat.  Hermiones that thes hyat\n",
      "\n",
      "iter = 29100, smooth loss = 1.784327, time = 29.83s\n",
      "iter = 29200, smooth loss = 1.793755, time = 29.93s\n",
      "iter = 29300, smooth loss = 1.794441, time = 30.02s\n",
      "iter = 29400, smooth loss = 1.804665, time = 30.12s\n",
      "iter = 29500, smooth loss = 1.804600, time = 30.23s\n",
      "iter = 29600, smooth loss = 1.800328, time = 30.33s\n",
      "iter = 29700, smooth loss = 1.793254, time = 30.43s\n",
      "iter = 29800, smooth loss = 1.789995, time = 30.53s\n",
      "iter = 29900, smooth loss = 1.792725, time = 30.63s\n",
      "iter = 30000, smooth loss = 1.793462, time = 30.73s\n",
      "Sample text at iteration 30000:\n",
      "sper the vorg fatir.  Ye the washer ally on ha shay of the girer sen\"Whehe of thambo the laage afly of . . . ...\n",
      "He didne therorgss not viccull shrot over cnispe, an!  inter melenge s welzars weres,\n",
      "Y\n",
      "\n",
      "Sample text at iteration 30000:\n",
      "sper the vorg fatir.  Ye the washer ally on ha shay of the girer sen\"Whehe of thambo the laage afly of . . . ...\n",
      "He didne therorgss not viccull shrot over cnispe, an!  inter melenge s welzars weres,\n",
      "Y\n",
      "\n",
      "iter = 30100, smooth loss = 1.790366, time = 30.83s\n",
      "iter = 30200, smooth loss = 1.784621, time = 30.93s\n",
      "iter = 30300, smooth loss = 1.772854, time = 31.03s\n",
      "iter = 30400, smooth loss = 1.766649, time = 31.13s\n",
      "iter = 30500, smooth loss = 1.763590, time = 31.23s\n",
      "iter = 30600, smooth loss = 1.771421, time = 31.33s\n",
      "iter = 30700, smooth loss = 1.771717, time = 31.43s\n",
      "iter = 30800, smooth loss = 1.779588, time = 31.53s\n",
      "iter = 30900, smooth loss = 1.797386, time = 31.63s\n",
      "iter = 31000, smooth loss = 1.791389, time = 31.73s\n",
      "Sample text at iteration 31000:\n",
      "searly over peride ledder tny itsm to be ized Lowd teruld taster to starting atalking- Howeld, yeary ceclas the dissted awo hid Bagain?\"\n",
      "Snove whey very teatly yead Weom nos only thisk ho eturd kees b\n",
      "\n",
      "Sample text at iteration 31000:\n",
      "searly over peride ledder tny itsm to be ized Lowd teruld taster to starting atalking- Howeld, yeary ceclas the dissted awo hid Bagain?\"\n",
      "Snove whey very teatly yead Weom nos only thisk ho eturd kees b\n",
      "\n",
      "iter = 31100, smooth loss = 1.793147, time = 31.84s\n",
      "iter = 31200, smooth loss = 1.786893, time = 31.94s\n",
      "iter = 31300, smooth loss = 1.776967, time = 32.04s\n",
      "iter = 31400, smooth loss = 1.772270, time = 32.14s\n",
      "iter = 31500, smooth loss = 1.778189, time = 32.23s\n",
      "iter = 31600, smooth loss = 1.773393, time = 32.33s\n",
      "iter = 31700, smooth loss = 1.761918, time = 32.43s\n",
      "iter = 31800, smooth loss = 1.760080, time = 32.53s\n",
      "iter = 31900, smooth loss = 1.757966, time = 32.64s\n",
      "iter = 32000, smooth loss = 1.759227, time = 32.74s\n",
      "Sample text at iteration 32000:\n",
      "riaus. . then him boy him..\n",
      "\"That?\"  seid my had fin him sizibay neting it dadached buct's whink looks. I dear have cauld..\n",
      "There off in a deed toly whac the good a bagine clonged had benuncount oum, \n",
      "\n",
      "Sample text at iteration 32000:\n",
      "riaus. . then him boy him..\n",
      "\"That?\"  seid my had fin him sizibay neting it dadached buct's whink looks. I dear have cauld..\n",
      "There off in a deed toly whac the good a bagine clonged had benuncount oum, \n",
      "\n",
      "iter = 32100, smooth loss = 1.752958, time = 32.84s\n",
      "iter = 32200, smooth loss = 1.745929, time = 32.94s\n",
      "iter = 32300, smooth loss = 1.743706, time = 33.04s\n",
      "iter = 32400, smooth loss = 1.740437, time = 33.14s\n",
      "iter = 32500, smooth loss = 1.739477, time = 33.24s\n",
      "iter = 32600, smooth loss = 1.736645, time = 33.34s\n",
      "iter = 32700, smooth loss = 1.746490, time = 33.44s\n",
      "iter = 32800, smooth loss = 1.756914, time = 33.54s\n",
      "iter = 32900, smooth loss = 1.757601, time = 33.64s\n",
      "iter = 33000, smooth loss = 1.757575, time = 33.74s\n",
      "Sample text at iteration 33000:\n",
      "sh con the gell Iwar?\"  she lortlffor to stask her mage the eder uply thothald a diffftares,\" said Higmbasward to back towand Go staskild with, potsom.\"\n",
      "\n",
      "Wey comion, p(offf bout Hermione ooked, Itclet\n",
      "\n",
      "Sample text at iteration 33000:\n",
      "sh con the gell Iwar?\"  she lortlffor to stask her mage the eder uply thothald a diffftares,\" said Higmbasward to back towand Go staskild with, potsom.\"\n",
      "\n",
      "Wey comion, p(offf bout Hermione ooked, Itclet\n",
      "\n",
      "iter = 33100, smooth loss = 1.761509, time = 33.85s\n",
      "iter = 33200, smooth loss = 1.763733, time = 33.95s\n",
      "iter = 33300, smooth loss = 1.759778, time = 34.05s\n",
      "iter = 33400, smooth loss = 1.754965, time = 34.15s\n",
      "iter = 33500, smooth loss = 1.746136, time = 34.25s\n",
      "iter = 33600, smooth loss = 1.734397, time = 34.35s\n",
      "iter = 33700, smooth loss = 1.724576, time = 34.45s\n",
      "iter = 33800, smooth loss = 1.711770, time = 34.55s\n",
      "iter = 33900, smooth loss = 1.704490, time = 34.65s\n",
      "iter = 34000, smooth loss = 1.706796, time = 34.75s\n",
      "Sample text at iteration 34000:\n",
      "e sees said, anm leed tilke for with you'ble of ace he callio, ee,\" said Hagrid jumbred pain in here the ziglle!\" staidie, loobed to the to feated, Hagrid mew it anter, an'ted you to stable?\" said - H\n",
      "\n",
      "Sample text at iteration 34000:\n",
      "e sees said, anm leed tilke for with you'ble of ace he callio, ee,\" said Hagrid jumbred pain in here the ziglle!\" staidie, loobed to the to feated, Hagrid mew it anter, an'ted you to stable?\" said - H\n",
      "\n",
      "iter = 34100, smooth loss = 1.695870, time = 34.85s\n",
      "iter = 34200, smooth loss = 1.694340, time = 34.95s\n",
      "iter = 34300, smooth loss = 1.680844, time = 35.05s\n",
      "iter = 34400, smooth loss = 1.679223, time = 35.15s\n",
      "iter = 34500, smooth loss = 1.680041, time = 35.25s\n",
      "iter = 34600, smooth loss = 1.678748, time = 35.35s\n",
      "iter = 34700, smooth loss = 1.690454, time = 35.45s\n",
      "iter = 34800, smooth loss = 1.702236, time = 35.55s\n",
      "iter = 34900, smooth loss = 1.697427, time = 35.65s\n",
      "iter = 35000, smooth loss = 1.715051, time = 35.75s\n",
      "Sample text at iteration 35000:\n",
      "makaplatse Bagmbe!\"\n",
      "\"Co veryan paine;, I ne hapry looked and said I momenintcone the muld hissidg the even yffor. \"\n",
      "\"If to see this,\"  .  Profes, she was les wand to somean?\" said Hersierther had peam\n",
      "\n",
      "Sample text at iteration 35000:\n",
      "makaplatse Bagmbe!\"\n",
      "\"Co veryan paine;, I ne hapry looked and said I momenintcone the muld hissidg the even yffor. \"\n",
      "\"If to see this,\"  .  Profes, she was les wand to somean?\" said Hersierther had peam\n",
      "\n",
      "iter = 35100, smooth loss = 1.713200, time = 35.85s\n",
      "iter = 35200, smooth loss = 1.713279, time = 35.95s\n",
      "iter = 35300, smooth loss = 1.703830, time = 36.05s\n",
      "iter = 35400, smooth loss = 1.693047, time = 36.15s\n",
      "iter = 35500, smooth loss = 1.694706, time = 36.25s\n",
      "iter = 35600, smooth loss = 1.700435, time = 36.35s\n",
      "iter = 35700, smooth loss = 1.704101, time = 36.45s\n",
      "iter = 35800, smooth loss = 1.706064, time = 36.55s\n",
      "iter = 35900, smooth loss = 1.701430, time = 36.65s\n",
      "iter = 36000, smooth loss = 1.709775, time = 36.75s\n",
      "Sample text at iteration 36000:\n",
      "iog uf sagen of the not coundway-surting just tegly-drowher Cround out og!\"  she fore no kees on were's foren they disod rowed haxtement shyent of the pered made were being of whun of tighenc,\" botend\n",
      "\n",
      "Sample text at iteration 36000:\n",
      "iog uf sagen of the not coundway-surting just tegly-drowher Cround out og!\"  she fore no kees on were's foren they disod rowed haxtement shyent of the pered made were being of whun of tighenc,\" botend\n",
      "\n",
      "iter = 36100, smooth loss = 1.699339, time = 36.86s\n",
      "iter = 36200, smooth loss = 1.702523, time = 36.96s\n",
      "iter = 36300, smooth loss = 1.697338, time = 37.06s\n",
      "iter = 36400, smooth loss = 1.692113, time = 37.16s\n",
      "iter = 36500, smooth loss = 1.678924, time = 37.26s\n",
      "iter = 36600, smooth loss = 1.676089, time = 37.36s\n",
      "iter = 36700, smooth loss = 1.680564, time = 37.47s\n",
      "iter = 36800, smooth loss = 1.689265, time = 37.57s\n",
      "iter = 36900, smooth loss = 1.705945, time = 37.67s\n",
      "iter = 37000, smooth loss = 1.719944, time = 37.77s\n",
      "Sample text at iteration 37000:\n",
      "ed to could up what ...\n",
      "Sime was the piin of the gutin hewsirve, Harry sive serece.  se's shet, Mad he's aranterch ever Pigat offewid, whecke Manked there whicked however must wight was nark be with m\n",
      "\n",
      "Sample text at iteration 37000:\n",
      "ed to could up what ...\n",
      "Sime was the piin of the gutin hewsirve, Harry sive serece.  se's shet, Mad he's aranterch ever Pigat offewid, whecke Manked there whicked however must wight was nark be with m\n",
      "\n",
      "iter = 37100, smooth loss = 1.719398, time = 37.88s\n",
      "iter = 37200, smooth loss = 1.719416, time = 37.98s\n",
      "iter = 37300, smooth loss = 1.713600, time = 38.08s\n",
      "iter = 37400, smooth loss = 1.705189, time = 38.18s\n",
      "iter = 37500, smooth loss = 1.708177, time = 38.28s\n",
      "iter = 37600, smooth loss = 1.704078, time = 38.38s\n",
      "iter = 37700, smooth loss = 1.707545, time = 38.48s\n",
      "iter = 37800, smooth loss = 1.712004, time = 38.58s\n",
      "iter = 37900, smooth loss = 1.704171, time = 38.69s\n",
      "iter = 38000, smooth loss = 1.717847, time = 38.79s\n",
      "Sample text at iteration 38000:\n",
      "thong of, and that be st, Unamentes notheing, ancand it bear, whiched hinchengballd be miching was top to, shake in Mith the pays fils, staring.  The prended his light listry, peopleving tack his peal\n",
      "\n",
      "Sample text at iteration 38000:\n",
      "thong of, and that be st, Unamentes notheing, ancand it bear, whiched hinchengballd be miching was top to, shake in Mith the pays fils, staring.  The prended his light listry, peopleving tack his peal\n",
      "\n",
      "iter = 38100, smooth loss = 1.720956, time = 38.90s\n",
      "iter = 38200, smooth loss = 1.716603, time = 39.00s\n",
      "iter = 38300, smooth loss = 1.704099, time = 39.10s\n",
      "iter = 38400, smooth loss = 1.700491, time = 39.20s\n",
      "iter = 38500, smooth loss = 1.697723, time = 39.30s\n",
      "iter = 38600, smooth loss = 1.689887, time = 39.40s\n",
      "iter = 38700, smooth loss = 1.688781, time = 39.50s\n",
      "iter = 38800, smooth loss = 1.689569, time = 39.60s\n",
      "iter = 38900, smooth loss = 1.693086, time = 39.71s\n",
      "iter = 39000, smooth loss = 1.700587, time = 39.81s\n",
      "Sample text at iteration 39000:\n",
      "y armast, Cedric sabledory wat Hermits.\n",
      "Vold mighir.  He wal had tole the groless veed the was whis the cepscin upt with putced as Volderor; walld. in a browed id and said.  He and skeared priteves he\n",
      "\n",
      "Sample text at iteration 39000:\n",
      "y armast, Cedric sabledory wat Hermits.\n",
      "Vold mighir.  He wal had tole the groless veed the was whis the cepscin upt with putced as Volderor; walld. in a browed id and said.  He and skeared priteves he\n",
      "\n",
      "iter = 39100, smooth loss = 1.706251, time = 39.92s\n",
      "iter = 39200, smooth loss = 1.712476, time = 40.02s\n",
      "iter = 39300, smooth loss = 1.714083, time = 40.12s\n",
      "iter = 39400, smooth loss = 1.718060, time = 40.25s\n",
      "iter = 39500, smooth loss = 1.717667, time = 40.35s\n",
      "iter = 39600, smooth loss = 1.725280, time = 40.45s\n",
      "iter = 39700, smooth loss = 1.715132, time = 40.55s\n",
      "iter = 39800, smooth loss = 1.706300, time = 40.65s\n",
      "iter = 39900, smooth loss = 1.698286, time = 40.75s\n",
      "iter = 40000, smooth loss = 1.689597, time = 40.85s\n",
      "Sample text at iteration 40000:\n",
      "hrourd thet thet dair chillfed thes, that.  I mass - Hermiat me into that aplarted biggiculld pioming now bease? \"Harry were rears, didn't retchen Lome tere; I was oven, \"\n",
      "Eand and a pee ford how.  bo\n",
      "\n",
      "Sample text at iteration 40000:\n",
      "hrourd thet thet dair chillfed thes, that.  I mass - Hermiat me into that aplarted biggiculld pioming now bease? \"Harry were rears, didn't retchen Lome tere; I was oven, \"\n",
      "Eand and a pee ford how.  bo\n",
      "\n",
      "iter = 40100, smooth loss = 1.677075, time = 40.96s\n",
      "iter = 40200, smooth loss = 1.664335, time = 41.06s\n",
      "iter = 40300, smooth loss = 1.656528, time = 41.16s\n",
      "iter = 40400, smooth loss = 1.655717, time = 41.26s\n",
      "iter = 40500, smooth loss = 1.650221, time = 41.36s\n",
      "iter = 40600, smooth loss = 1.649608, time = 41.45s\n",
      "iter = 40700, smooth loss = 1.641828, time = 41.55s\n",
      "iter = 40800, smooth loss = 1.647557, time = 41.65s\n",
      "iter = 40900, smooth loss = 1.650811, time = 41.75s\n",
      "iter = 41000, smooth loss = 1.647566, time = 41.85s\n",
      "Sample text at iteration 41000:\n",
      "rouver you cumblined uncest handway.  The \"not usent so cound arel the wast, Dooy!  Scestiop, for PomJus rehenshing he Walkenw at offer into thearided was acte ontenticie.  \"Deitht?  He rounlinging ha\n",
      "\n",
      "Sample text at iteration 41000:\n",
      "rouver you cumblined uncest handway.  The \"not usent so cound arel the wast, Dooy!  Scestiop, for PomJus rehenshing he Walkenw at offer into thearided was acte ontenticie.  \"Deitht?  He rounlinging ha\n",
      "\n",
      "iter = 41100, smooth loss = 1.657064, time = 41.96s\n",
      "iter = 41200, smooth loss = 1.656676, time = 42.06s\n",
      "iter = 41300, smooth loss = 1.662851, time = 42.16s\n",
      "iter = 41400, smooth loss = 1.664794, time = 42.26s\n",
      "iter = 41500, smooth loss = 1.658431, time = 42.35s\n",
      "iter = 41600, smooth loss = 1.659497, time = 42.46s\n",
      "iter = 41700, smooth loss = 1.643670, time = 42.56s\n",
      "iter = 41800, smooth loss = 1.644992, time = 42.66s\n",
      "iter = 41900, smooth loss = 1.644871, time = 42.76s\n",
      "iter = 42000, smooth loss = 1.637770, time = 42.87s\n",
      "Sample text at iteration 42000:\n",
      "eill wited il golvertly he stoblice of tum.\n",
      "\"ne, ayfole ,\"I polpenily maress tiat, but the shaived went now.  He like bying he s?\" I was head mus - whed's elougon himself corct with murher howand sood\n",
      "\n",
      "Sample text at iteration 42000:\n",
      "eill wited il golvertly he stoblice of tum.\n",
      "\"ne, ayfole ,\"I polpenily maress tiat, but the shaived went now.  He like bying he s?\" I was head mus - whed's elougon himself corct with murher howand sood\n",
      "\n",
      "iter = 42100, smooth loss = 1.633546, time = 42.97s\n",
      "iter = 42200, smooth loss = 1.628109, time = 43.07s\n",
      "iter = 42300, smooth loss = 1.629961, time = 43.17s\n",
      "iter = 42400, smooth loss = 1.630708, time = 43.28s\n",
      "iter = 42500, smooth loss = 1.636527, time = 43.38s\n",
      "iter = 42600, smooth loss = 1.635740, time = 43.48s\n",
      "iter = 42700, smooth loss = 1.647514, time = 43.58s\n",
      "iter = 42800, smooth loss = 1.650720, time = 43.68s\n",
      "iter = 42900, smooth loss = 1.650427, time = 43.78s\n",
      "iter = 43000, smooth loss = 1.649914, time = 43.88s\n",
      "Sample text at iteration 43000:\n",
      "eion fees stays.  Dumbledore?  I knotem,\"\" said Dumbledore to the no ssnet would, what's FarjushL now, nours all ts been was not ofers. Ading the lorking for them,\" said DIdangs and be as Wolld.  \"You\n",
      "\n",
      "Sample text at iteration 43000:\n",
      "eion fees stays.  Dumbledore?  I knotem,\"\" said Dumbledore to the no ssnet would, what's FarjushL now, nours all ts been was not ofers. Ading the lorking for them,\" said DIdangs and be as Wolld.  \"You\n",
      "\n",
      "iter = 43100, smooth loss = 1.647327, time = 43.99s\n",
      "iter = 43200, smooth loss = 1.643747, time = 44.09s\n",
      "iter = 43300, smooth loss = 1.641052, time = 44.19s\n",
      "iter = 43400, smooth loss = 1.651833, time = 44.30s\n",
      "iter = 43500, smooth loss = 1.646929, time = 44.40s\n",
      "iter = 43600, smooth loss = 1.645391, time = 44.50s\n",
      "iter = 43700, smooth loss = 1.652903, time = 44.60s\n",
      "iter = 43800, smooth loss = 1.660483, time = 44.70s\n",
      "iter = 43900, smooth loss = 1.660205, time = 44.80s\n",
      "iter = 44000, smooth loss = 1.661241, time = 44.90s\n",
      "Sample text at iteration 44000:\n",
      "ile.\n",
      "\"Ry him intamion all cons of cotreaved, heres he was chembletened, ligsle themr for it oden tomble talk Lecill, shrite an curhand to at evererce that a sighed beepreofure thotes more been'llye.  \n",
      "\n",
      "Sample text at iteration 44000:\n",
      "ile.\n",
      "\"Ry him intamion all cons of cotreaved, heres he was chembletened, ligsle themr for it oden tomble talk Lecill, shrite an curhand to at evererce that a sighed beepreofure thotes more been'llye.  \n",
      "\n",
      "iter = 44100, smooth loss = 1.662467, time = 45.01s\n",
      "iter = 44200, smooth loss = 1.667374, time = 45.11s\n",
      "iter = 44300, smooth loss = 1.665434, time = 45.21s\n",
      "Completed epoch at iteration 44302\n",
      "iter = 44400, smooth loss = 1.692857, time = 45.31s\n",
      "iter = 44500, smooth loss = 1.701355, time = 45.41s\n",
      "iter = 44600, smooth loss = 1.704753, time = 45.51s\n",
      "iter = 44700, smooth loss = 1.700728, time = 45.61s\n",
      "iter = 44800, smooth loss = 1.705672, time = 45.71s\n",
      "iter = 44900, smooth loss = 1.710447, time = 45.81s\n",
      "iter = 45000, smooth loss = 1.709406, time = 45.91s\n",
      "Sample text at iteration 45000:\n",
      "at at oul mitthestell mutters wimd beft to goo he deeld!  So wang carm a fre would hok wald tood like more hes was proice wos don lought could me.\"  It of yoing fill he Vith?\"  say to whot of condine \n",
      "\n",
      "Sample text at iteration 45000:\n",
      "at at oul mitthestell mutters wimd beft to goo he deeld!  So wang carm a fre would hok wald tood like more hes was proice wos don lought could me.\"  It of yoing fill he Vith?\"  say to whot of condine \n",
      "\n",
      "iter = 45100, smooth loss = 1.708296, time = 46.02s\n",
      "iter = 45200, smooth loss = 1.700141, time = 46.12s\n",
      "iter = 45300, smooth loss = 1.698123, time = 46.22s\n",
      "iter = 45400, smooth loss = 1.696342, time = 46.32s\n",
      "iter = 45500, smooth loss = 1.692867, time = 46.42s\n",
      "iter = 45600, smooth loss = 1.688280, time = 46.52s\n",
      "iter = 45700, smooth loss = 1.693818, time = 46.62s\n",
      "iter = 45800, smooth loss = 1.690853, time = 46.72s\n",
      "iter = 45900, smooth loss = 1.711034, time = 46.83s\n",
      "iter = 46000, smooth loss = 1.725884, time = 46.93s\n",
      "Sample text at iteration 46000:\n",
      "eay.\"\n",
      "That saide a you's dadge that he reak befoy - bey fit settern in keem -- feat marr Prtions out that thoor all a the geve the gettaition in the cigars wa lerved; Profom awims out - firs had beaks\n",
      "\n",
      "Sample text at iteration 46000:\n",
      "eay.\"\n",
      "That saide a you's dadge that he reak befoy - bey fit settern in keem -- feat marr Prtions out that thoor all a the geve the gettaition in the cigars wa lerved; Profom awims out - firs had beaks\n",
      "\n",
      "iter = 46100, smooth loss = 1.727279, time = 47.03s\n",
      "iter = 46200, smooth loss = 1.728147, time = 47.13s\n",
      "iter = 46300, smooth loss = 1.721661, time = 47.23s\n",
      "iter = 46400, smooth loss = 1.714685, time = 47.34s\n",
      "iter = 46500, smooth loss = 1.711355, time = 47.44s\n",
      "iter = 46600, smooth loss = 1.723030, time = 47.54s\n",
      "iter = 46700, smooth loss = 1.722621, time = 47.64s\n",
      "iter = 46800, smooth loss = 1.719015, time = 47.74s\n",
      "iter = 46900, smooth loss = 1.722238, time = 47.84s\n",
      "iter = 47000, smooth loss = 1.712777, time = 47.94s\n",
      "Sample text at iteration 47000:\n",
      ", break ittige a loot lotiext bourGly, gondent skow uppaned the Dumbledone simens at thing so the and trreverssand that so and caseed, aude ferghine somesppottered to get his notered, puant fixnyering\n",
      "\n",
      "Sample text at iteration 47000:\n",
      ", break ittige a loot lotiext bourGly, gondent skow uppaned the Dumbledone simens at thing so the and trreverssand that so and caseed, aude ferghine somesppottered to get his notered, puant fixnyering\n",
      "\n",
      "iter = 47100, smooth loss = 1.701797, time = 48.04s\n",
      "iter = 47200, smooth loss = 1.690015, time = 48.14s\n",
      "iter = 47300, smooth loss = 1.683918, time = 48.24s\n",
      "iter = 47400, smooth loss = 1.690826, time = 48.34s\n",
      "iter = 47500, smooth loss = 1.684431, time = 48.44s\n",
      "iter = 47600, smooth loss = 1.690530, time = 48.54s\n",
      "iter = 47700, smooth loss = 1.695394, time = 48.64s\n",
      "iter = 47800, smooth loss = 1.692763, time = 48.74s\n",
      "iter = 47900, smooth loss = 1.693735, time = 48.84s\n",
      "iter = 48000, smooth loss = 1.700166, time = 48.94s\n",
      "Sample text at iteration 48000:\n",
      "epers,\" s. BRoth ather, Cy ford best Mrs. Pates rrimarranously Harry, deed ie goch makt to caming him to her spoint up the was jumirionn blooken mor.\"\n",
      "\"Tearess osser tlatch, have blo to I hix ow.  Sut\n",
      "\n",
      "Sample text at iteration 48000:\n",
      "epers,\" s. BRoth ather, Cy ford best Mrs. Pates rrimarranously Harry, deed ie goch makt to caming him to her spoint up the was jumirionn blooken mor.\"\n",
      "\"Tearess osser tlatch, have blo to I hix ow.  Sut\n",
      "\n",
      "iter = 48100, smooth loss = 1.708710, time = 49.05s\n",
      "iter = 48200, smooth loss = 1.708567, time = 49.15s\n",
      "iter = 48300, smooth loss = 1.703799, time = 49.25s\n",
      "iter = 48400, smooth loss = 1.705634, time = 49.35s\n",
      "iter = 48500, smooth loss = 1.706579, time = 49.45s\n",
      "iter = 48600, smooth loss = 1.707764, time = 49.55s\n",
      "iter = 48700, smooth loss = 1.708705, time = 49.65s\n",
      "iter = 48800, smooth loss = 1.718167, time = 49.75s\n",
      "iter = 48900, smooth loss = 1.713631, time = 49.85s\n",
      "iter = 49000, smooth loss = 1.718395, time = 49.95s\n",
      "Sample text at iteration 49000:\n",
      "aling ext very one apphther.\"\n",
      "Sit insompistion, this hard, the's a book for himpered them.  Simat dore?\"\n",
      "snow it from with her.  Mrons ad Magicl\n",
      "veat sark mosible.\"...\"\n",
      "Lood st.  He wal chut hampt sud\n",
      "\n",
      "Sample text at iteration 49000:\n",
      "aling ext very one apphther.\"\n",
      "Sit insompistion, this hard, the's a book for himpered them.  Simat dore?\"\n",
      "snow it from with her.  Mrons ad Magicl\n",
      "veat sark mosible.\"...\"\n",
      "Lood st.  He wal chut hampt sud\n",
      "\n",
      "iter = 49100, smooth loss = 1.719128, time = 50.05s\n",
      "iter = 49200, smooth loss = 1.724996, time = 50.15s\n",
      "iter = 49300, smooth loss = 1.726174, time = 50.25s\n",
      "iter = 49400, smooth loss = 1.727418, time = 50.35s\n",
      "iter = 49500, smooth loss = 1.736503, time = 50.45s\n",
      "iter = 49600, smooth loss = 1.743301, time = 50.55s\n",
      "iter = 49700, smooth loss = 1.745534, time = 50.65s\n",
      "iter = 49800, smooth loss = 1.745246, time = 50.75s\n",
      "iter = 49900, smooth loss = 1.748608, time = 50.85s\n",
      "iter = 50000, smooth loss = 1.746708, time = 50.95s\n",
      "Sample text at iteration 50000:\n",
      "seetes them?   He was aid als wach fineves and Geary, what the.  The nomeen my a smigh,\" said Harry themes, stulled angienatch been scoolst here hombed pheir plocking having of chuers all seed - they \n",
      "\n",
      "Sample text at iteration 50000:\n",
      "seetes them?   He was aid als wach fineves and Geary, what the.  The nomeen my a smigh,\" said Harry themes, stulled angienatch been scoolst here hombed pheir plocking having of chuers all seed - they \n",
      "\n",
      "iter = 50100, smooth loss = 1.755503, time = 51.05s\n",
      "iter = 50200, smooth loss = 1.750842, time = 51.15s\n",
      "iter = 50300, smooth loss = 1.747297, time = 51.25s\n",
      "iter = 50400, smooth loss = 1.745866, time = 51.35s\n",
      "iter = 50500, smooth loss = 1.752407, time = 51.45s\n",
      "iter = 50600, smooth loss = 1.756679, time = 51.55s\n",
      "iter = 50700, smooth loss = 1.780012, time = 51.65s\n",
      "iter = 50800, smooth loss = 1.787082, time = 51.75s\n",
      "iter = 50900, smooth loss = 1.786594, time = 51.85s\n",
      "iter = 51000, smooth loss = 1.780046, time = 51.96s\n",
      "Sample text at iteration 51000:\n",
      " his he semblets of the green out his pevew didning, and sod the outed a fing the Fimaume wothes at his suppenized imstwing there what laments porking chassing rebrying the Lod, Hewivy his and were as\n",
      "\n",
      "Sample text at iteration 51000:\n",
      " his he semblets of the green out his pevew didning, and sod the outed a fing the Fimaume wothes at his suppenized imstwing there what laments porking chassing rebrying the Lod, Hewivy his and were as\n",
      "\n",
      "iter = 51100, smooth loss = 1.775140, time = 52.06s\n",
      "iter = 51200, smooth loss = 1.773102, time = 52.16s\n",
      "iter = 51300, smooth loss = 1.762059, time = 52.26s\n",
      "iter = 51400, smooth loss = 1.758275, time = 52.36s\n",
      "iter = 51500, smooth loss = 1.749956, time = 52.46s\n",
      "iter = 51600, smooth loss = 1.732581, time = 52.56s\n",
      "iter = 51700, smooth loss = 1.726488, time = 52.66s\n",
      "iter = 51800, smooth loss = 1.721747, time = 52.76s\n",
      "iter = 51900, smooth loss = 1.722019, time = 52.86s\n",
      "iter = 52000, smooth loss = 1.709812, time = 52.96s\n",
      "Sample text at iteration 52000:\n",
      "saytsing the sact!\"\n",
      "\"Es glirbled on the mascrilly on hide they spore,\" said Ron.\n",
      "\"Thy only,\" said Voke the pask in squick cometise alar?\"\n",
      "They?\" salpoys it deat dick s,\" said Hel!\"  said Ron, Vood -\" \n",
      "\n",
      "Sample text at iteration 52000:\n",
      "saytsing the sact!\"\n",
      "\"Es glirbled on the mascrilly on hide they spore,\" said Ron.\n",
      "\"Thy only,\" said Voke the pask in squick cometise alar?\"\n",
      "They?\" salpoys it deat dick s,\" said Hel!\"  said Ron, Vood -\" \n",
      "\n",
      "iter = 52100, smooth loss = 1.704010, time = 53.06s\n",
      "iter = 52200, smooth loss = 1.692976, time = 53.16s\n",
      "iter = 52300, smooth loss = 1.687425, time = 53.26s\n",
      "iter = 52400, smooth loss = 1.683332, time = 53.37s\n",
      "iter = 52500, smooth loss = 1.676840, time = 53.47s\n",
      "iter = 52600, smooth loss = 1.672266, time = 53.57s\n",
      "iter = 52700, smooth loss = 1.663489, time = 53.66s\n",
      "iter = 52800, smooth loss = 1.651321, time = 53.76s\n",
      "iter = 52900, smooth loss = 1.645149, time = 53.86s\n",
      "iter = 53000, smooth loss = 1.644983, time = 53.96s\n",
      "Sample text at iteration 53000:\n",
      " thes patfon the or. We dark as he'l they dow Harrow been an it ten it tark to him them wize, aid veryes as the texate of his suppore, I sprint, in the Dark throus blife; is hear preating to part that\n",
      "\n",
      "Sample text at iteration 53000:\n",
      " thes patfon the or. We dark as he'l they dow Harrow been an it ten it tark to him them wize, aid veryes as the texate of his suppore, I sprint, in the Dark throus blife; is hear preating to part that\n",
      "\n",
      "iter = 53100, smooth loss = 1.658687, time = 54.09s\n",
      "iter = 53200, smooth loss = 1.667357, time = 54.19s\n",
      "iter = 53300, smooth loss = 1.665799, time = 54.29s\n",
      "iter = 53400, smooth loss = 1.674738, time = 54.39s\n",
      "iter = 53500, smooth loss = 1.685085, time = 54.49s\n",
      "iter = 53600, smooth loss = 1.682795, time = 54.59s\n",
      "iter = 53700, smooth loss = 1.685162, time = 54.69s\n",
      "iter = 53800, smooth loss = 1.684428, time = 54.79s\n",
      "iter = 53900, smooth loss = 1.679111, time = 54.89s\n",
      "iter = 54000, smooth loss = 1.674521, time = 54.99s\n",
      "Sample text at iteration 54000:\n",
      "ee tee norge to have chill times over the seot, Arrough boud.  \"Deatly clacked now, gotetes. . . I!\"  sime a teke?\" I'll be kill,  she soom, Youd be ond on a horrise.\"\n",
      "\"Whas -ent then yeass rebled to \n",
      "\n",
      "Sample text at iteration 54000:\n",
      "ee tee norge to have chill times over the seot, Arrough boud.  \"Deatly clacked now, gotetes. . . I!\"  sime a teke?\" I'll be kill,  she soom, Youd be ond on a horrise.\"\n",
      "\"Whas -ent then yeass rebled to \n",
      "\n",
      "iter = 54100, smooth loss = 1.687186, time = 55.09s\n",
      "iter = 54200, smooth loss = 1.677283, time = 55.19s\n",
      "iter = 54300, smooth loss = 1.683111, time = 55.29s\n",
      "iter = 54400, smooth loss = 1.693929, time = 55.39s\n",
      "iter = 54500, smooth loss = 1.696215, time = 55.49s\n",
      "iter = 54600, smooth loss = 1.705093, time = 55.59s\n",
      "iter = 54700, smooth loss = 1.711757, time = 55.69s\n",
      "iter = 54800, smooth loss = 1.711303, time = 55.79s\n",
      "iter = 54900, smooth loss = 1.725097, time = 55.89s\n",
      "iter = 55000, smooth loss = 1.737687, time = 55.99s\n",
      "Sample text at iteration 55000:\n",
      "oume\n",
      "Long as saaxing a brove, with the batwed the ceat-ell ttatters, we Grope, cillswly calloully, as he said, therr toobleded apperiagon winched and deears the Mast you're with it was glife torble si\n",
      "\n",
      "Sample text at iteration 55000:\n",
      "oume\n",
      "Long as saaxing a brove, with the batwed the ceat-ell ttatters, we Grope, cillswly calloully, as he said, therr toobleded apperiagon winched and deears the Mast you're with it was glife torble si\n",
      "\n",
      "iter = 55100, smooth loss = 1.743870, time = 56.09s\n",
      "iter = 55200, smooth loss = 1.743921, time = 56.19s\n",
      "iter = 55300, smooth loss = 1.749049, time = 56.29s\n",
      "iter = 55400, smooth loss = 1.736786, time = 56.39s\n",
      "iter = 55500, smooth loss = 1.738215, time = 56.49s\n",
      "iter = 55600, smooth loss = 1.735260, time = 56.59s\n",
      "iter = 55700, smooth loss = 1.725404, time = 56.69s\n",
      "iter = 55800, smooth loss = 1.730287, time = 56.79s\n",
      "iter = 55900, smooth loss = 1.730928, time = 56.89s\n",
      "iter = 56000, smooth loss = 1.741203, time = 57.02s\n",
      "Sample text at iteration 56000:\n",
      "lecory goonch Coamborting.  Mistom Shair deascam, it o chally cangeratul Franc stillutien too onto mo bes... bat looked of beloo turns and a strostcuddeporing thes laggen at thoig orert him, his onjor\n",
      "\n",
      "Sample text at iteration 56000:\n",
      "lecory goonch Coamborting.  Mistom Shair deascam, it o chally cangeratul Franc stillutien too onto mo bes... bat looked of beloo turns and a strostcuddeporing thes laggen at thoig orert him, his onjor\n",
      "\n",
      "iter = 56100, smooth loss = 1.752371, time = 57.13s\n",
      "iter = 56200, smooth loss = 1.746959, time = 57.23s\n",
      "iter = 56300, smooth loss = 1.746048, time = 57.33s\n",
      "iter = 56400, smooth loss = 1.745073, time = 57.43s\n",
      "iter = 56500, smooth loss = 1.752223, time = 57.52s\n",
      "iter = 56600, smooth loss = 1.742089, time = 57.62s\n",
      "iter = 56700, smooth loss = 1.726081, time = 57.73s\n",
      "iter = 56800, smooth loss = 1.724395, time = 57.84s\n",
      "iter = 56900, smooth loss = 1.727782, time = 57.94s\n",
      "iter = 57000, smooth loss = 1.726160, time = 58.05s\n",
      "Sample text at iteration 57000:\n",
      "verty got around with the pwedt was aroun, at thought,\" smime - betterd Duthy said langer. It.  The plicked in \"See like he dists elvest to berees, and serowed foor mave down mored astice dick icpodin\n",
      "\n",
      "Sample text at iteration 57000:\n",
      "verty got around with the pwedt was aroun, at thought,\" smime - betterd Duthy said langer. It.  The plicked in \"See like he dists elvest to berees, and serowed foor mave down mored astice dick icpodin\n",
      "\n",
      "iter = 57100, smooth loss = 1.720731, time = 58.15s\n",
      "iter = 57200, smooth loss = 1.713349, time = 58.25s\n",
      "iter = 57300, smooth loss = 1.715626, time = 58.35s\n",
      "iter = 57400, smooth loss = 1.701852, time = 58.45s\n",
      "iter = 57500, smooth loss = 1.691367, time = 58.55s\n",
      "iter = 57600, smooth loss = 1.694686, time = 58.65s\n",
      "iter = 57700, smooth loss = 1.688577, time = 58.75s\n",
      "iter = 57800, smooth loss = 1.696440, time = 58.85s\n",
      "iter = 57900, smooth loss = 1.692013, time = 58.95s\n",
      "iter = 58000, smooth loss = 1.693474, time = 59.05s\n",
      "Sample text at iteration 58000:\n",
      " aws was against offed high have sprette brown't fee tale Harry sof take his pisars.\n",
      "WHE ITry saty has squid I'd woote, \"Are specks of hid.  The was been snealing have rouslasulened HogFa geve so hich\n",
      "\n",
      "Sample text at iteration 58000:\n",
      " aws was against offed high have sprette brown't fee tale Harry sof take his pisars.\n",
      "WHE ITry saty has squid I'd woote, \"Are specks of hid.  The was been snealing have rouslasulened HogFa geve so hich\n",
      "\n",
      "iter = 58100, smooth loss = 1.695573, time = 59.15s\n",
      "iter = 58200, smooth loss = 1.694959, time = 59.26s\n",
      "iter = 58300, smooth loss = 1.707722, time = 59.36s\n",
      "iter = 58400, smooth loss = 1.725987, time = 59.46s\n",
      "iter = 58500, smooth loss = 1.725658, time = 59.56s\n",
      "iter = 58600, smooth loss = 1.727847, time = 59.67s\n",
      "iter = 58700, smooth loss = 1.721484, time = 59.77s\n",
      "iter = 58800, smooth loss = 1.721300, time = 59.87s\n",
      "iter = 58900, smooth loss = 1.723481, time = 59.97s\n",
      "iter = 59000, smooth loss = 1.718159, time = 60.07s\n",
      "Sample text at iteration 59000:\n",
      "ains up at a sure leaning to antess the furscinge and shemblatilll, scoosele to his pain. . . years' owleds, as kner he was bliaton their up hoplewly, Quideing boy stainngly werting, Mading in thanker\n",
      "\n",
      "Sample text at iteration 59000:\n",
      "ains up at a sure leaning to antess the furscinge and shemblatilll, scoosele to his pain. . . years' owleds, as kner he was bliaton their up hoplewly, Quideing boy stainngly werting, Mading in thanker\n",
      "\n",
      "iter = 59100, smooth loss = 1.714380, time = 60.18s\n",
      "iter = 59200, smooth loss = 1.704717, time = 60.28s\n",
      "iter = 59300, smooth loss = 1.694736, time = 60.38s\n",
      "iter = 59400, smooth loss = 1.688502, time = 60.48s\n",
      "iter = 59500, smooth loss = 1.684571, time = 60.58s\n",
      "iter = 59600, smooth loss = 1.680210, time = 60.68s\n",
      "iter = 59700, smooth loss = 1.672542, time = 60.78s\n",
      "iter = 59800, smooth loss = 1.660430, time = 60.88s\n",
      "iter = 59900, smooth loss = 1.659394, time = 60.98s\n",
      "iter = 60000, smooth loss = 1.659627, time = 61.08s\n",
      "Sample text at iteration 60000:\n",
      " uned a seew Rig the live.\n",
      "The than you about stains' was the risemess mum of sugget, stasn of the trunger aspang.\n",
      "\"Astletching theled, wing as Hermione in into the id to shags feet, and yeaget, then \n",
      "\n",
      "Sample text at iteration 60000:\n",
      " uned a seew Rig the live.\n",
      "The than you about stains' was the risemess mum of sugget, stasn of the trunger aspang.\n",
      "\"Astletching theled, wing as Hermione in into the id to shags feet, and yeaget, then \n",
      "\n",
      "iter = 60100, smooth loss = 1.663158, time = 61.19s\n",
      "iter = 60200, smooth loss = 1.668821, time = 61.29s\n",
      "iter = 60300, smooth loss = 1.660512, time = 61.39s\n",
      "iter = 60400, smooth loss = 1.651561, time = 61.49s\n",
      "iter = 60500, smooth loss = 1.650424, time = 61.59s\n",
      "iter = 60600, smooth loss = 1.637537, time = 61.69s\n",
      "iter = 60700, smooth loss = 1.634050, time = 61.79s\n",
      "iter = 60800, smooth loss = 1.641574, time = 61.89s\n",
      "iter = 60900, smooth loss = 1.633756, time = 61.99s\n",
      "iter = 61000, smooth loss = 1.640461, time = 62.09s\n",
      "Sample text at iteration 61000:\n",
      "t his fen you've be extree Pottenes.\n",
      "\"Thon't tus - sit in y force of Knum Profocard McGonarge off,\" said Chedrimes, \"Justrying Slattermatione uslet to kinse of the gromsed.  \"No's not's scat for in Fr\n",
      "\n",
      "Sample text at iteration 61000:\n",
      "t his fen you've be extree Pottenes.\n",
      "\"Thon't tus - sit in y force of Knum Profocard McGonarge off,\" said Chedrimes, \"Justrying Slattermatione uslet to kinse of the gromsed.  \"No's not's scat for in Fr\n",
      "\n",
      "iter = 61100, smooth loss = 1.643109, time = 62.20s\n",
      "iter = 61200, smooth loss = 1.637595, time = 62.30s\n",
      "iter = 61300, smooth loss = 1.632126, time = 62.40s\n",
      "iter = 61400, smooth loss = 1.634593, time = 62.50s\n",
      "iter = 61500, smooth loss = 1.631236, time = 62.60s\n",
      "iter = 61600, smooth loss = 1.629048, time = 62.70s\n",
      "iter = 61700, smooth loss = 1.625393, time = 62.80s\n",
      "iter = 61800, smooth loss = 1.623656, time = 62.90s\n",
      "iter = 61900, smooth loss = 1.633337, time = 63.00s\n",
      "iter = 62000, smooth loss = 1.638728, time = 63.10s\n",
      "Sample text at iteration 62000:\n",
      "e on the reat dearxed plinty of theng voincish!\"  op on them says fels hearving to Harry were smow.  A frost of swarts ears, sire scace-emong Harry?\"\n",
      "\"It'swed alter.\n",
      "\"I don't yeel nhey endered an it h\n",
      "\n",
      "Sample text at iteration 62000:\n",
      "e on the reat dearxed plinty of theng voincish!\"  op on them says fels hearving to Harry were smow.  A frost of swarts ears, sire scace-emong Harry?\"\n",
      "\"It'swed alter.\n",
      "\"I don't yeel nhey endered an it h\n",
      "\n",
      "iter = 62100, smooth loss = 1.643390, time = 63.20s\n",
      "iter = 62200, smooth loss = 1.652233, time = 63.30s\n",
      "iter = 62300, smooth loss = 1.654028, time = 63.40s\n",
      "iter = 62400, smooth loss = 1.649559, time = 63.50s\n",
      "iter = 62500, smooth loss = 1.657842, time = 63.60s\n",
      "iter = 62600, smooth loss = 1.663389, time = 63.70s\n",
      "iter = 62700, smooth loss = 1.653980, time = 63.80s\n",
      "iter = 62800, smooth loss = 1.659835, time = 63.90s\n",
      "iter = 62900, smooth loss = 1.664132, time = 64.00s\n",
      "iter = 63000, smooth loss = 1.663557, time = 64.10s\n",
      "Sample text at iteration 63000:\n",
      "ir mone act eever's becure cantle, and the repater?\" said Rit. Harry were Quidders feotto, his eoper through plitir, Rita Skeltered the jubbet triever.  The puntaress, anyther becknele about otr in fe\n",
      "\n",
      "Sample text at iteration 63000:\n",
      "ir mone act eever's becure cantle, and the repater?\" said Rit. Harry were Quidders feotto, his eoper through plitir, Rita Skeltered the jubbet triever.  The puntaress, anyther becknele about otr in fe\n",
      "\n",
      "iter = 63100, smooth loss = 1.666612, time = 64.21s\n",
      "iter = 63200, smooth loss = 1.670378, time = 64.31s\n",
      "iter = 63300, smooth loss = 1.665329, time = 64.41s\n",
      "iter = 63400, smooth loss = 1.667654, time = 64.51s\n",
      "iter = 63500, smooth loss = 1.664706, time = 64.61s\n",
      "iter = 63600, smooth loss = 1.661017, time = 64.71s\n",
      "iter = 63700, smooth loss = 1.651235, time = 64.81s\n",
      "iter = 63800, smooth loss = 1.646314, time = 64.91s\n",
      "iter = 63900, smooth loss = 1.652782, time = 65.00s\n",
      "iter = 64000, smooth loss = 1.657112, time = 65.10s\n",
      "Sample text at iteration 64000:\n",
      "g he wast hist!\" she wands biling a warch excloon looked appeners - rust a Skeeanly. I coons; whipping and Hagrid, watched with Moody wars was nowerato.\n",
      "\"And the drefter hersidge, the syin down which \n",
      "\n",
      "Sample text at iteration 64000:\n",
      "g he wast hist!\" she wands biling a warch excloon looked appeners - rust a Skeeanly. I coons; whipping and Hagrid, watched with Moody wars was nowerato.\n",
      "\"And the drefter hersidge, the syin down which \n",
      "\n",
      "iter = 64100, smooth loss = 1.658368, time = 65.21s\n",
      "iter = 64200, smooth loss = 1.648835, time = 65.31s\n",
      "iter = 64300, smooth loss = 1.642801, time = 65.41s\n",
      "iter = 64400, smooth loss = 1.636324, time = 65.51s\n",
      "iter = 64500, smooth loss = 1.631187, time = 65.61s\n",
      "iter = 64600, smooth loss = 1.636013, time = 65.71s\n",
      "iter = 64700, smooth loss = 1.639473, time = 65.81s\n",
      "iter = 64800, smooth loss = 1.631887, time = 65.92s\n",
      "iter = 64900, smooth loss = 1.634434, time = 66.02s\n",
      "iter = 65000, smooth loss = 1.636315, time = 66.12s\n",
      "Sample text at iteration 65000:\n",
      "on yould I very ncally gass, wondent what it enterted an ideas bepy ut fued les.  They had you because the out to that,\"Seersy twong to in tigh toble he back treer in the firse sey.  Are I'd that wo k\n",
      "\n",
      "Sample text at iteration 65000:\n",
      "on yould I very ncally gass, wondent what it enterted an ideas bepy ut fued les.  They had you because the out to that,\"Seersy twong to in tigh toble he back treer in the firse sey.  Are I'd that wo k\n",
      "\n",
      "iter = 65100, smooth loss = 1.637592, time = 66.22s\n",
      "iter = 65200, smooth loss = 1.634229, time = 66.32s\n",
      "iter = 65300, smooth loss = 1.628468, time = 66.42s\n",
      "iter = 65400, smooth loss = 1.630310, time = 66.52s\n",
      "iter = 65500, smooth loss = 1.627429, time = 66.62s\n",
      "iter = 65600, smooth loss = 1.626865, time = 66.72s\n",
      "iter = 65700, smooth loss = 1.623864, time = 66.82s\n",
      "iter = 65800, smooth loss = 1.624008, time = 66.92s\n",
      "iter = 65900, smooth loss = 1.620045, time = 67.02s\n",
      "iter = 66000, smooth loss = 1.619646, time = 67.12s\n",
      "Sample text at iteration 66000:\n",
      "ddred you pankly she sick one - out one, you knew to to onp thing it.\n",
      "The was reed that the aid. .  The manger nown spranted thrughine the way flimbled eyound ell.  \"Down for again. \n",
      "\"Vert out of Fili\n",
      "\n",
      "Sample text at iteration 66000:\n",
      "ddred you pankly she sick one - out one, you knew to to onp thing it.\n",
      "The was reed that the aid. .  The manger nown spranted thrughine the way flimbled eyound ell.  \"Down for again. \n",
      "\"Vert out of Fili\n",
      "\n",
      "iter = 66100, smooth loss = 1.614078, time = 67.23s\n",
      "iter = 66200, smooth loss = 1.611671, time = 67.33s\n",
      "iter = 66300, smooth loss = 1.613042, time = 67.43s\n",
      "iter = 66400, smooth loss = 1.620760, time = 67.53s\n",
      "iter = 66500, smooth loss = 1.636682, time = 67.63s\n",
      "iter = 66600, smooth loss = 1.636562, time = 67.73s\n",
      "iter = 66700, smooth loss = 1.644249, time = 67.83s\n",
      "iter = 66800, smooth loss = 1.653552, time = 67.93s\n",
      "iter = 66900, smooth loss = 1.647530, time = 68.03s\n",
      "iter = 67000, smooth loss = 1.652116, time = 68.13s\n",
      "Sample text at iteration 67000:\n",
      "ed palled as feich thished, and one tenirst\n",
      "Dumbledere all the clothed up itched lessing tore?\"\n",
      "Harry said exbloss, as seized toge, asker, green be nistlasow an kides of that Harry wath showed the was\n",
      "\n",
      "Sample text at iteration 67000:\n",
      "ed palled as feich thished, and one tenirst\n",
      "Dumbledere all the clothed up itched lessing tore?\"\n",
      "Harry said exbloss, as seized toge, asker, green be nistlasow an kides of that Harry wath showed the was\n",
      "\n",
      "iter = 67100, smooth loss = 1.644869, time = 68.24s\n",
      "iter = 67200, smooth loss = 1.640203, time = 68.33s\n",
      "iter = 67300, smooth loss = 1.634827, time = 68.43s\n",
      "iter = 67400, smooth loss = 1.625227, time = 68.56s\n",
      "iter = 67500, smooth loss = 1.634598, time = 68.66s\n",
      "iter = 67600, smooth loss = 1.633574, time = 68.75s\n",
      "iter = 67700, smooth loss = 1.635405, time = 68.85s\n",
      "iter = 67800, smooth loss = 1.638368, time = 68.95s\n",
      "iter = 67900, smooth loss = 1.647259, time = 69.05s\n",
      "iter = 68000, smooth loss = 1.648369, time = 69.15s\n",
      "Sample text at iteration 68000:\n",
      ", long ous you?\"\n",
      "\"Be-jeathed.\n",
      "\"Les,\" sought Ron?\"\n",
      "\"Norge?\"\n",
      "Gitained aboun, you?\"\n",
      "\"Now from a finds fron't Fred it had govess.\n",
      "\"But that Ske that mose table?\"  Fleased dole morf thanting what as not, a\n",
      "\n",
      "Sample text at iteration 68000:\n",
      ", long ous you?\"\n",
      "\"Be-jeathed.\n",
      "\"Les,\" sought Ron?\"\n",
      "\"Norge?\"\n",
      "Gitained aboun, you?\"\n",
      "\"Now from a finds fron't Fred it had govess.\n",
      "\"But that Ske that mose table?\"  Fleased dole morf thanting what as not, a\n",
      "\n",
      "iter = 68100, smooth loss = 1.653710, time = 69.26s\n",
      "iter = 68200, smooth loss = 1.658959, time = 69.36s\n",
      "iter = 68300, smooth loss = 1.648725, time = 69.45s\n",
      "iter = 68400, smooth loss = 1.632187, time = 69.55s\n",
      "iter = 68500, smooth loss = 1.633127, time = 69.65s\n",
      "iter = 68600, smooth loss = 1.643095, time = 69.75s\n",
      "iter = 68700, smooth loss = 1.652269, time = 69.85s\n",
      "iter = 68800, smooth loss = 1.651862, time = 69.95s\n",
      "iter = 68900, smooth loss = 1.654451, time = 70.05s\n",
      "iter = 69000, smooth loss = 1.663204, time = 70.16s\n",
      "Sample text at iteration 69000:\n",
      "igh pone the endriource.\n",
      "\"The lood, rethenscon soces not, there's digging the intours, thry don't eroust tare with re loodd on the stuppry for what corred him, back,\" Ron, a hald soubse, now slcest.  \n",
      "\n",
      "Sample text at iteration 69000:\n",
      "igh pone the endriource.\n",
      "\"The lood, rethenscon soces not, there's digging the intours, thry don't eroust tare with re loodd on the stuppry for what corred him, back,\" Ron, a hald soubse, now slcest.  \n",
      "\n",
      "iter = 69100, smooth loss = 1.663052, time = 70.27s\n",
      "iter = 69200, smooth loss = 1.659071, time = 70.37s\n",
      "iter = 69300, smooth loss = 1.653878, time = 70.47s\n",
      "iter = 69400, smooth loss = 1.659393, time = 70.57s\n",
      "iter = 69500, smooth loss = 1.675314, time = 70.67s\n",
      "iter = 69600, smooth loss = 1.670790, time = 70.77s\n",
      "iter = 69700, smooth loss = 1.660686, time = 70.87s\n",
      "iter = 69800, smooth loss = 1.652739, time = 70.97s\n",
      "iter = 69900, smooth loss = 1.652986, time = 71.07s\n",
      "iter = 70000, smooth loss = 1.660455, time = 71.17s\n",
      "Sample text at iteration 70000:\n",
      "iruch's air.  Whthe really coll be a gone.\n",
      "\"Devel sor from Kauxin't hoden histots singiring you rage agan, Her, Professo patter Kurracougo beally.\n",
      "At Ker!\"\n",
      "Parvati.  Ron coom Marmowing they winding ex\n",
      "\n",
      "Sample text at iteration 70000:\n",
      "iruch's air.  Whthe really coll be a gone.\n",
      "\"Devel sor from Kauxin't hoden histots singiring you rage agan, Her, Professo patter Kurracougo beally.\n",
      "At Ker!\"\n",
      "Parvati.  Ron coom Marmowing they winding ex\n",
      "\n",
      "iter = 70100, smooth loss = 1.664599, time = 71.27s\n",
      "iter = 70200, smooth loss = 1.659352, time = 71.37s\n",
      "iter = 70300, smooth loss = 1.650026, time = 71.47s\n",
      "iter = 70400, smooth loss = 1.652798, time = 71.57s\n",
      "iter = 70500, smooth loss = 1.646902, time = 71.67s\n",
      "iter = 70600, smooth loss = 1.646866, time = 71.77s\n",
      "iter = 70700, smooth loss = 1.671467, time = 71.87s\n",
      "iter = 70800, smooth loss = 1.689105, time = 71.97s\n",
      "iter = 70900, smooth loss = 1.674746, time = 72.07s\n",
      "iter = 71000, smooth loss = 1.665635, time = 72.17s\n",
      "Sample text at iteration 71000:\n",
      "ss treany wosef conntille what onrid up and hadn, and the suching alterse wand a conchemew it, reaching that around though. \"Krugred a crently him got weid adget and the intoos spacked to the attered \n",
      "\n",
      "Sample text at iteration 71000:\n",
      "ss treany wosef conntille what onrid up and hadn, and the suching alterse wand a conchemew it, reaching that around though. \"Krugred a crently him got weid adget and the intoos spacked to the attered \n",
      "\n",
      "iter = 71100, smooth loss = 1.656190, time = 72.28s\n",
      "iter = 71200, smooth loss = 1.653595, time = 72.38s\n",
      "iter = 71300, smooth loss = 1.646947, time = 72.48s\n",
      "iter = 71400, smooth loss = 1.649813, time = 72.58s\n",
      "iter = 71500, smooth loss = 1.647373, time = 72.67s\n",
      "iter = 71600, smooth loss = 1.634633, time = 72.77s\n",
      "iter = 71700, smooth loss = 1.639289, time = 72.87s\n",
      "iter = 71800, smooth loss = 1.653590, time = 72.97s\n",
      "iter = 71900, smooth loss = 1.660936, time = 73.07s\n",
      "iter = 72000, smooth loss = 1.666937, time = 73.17s\n",
      "Sample text at iteration 72000:\n",
      "ll exarting a sent nite her was it, a reself,\" said Maxilr quide being eggr.  IS who dood.\n",
      "\"It, quite abouttattly will bet would ba sulfted Harry had lence file his fareed saffered that look, my not c\n",
      "\n",
      "Sample text at iteration 72000:\n",
      "ll exarting a sent nite her was it, a reself,\" said Maxilr quide being eggr.  IS who dood.\n",
      "\"It, quite abouttattly will bet would ba sulfted Harry had lence file his fareed saffered that look, my not c\n",
      "\n",
      "iter = 72100, smooth loss = 1.668112, time = 73.28s\n",
      "iter = 72200, smooth loss = 1.670518, time = 73.38s\n",
      "iter = 72300, smooth loss = 1.668806, time = 73.48s\n",
      "iter = 72400, smooth loss = 1.668867, time = 73.58s\n",
      "iter = 72500, smooth loss = 1.671515, time = 73.69s\n",
      "iter = 72600, smooth loss = 1.671106, time = 73.78s\n",
      "iter = 72700, smooth loss = 1.667222, time = 73.89s\n",
      "iter = 72800, smooth loss = 1.663590, time = 73.99s\n",
      "iter = 72900, smooth loss = 1.652277, time = 74.09s\n",
      "iter = 73000, smooth loss = 1.637957, time = 74.19s\n",
      "Sample text at iteration 73000:\n",
      " sout Mast's me?\" sort, Harry. Poris,\" said Harry.\n",
      "Hordy tapk to Moody erint that herion wompory any.\n",
      "\"You?\"\n",
      "\"Cotes... wit sainingind how they'sing Snapes.\n",
      "THarnis \"g. . . you said. \"Lyed.  \"He missin\n",
      "\n",
      "Sample text at iteration 73000:\n",
      " sout Mast's me?\" sort, Harry. Poris,\" said Harry.\n",
      "Hordy tapk to Moody erint that herion wompory any.\n",
      "\"You?\"\n",
      "\"Cotes... wit sainingind how they'sing Snapes.\n",
      "THarnis \"g. . . you said. \"Lyed.  \"He missin\n",
      "\n",
      "iter = 73100, smooth loss = 1.627583, time = 74.29s\n",
      "iter = 73200, smooth loss = 1.628433, time = 74.39s\n",
      "iter = 73300, smooth loss = 1.623901, time = 74.50s\n",
      "iter = 73400, smooth loss = 1.632979, time = 74.60s\n",
      "iter = 73500, smooth loss = 1.642378, time = 74.70s\n",
      "iter = 73600, smooth loss = 1.645187, time = 74.80s\n",
      "iter = 73700, smooth loss = 1.656593, time = 74.90s\n",
      "iter = 73800, smooth loss = 1.656593, time = 75.00s\n",
      "iter = 73900, smooth loss = 1.652470, time = 75.09s\n",
      "iter = 74000, smooth loss = 1.643853, time = 75.19s\n",
      "Sample text at iteration 74000:\n",
      "th Harry.  Hirss s,\" Madgat sat mickn from Krum Pargaty about at the dair, groothe Dudb-c, star, Won in the upost he stare sarulive bidn't ment, his - bur you neared applated, waten in digh reture. \"T\n",
      "\n",
      "Sample text at iteration 74000:\n",
      "th Harry.  Hirss s,\" Madgat sat mickn from Krum Pargaty about at the dair, groothe Dudb-c, star, Won in the upost he stare sarulive bidn't ment, his - bur you neared applated, waten in digh reture. \"T\n",
      "\n",
      "iter = 74100, smooth loss = 1.639695, time = 75.30s\n",
      "iter = 74200, smooth loss = 1.645310, time = 75.40s\n",
      "iter = 74300, smooth loss = 1.648757, time = 75.50s\n",
      "iter = 74400, smooth loss = 1.649125, time = 75.60s\n",
      "iter = 74500, smooth loss = 1.644609, time = 75.70s\n",
      "iter = 74600, smooth loss = 1.632095, time = 75.80s\n",
      "iter = 74700, smooth loss = 1.623006, time = 75.91s\n",
      "iter = 74800, smooth loss = 1.621113, time = 76.00s\n",
      "iter = 74900, smooth loss = 1.629174, time = 76.11s\n",
      "iter = 75000, smooth loss = 1.630218, time = 76.21s\n",
      "Sample text at iteration 75000:\n",
      "ven and it was was just are awore tassere fact, Pottying I down buf Hermione has time to capsees outtile, subpring warted to Roghre.  Outhis were to Lad hare's guldes verledys of the their mos, and qu\n",
      "\n",
      "Sample text at iteration 75000:\n",
      "ven and it was was just are awore tassere fact, Pottying I down buf Hermione has time to capsees outtile, subpring warted to Roghre.  Outhis were to Lad hare's guldes verledys of the their mos, and qu\n",
      "\n",
      "iter = 75100, smooth loss = 1.638910, time = 76.31s\n",
      "iter = 75200, smooth loss = 1.658216, time = 76.41s\n",
      "iter = 75300, smooth loss = 1.651747, time = 76.51s\n",
      "iter = 75400, smooth loss = 1.653017, time = 76.61s\n",
      "iter = 75500, smooth loss = 1.649503, time = 76.71s\n",
      "iter = 75600, smooth loss = 1.640427, time = 76.81s\n",
      "iter = 75700, smooth loss = 1.638957, time = 76.91s\n",
      "iter = 75800, smooth loss = 1.646002, time = 77.01s\n",
      "iter = 75900, smooth loss = 1.642574, time = 77.11s\n",
      "iter = 76000, smooth loss = 1.630436, time = 77.21s\n",
      "Sample text at iteration 76000:\n",
      "l not over you?\"  \"\n",
      "It was closetch wars.  Hermed hous, was abother bot off cometayf him quinger he wask that Rons was ely fincus, hack.\n",
      "\"If Ron want Sirions. So tone left low a thelt heer off had he \n",
      "\n",
      "Sample text at iteration 76000:\n",
      "l not over you?\"  \"\n",
      "It was closetch wars.  Hermed hous, was abother bot off cometayf him quinger he wask that Rons was ely fincus, hack.\n",
      "\"If Ron want Sirions. So tone left low a thelt heer off had he \n",
      "\n",
      "iter = 76100, smooth loss = 1.626368, time = 77.32s\n",
      "iter = 76200, smooth loss = 1.623681, time = 77.42s\n",
      "iter = 76300, smooth loss = 1.624663, time = 77.52s\n",
      "iter = 76400, smooth loss = 1.617292, time = 77.62s\n",
      "iter = 76500, smooth loss = 1.609853, time = 77.72s\n",
      "iter = 76600, smooth loss = 1.607146, time = 77.82s\n",
      "iter = 76700, smooth loss = 1.604849, time = 77.92s\n",
      "iter = 76800, smooth loss = 1.606654, time = 78.02s\n",
      "iter = 76900, smooth loss = 1.604735, time = 78.12s\n",
      "iter = 77000, smooth loss = 1.613717, time = 78.22s\n",
      "Sample text at iteration 77000:\n",
      "he cap?\"\n",
      "\"Oh!\" Paky some pleo, oldo but's were My.  \"Harry, she hear conlys Werkong to Priptien the off they grat the gribbe them ling tean senn you look out Ofraring to Hermigring doparge hals, livav\n",
      "\n",
      "Sample text at iteration 77000:\n",
      "he cap?\"\n",
      "\"Oh!\" Paky some pleo, oldo but's were My.  \"Harry, she hear conlys Werkong to Priptien the off they grat the gribbe them ling tean senn you look out Ofraring to Hermigring doparge hals, livav\n",
      "\n",
      "iter = 77100, smooth loss = 1.625577, time = 78.32s\n",
      "iter = 77200, smooth loss = 1.627967, time = 78.42s\n",
      "iter = 77300, smooth loss = 1.629176, time = 78.52s\n",
      "iter = 77400, smooth loss = 1.633538, time = 78.63s\n",
      "iter = 77500, smooth loss = 1.633685, time = 78.73s\n",
      "iter = 77600, smooth loss = 1.631904, time = 78.83s\n",
      "iter = 77700, smooth loss = 1.628853, time = 78.93s\n",
      "iter = 77800, smooth loss = 1.621091, time = 79.03s\n",
      "iter = 77900, smooth loss = 1.607297, time = 79.16s\n",
      "iter = 78000, smooth loss = 1.595699, time = 79.27s\n",
      "Sample text at iteration 78000:\n",
      "ele. ene?\"  now sudd't to he's -\"\n",
      "Fhere swistlect've just -\"\n",
      "The was to tho woods potching stand you, she was whet dorightun to to - he'll - thront sligitly, sint into to to houth - he said he see -\"\n",
      "\n",
      "\n",
      "Sample text at iteration 78000:\n",
      "ele. ene?\"  now sudd't to he's -\"\n",
      "Fhere swistlect've just -\"\n",
      "The was to tho woods potching stand you, she was whet dorightun to to - he'll - thront sligitly, sint into to to houth - he said he see -\"\n",
      "\n",
      "\n",
      "iter = 78100, smooth loss = 1.579579, time = 79.38s\n",
      "iter = 78200, smooth loss = 1.574199, time = 79.48s\n",
      "iter = 78300, smooth loss = 1.578858, time = 79.57s\n",
      "iter = 78400, smooth loss = 1.567276, time = 79.68s\n",
      "iter = 78500, smooth loss = 1.564589, time = 79.78s\n",
      "iter = 78600, smooth loss = 1.551929, time = 79.88s\n",
      "iter = 78700, smooth loss = 1.550116, time = 79.98s\n",
      "iter = 78800, smooth loss = 1.553019, time = 80.08s\n",
      "iter = 78900, smooth loss = 1.552949, time = 80.18s\n",
      "iter = 79000, smooth loss = 1.564244, time = 80.28s\n",
      "Sample text at iteration 79000:\n",
      "chursienot close. . . - Snep were head fires to shot for his way Dumbledore. . Durve it in you gell ow you knip wriongeres out.  Just swan retalestearghen were invarges blasking tearly forgeing out of\n",
      "\n",
      "Sample text at iteration 79000:\n",
      "chursienot close. . . - Snep were head fires to shot for his way Dumbledore. . Durve it in you gell ow you knip wriongeres out.  Just swan retalestearghen were invarges blasking tearly forgeing out of\n",
      "\n",
      "iter = 79100, smooth loss = 1.578049, time = 80.38s\n",
      "iter = 79200, smooth loss = 1.573962, time = 80.48s\n",
      "iter = 79300, smooth loss = 1.591421, time = 80.58s\n",
      "iter = 79400, smooth loss = 1.589733, time = 80.68s\n",
      "iter = 79500, smooth loss = 1.590963, time = 80.78s\n",
      "iter = 79600, smooth loss = 1.582948, time = 80.88s\n",
      "iter = 79700, smooth loss = 1.572646, time = 80.98s\n",
      "iter = 79800, smooth loss = 1.574841, time = 81.08s\n",
      "iter = 79900, smooth loss = 1.582382, time = 81.18s\n",
      "iter = 80000, smooth loss = 1.584714, time = 81.28s\n",
      "Sample text at iteration 80000:\n",
      " me their was asly wall. Ron't will wouldn't she neverth aroff; Alkime of large whic.  Hagrine: . . . theyend?  Nothally frokend thes could supfen his swaved, very spillight was thispering elly; his v\n",
      "\n",
      "Sample text at iteration 80000:\n",
      " me their was asly wall. Ron't will wouldn't she neverth aroff; Alkime of large whic.  Hagrine: . . . theyend?  Nothally frokend thes could supfen his swaved, very spillight was thispering elly; his v\n",
      "\n",
      "iter = 80100, smooth loss = 1.585330, time = 81.38s\n",
      "iter = 80200, smooth loss = 1.580862, time = 81.48s\n",
      "iter = 80300, smooth loss = 1.588950, time = 81.59s\n",
      "iter = 80400, smooth loss = 1.577842, time = 81.69s\n",
      "iter = 80500, smooth loss = 1.581955, time = 81.79s\n",
      "iter = 80600, smooth loss = 1.573721, time = 81.88s\n",
      "iter = 80700, smooth loss = 1.566385, time = 81.99s\n",
      "iter = 80800, smooth loss = 1.555440, time = 82.09s\n",
      "iter = 80900, smooth loss = 1.551025, time = 82.19s\n",
      "iter = 81000, smooth loss = 1.554239, time = 82.28s\n",
      "Sample text at iteration 81000:\n",
      "oker were agair.\n",
      "\"Dumbledore' and this is, penaie. a Crought,\" said Harry.\n",
      "The would thinmiey pidened it was founonmed on and cancet for inso tower Dollion- about about agriase of the his moon refly i\n",
      "\n",
      "Sample text at iteration 81000:\n",
      "oker were agair.\n",
      "\"Dumbledore' and this is, penaie. a Crought,\" said Harry.\n",
      "The would thinmiey pidened it was founonmed on and cancet for inso tower Dollion- about about agriase of the his moon refly i\n",
      "\n",
      "iter = 81100, smooth loss = 1.565524, time = 82.39s\n",
      "iter = 81200, smooth loss = 1.582701, time = 82.49s\n",
      "iter = 81300, smooth loss = 1.598480, time = 82.59s\n",
      "iter = 81400, smooth loss = 1.598446, time = 82.69s\n",
      "iter = 81500, smooth loss = 1.598205, time = 82.79s\n",
      "iter = 81600, smooth loss = 1.592060, time = 82.89s\n",
      "iter = 81700, smooth loss = 1.584262, time = 82.99s\n",
      "iter = 81800, smooth loss = 1.586100, time = 83.08s\n",
      "iter = 81900, smooth loss = 1.584170, time = 83.18s\n",
      "iter = 82000, smooth loss = 1.589785, time = 83.28s\n",
      "Sample text at iteration 82000:\n",
      "lassed to her coudse ellegs of to befile a themmes to all trouch head of the DArass her had gars; he cassand he wark.\n",
      "We all that whister to sengery, Profestle. The clus-ally palehter, and Momm!\" said\n",
      "\n",
      "Sample text at iteration 82000:\n",
      "lassed to her coudse ellegs of to befile a themmes to all trouch head of the DArass her had gars; he cassand he wark.\n",
      "We all that whister to sengery, Profestle. The clus-ally palehter, and Momm!\" said\n",
      "\n",
      "iter = 82100, smooth loss = 1.593210, time = 83.39s\n",
      "iter = 82200, smooth loss = 1.585511, time = 83.49s\n",
      "iter = 82300, smooth loss = 1.600053, time = 83.59s\n",
      "iter = 82400, smooth loss = 1.604819, time = 83.69s\n",
      "iter = 82500, smooth loss = 1.601297, time = 83.79s\n",
      "iter = 82600, smooth loss = 1.590082, time = 83.89s\n",
      "iter = 82700, smooth loss = 1.584317, time = 83.99s\n",
      "iter = 82800, smooth loss = 1.582628, time = 84.08s\n",
      "iter = 82900, smooth loss = 1.575708, time = 84.18s\n",
      "iter = 83000, smooth loss = 1.573634, time = 84.29s\n",
      "Sample text at iteration 83000:\n",
      "tal soffered its; fin.  Who ene preath heard to the caw, there was and lasty offile the mups. hads that Harry's look notered over ontreat Harry's are wath place, then.  He - ot was air cround fornting\n",
      "\n",
      "Sample text at iteration 83000:\n",
      "tal soffered its; fin.  Who ene preath heard to the caw, there was and lasty offile the mups. hads that Harry's look notered over ontreat Harry's are wath place, then.  He - ot was air cround fornting\n",
      "\n",
      "iter = 83100, smooth loss = 1.575146, time = 84.39s\n",
      "iter = 83200, smooth loss = 1.578385, time = 84.49s\n",
      "iter = 83300, smooth loss = 1.586782, time = 84.59s\n",
      "iter = 83400, smooth loss = 1.592235, time = 84.69s\n",
      "iter = 83500, smooth loss = 1.597236, time = 84.79s\n",
      "iter = 83600, smooth loss = 1.599758, time = 84.89s\n",
      "iter = 83700, smooth loss = 1.604272, time = 84.99s\n",
      "iter = 83800, smooth loss = 1.604160, time = 85.09s\n",
      "iter = 83900, smooth loss = 1.611840, time = 85.19s\n",
      "iter = 84000, smooth loss = 1.602947, time = 85.29s\n",
      "Sample text at iteration 84000:\n",
      "Tom boy othing year lasts as Harry was in the tourst to that on his madic sore in there.  I my beilan eyestor fen, \"I had I who his ilat.. Voldemorich Eyon tuen withing.\n",
      "\"I ...\n",
      "\"Stert ot kill the him,\n",
      "\n",
      "Sample text at iteration 84000:\n",
      "Tom boy othing year lasts as Harry was in the tourst to that on his madic sore in there.  I my beilan eyestor fen, \"I had I who his ilat.. Voldemorich Eyon tuen withing.\n",
      "\"I ...\n",
      "\"Stert ot kill the him,\n",
      "\n",
      "iter = 84100, smooth loss = 1.594629, time = 85.39s\n",
      "iter = 84200, smooth loss = 1.587487, time = 85.49s\n",
      "iter = 84300, smooth loss = 1.579913, time = 85.59s\n",
      "iter = 84400, smooth loss = 1.570240, time = 85.70s\n",
      "iter = 84500, smooth loss = 1.560598, time = 85.80s\n",
      "iter = 84600, smooth loss = 1.550702, time = 85.90s\n",
      "iter = 84700, smooth loss = 1.549227, time = 86.00s\n",
      "iter = 84800, smooth loss = 1.544243, time = 86.09s\n",
      "iter = 84900, smooth loss = 1.543399, time = 86.19s\n",
      "iter = 85000, smooth loss = 1.535308, time = 86.30s\n",
      "Sample text at iteration 85000:\n",
      "ry, and.  \"I suddere Wart; and Dibving!\"  Moost?\"  shouters them, tist,\" said Moody fround to a happeath Harry upon at Minist teat as though foom, then he raundy!\"\n",
      "Harg,\" the go whose fare?\"\n",
      "\"Ind of b\n",
      "\n",
      "Sample text at iteration 85000:\n",
      "ry, and.  \"I suddere Wart; and Dibving!\"  Moost?\"  shouters them, tist,\" said Moody fround to a happeath Harry upon at Minist teat as though foom, then he raundy!\"\n",
      "Harg,\" the go whose fare?\"\n",
      "\"Ind of b\n",
      "\n",
      "iter = 85100, smooth loss = 1.540458, time = 86.40s\n",
      "iter = 85200, smooth loss = 1.544096, time = 86.50s\n",
      "iter = 85300, smooth loss = 1.541424, time = 86.60s\n",
      "iter = 85400, smooth loss = 1.550197, time = 86.70s\n",
      "iter = 85500, smooth loss = 1.551151, time = 86.80s\n",
      "iter = 85600, smooth loss = 1.556495, time = 86.89s\n",
      "iter = 85700, smooth loss = 1.557316, time = 86.99s\n",
      "iter = 85800, smooth loss = 1.550893, time = 87.09s\n",
      "iter = 85900, smooth loss = 1.548820, time = 87.20s\n",
      "iter = 86000, smooth loss = 1.535538, time = 87.30s\n",
      "Sample text at iteration 86000:\n",
      "s no to to letts had hyes of to magical's thit Dumbledore.  Withor.  It was veice. ...\" hounded how for them niever the wrear.  \"Moody was over thyor right under niring for my my frite.  He parmed fru\n",
      "\n",
      "Sample text at iteration 86000:\n",
      "s no to to letts had hyes of to magical's thit Dumbledore.  Withor.  It was veice. ...\" hounded how for them niever the wrear.  \"Moody was over thyor right under niring for my my frite.  He parmed fru\n",
      "\n",
      "iter = 86100, smooth loss = 1.536368, time = 87.41s\n",
      "iter = 86200, smooth loss = 1.533752, time = 87.51s\n",
      "iter = 86300, smooth loss = 1.529201, time = 87.61s\n",
      "iter = 86400, smooth loss = 1.524344, time = 87.71s\n",
      "iter = 86500, smooth loss = 1.519691, time = 87.80s\n",
      "iter = 86600, smooth loss = 1.519834, time = 87.90s\n",
      "iter = 86700, smooth loss = 1.519300, time = 88.00s\n",
      "iter = 86800, smooth loss = 1.526124, time = 88.10s\n",
      "iter = 86900, smooth loss = 1.524423, time = 88.20s\n",
      "iter = 87000, smooth loss = 1.537716, time = 88.30s\n",
      "Sample text at iteration 87000:\n",
      "is!\"       Profuss.  He are shipp, assee so dide to thines knarbed.\n",
      "\"No still starest it will if you now, go con hand pull in the moming of can't be puctast of you ary mistly!   o though.  \"\n",
      "\"Yeasaly \n",
      "\n",
      "Sample text at iteration 87000:\n",
      "is!\"       Profuss.  He are shipp, assee so dide to thines knarbed.\n",
      "\"No still starest it will if you now, go con hand pull in the moming of can't be puctast of you ary mistly!   o though.  \"\n",
      "\"Yeasaly \n",
      "\n",
      "iter = 87100, smooth loss = 1.540997, time = 88.40s\n",
      "iter = 87200, smooth loss = 1.539443, time = 88.50s\n",
      "iter = 87300, smooth loss = 1.538244, time = 88.60s\n",
      "iter = 87400, smooth loss = 1.536282, time = 88.70s\n",
      "iter = 87500, smooth loss = 1.534593, time = 88.80s\n",
      "iter = 87600, smooth loss = 1.532645, time = 88.90s\n",
      "iter = 87700, smooth loss = 1.547140, time = 89.00s\n",
      "iter = 87800, smooth loss = 1.540447, time = 89.11s\n",
      "iter = 87900, smooth loss = 1.538714, time = 89.21s\n",
      "iter = 88000, smooth loss = 1.547409, time = 89.31s\n",
      "Sample text at iteration 88000:\n",
      "efurs, sauce the bodding burlimend even HaRry place forwat of come of sigget the Gremereh bising ablerment of my into the . . ..\".   I knew reamy back of ane sint come of shread all everytricing Has e\n",
      "\n",
      "Sample text at iteration 88000:\n",
      "efurs, sauce the bodding burlimend even HaRry place forwat of come of sigget the Gremereh bising ablerment of my into the . . ..\".   I knew reamy back of ane sint come of shread all everytricing Has e\n",
      "\n",
      "iter = 88100, smooth loss = 1.555042, time = 89.41s\n",
      "iter = 88200, smooth loss = 1.557013, time = 89.51s\n",
      "iter = 88300, smooth loss = 1.558628, time = 89.61s\n",
      "iter = 88400, smooth loss = 1.560855, time = 89.71s\n",
      "iter = 88500, smooth loss = 1.565511, time = 89.81s\n",
      "iter = 88600, smooth loss = 1.564615, time = 89.91s\n",
      "Completed epoch at iteration 88603\n",
      "iter = 88700, smooth loss = 1.591096, time = 90.01s\n",
      "iter = 88800, smooth loss = 1.601052, time = 90.11s\n",
      "iter = 88900, smooth loss = 1.607337, time = 90.21s\n",
      "iter = 89000, smooth loss = 1.603776, time = 90.31s\n",
      "Sample text at iteration 89000:\n",
      "is alough on that him ull, it smert .... vady Profler loider the fronned to the door stobbed agains the pab his differe here whech soundead, thice, the was down a done opened parts of the spoon it onc\n",
      "\n",
      "Sample text at iteration 89000:\n",
      "is alough on that him ull, it smert .... vady Profler loider the fronned to the door stobbed agains the pab his differe here whech soundead, thice, the was down a done opened parts of the spoon it onc\n",
      "\n",
      "iter = 89100, smooth loss = 1.606762, time = 90.42s\n",
      "iter = 89200, smooth loss = 1.611216, time = 90.52s\n",
      "iter = 89300, smooth loss = 1.610069, time = 90.62s\n",
      "iter = 89400, smooth loss = 1.611067, time = 90.72s\n",
      "iter = 89500, smooth loss = 1.603415, time = 90.82s\n",
      "iter = 89600, smooth loss = 1.600007, time = 90.92s\n",
      "iter = 89700, smooth loss = 1.598229, time = 91.01s\n",
      "iter = 89800, smooth loss = 1.596258, time = 91.11s\n",
      "iter = 89900, smooth loss = 1.592122, time = 91.21s\n",
      "iter = 90000, smooth loss = 1.599566, time = 91.31s\n",
      "Sample text at iteration 90000:\n",
      "y aronasto insu coulde, before. Harry had for the have he pain applauge him.  It are carly, Curseo was go.. He follimed lorked of hismect to a latiover trouch Hermeation was had scrobling ous with to \n",
      "\n",
      "Sample text at iteration 90000:\n",
      "y aronasto insu coulde, before. Harry had for the have he pain applauge him.  It are carly, Curseo was go.. He follimed lorked of hismect to a latiover trouch Hermeation was had scrobling ous with to \n",
      "\n",
      "iter = 90100, smooth loss = 1.595362, time = 91.44s\n",
      "iter = 90200, smooth loss = 1.613848, time = 91.54s\n",
      "iter = 90300, smooth loss = 1.628563, time = 91.64s\n",
      "iter = 90400, smooth loss = 1.630056, time = 91.74s\n",
      "iter = 90500, smooth loss = 1.632153, time = 91.84s\n",
      "iter = 90600, smooth loss = 1.625673, time = 91.94s\n",
      "iter = 90700, smooth loss = 1.619620, time = 92.04s\n",
      "iter = 90800, smooth loss = 1.617811, time = 92.14s\n",
      "iter = 90900, smooth loss = 1.629889, time = 92.24s\n",
      "iter = 91000, smooth loss = 1.629729, time = 92.34s\n",
      "Sample text at iteration 91000:\n",
      "back, he dorch; sudden't back to them, alay not fur his room of year notian face, an his postand said, and if the wass's far up cranting he suddath.\n",
      "Warronsalays. The Darly winditeer, rould at this wa\n",
      "\n",
      "Sample text at iteration 91000:\n",
      "back, he dorch; sudden't back to them, alay not fur his room of year notian face, an his postand said, and if the wass's far up cranting he suddath.\n",
      "Warronsalays. The Darly winditeer, rould at this wa\n",
      "\n",
      "iter = 91100, smooth loss = 1.626559, time = 92.44s\n",
      "iter = 91200, smooth loss = 1.630924, time = 92.54s\n",
      "iter = 91300, smooth loss = 1.622988, time = 92.64s\n",
      "iter = 91400, smooth loss = 1.612440, time = 92.74s\n",
      "iter = 91500, smooth loss = 1.598933, time = 92.84s\n",
      "iter = 91600, smooth loss = 1.593842, time = 92.94s\n",
      "iter = 91700, smooth loss = 1.601055, time = 93.04s\n",
      "iter = 91800, smooth loss = 1.595617, time = 93.14s\n",
      "iter = 91900, smooth loss = 1.601020, time = 93.24s\n",
      "iter = 92000, smooth loss = 1.607533, time = 93.34s\n",
      "Sample text at iteration 92000:\n",
      "enew into you go when he placken, himing you assingrest!\"  Poldy thing a Pecale, exped outhers, could iz repiously assider Hermione the seathing awis Groat sighted down around Cup besnet at so to to h\n",
      "\n",
      "Sample text at iteration 92000:\n",
      "enew into you go when he placken, himing you assingrest!\"  Poldy thing a Pecale, exped outhers, could iz repiously assider Hermione the seathing awis Groat sighted down around Cup besnet at so to to h\n",
      "\n",
      "iter = 92100, smooth loss = 1.605578, time = 93.44s\n",
      "iter = 92200, smooth loss = 1.606333, time = 93.54s\n",
      "iter = 92300, smooth loss = 1.613691, time = 93.64s\n",
      "iter = 92400, smooth loss = 1.621368, time = 93.74s\n",
      "iter = 92500, smooth loss = 1.622055, time = 93.84s\n",
      "iter = 92600, smooth loss = 1.619662, time = 93.94s\n",
      "iter = 92700, smooth loss = 1.619584, time = 94.04s\n",
      "iter = 92800, smooth loss = 1.622040, time = 94.14s\n",
      "iter = 92900, smooth loss = 1.623895, time = 94.24s\n",
      "iter = 93000, smooth loss = 1.625862, time = 94.34s\n",
      "Sample text at iteration 93000:\n",
      "ll chill hand!\" said I car?\" Harry, All....  He smyen legg, umady, like asce up to be boty.\n",
      "\"It weatded Mr. Weasl you?\"\n",
      "\"Ye's back in gleave air sloom off the Billoms; then, carry bet earway, and up b\n",
      "\n",
      "Sample text at iteration 93000:\n",
      "ll chill hand!\" said I car?\" Harry, All....  He smyen legg, umady, like asce up to be boty.\n",
      "\"It weatded Mr. Weasl you?\"\n",
      "\"Ye's back in gleave air sloom off the Billoms; then, carry bet earway, and up b\n",
      "\n",
      "iter = 93100, smooth loss = 1.635668, time = 94.45s\n",
      "iter = 93200, smooth loss = 1.631281, time = 94.54s\n",
      "iter = 93300, smooth loss = 1.635594, time = 94.65s\n",
      "iter = 93400, smooth loss = 1.638453, time = 94.75s\n",
      "iter = 93500, smooth loss = 1.645653, time = 94.85s\n",
      "iter = 93600, smooth loss = 1.645046, time = 94.95s\n",
      "iter = 93700, smooth loss = 1.646181, time = 95.05s\n",
      "iter = 93800, smooth loss = 1.656437, time = 95.15s\n",
      "iter = 93900, smooth loss = 1.662587, time = 95.25s\n",
      "iter = 94000, smooth loss = 1.664771, time = 95.35s\n",
      "Sample text at iteration 94000:\n",
      "  Bagman'.  \"but a laugely approily voired a blasly Percy had nept.  Lugh Quidden....\n",
      "We sciled shrite edgetly -- I the how Cup,  sair Spunk Marummed tern the daparews and ash to deyer.\"...\"\n",
      "\"Oh it. H\n",
      "\n",
      "Sample text at iteration 94000:\n",
      "  Bagman'.  \"but a laugely approily voired a blasly Percy had nept.  Lugh Quidden....\n",
      "We sciled shrite edgetly -- I the how Cup,  sair Spunk Marummed tern the daparews and ash to deyer.\"...\"\n",
      "\"Oh it. H\n",
      "\n",
      "iter = 94100, smooth loss = 1.664192, time = 95.45s\n",
      "iter = 94200, smooth loss = 1.668762, time = 95.55s\n",
      "iter = 94300, smooth loss = 1.668024, time = 95.65s\n",
      "iter = 94400, smooth loss = 1.677240, time = 95.75s\n",
      "iter = 94500, smooth loss = 1.670146, time = 95.85s\n",
      "iter = 94600, smooth loss = 1.665950, time = 95.95s\n",
      "iter = 94700, smooth loss = 1.665030, time = 96.04s\n",
      "iter = 94800, smooth loss = 1.671711, time = 96.14s\n",
      "iter = 94900, smooth loss = 1.675195, time = 96.24s\n",
      "iter = 95000, smooth loss = 1.699724, time = 96.34s\n",
      "Sample text at iteration 95000:\n",
      "SEx\n",
      "WTEn Harrys pail edge-Toing ammeat!\"\n",
      "The wards!\"\n",
      "Harry be you Glowntly!\"\n",
      "Canting to be snackon That they hand!\"\n",
      "\"Seay, who potting formin, spearle.\n",
      "\"Wo the enersiod had tinnoing! och said suder to\n",
      "\n",
      "Sample text at iteration 95000:\n",
      "SEx\n",
      "WTEn Harrys pail edge-Toing ammeat!\"\n",
      "The wards!\"\n",
      "Harry be you Glowntly!\"\n",
      "Canting to be snackon That they hand!\"\n",
      "\"Seay, who potting formin, spearle.\n",
      "\"Wo the enersiod had tinnoing! och said suder to\n",
      "\n",
      "iter = 95100, smooth loss = 1.706588, time = 96.44s\n",
      "iter = 95200, smooth loss = 1.707654, time = 96.54s\n",
      "iter = 95300, smooth loss = 1.701171, time = 96.64s\n",
      "iter = 95400, smooth loss = 1.697527, time = 96.74s\n",
      "iter = 95500, smooth loss = 1.696787, time = 96.84s\n",
      "iter = 95600, smooth loss = 1.686821, time = 96.94s\n",
      "iter = 95700, smooth loss = 1.682138, time = 97.04s\n",
      "iter = 95800, smooth loss = 1.674028, time = 97.14s\n",
      "iter = 95900, smooth loss = 1.657316, time = 97.24s\n",
      "iter = 96000, smooth loss = 1.650800, time = 97.34s\n",
      "Sample text at iteration 96000:\n",
      "y back Bagman's,\" Saministovy.\n",
      "\"Weasley, hallo's hays to replance, \"warts of you!\"\n",
      "\"Neser and a gral the Weard ruther ou'll pilked trey from dreakly. He gray,\" said Muss they was come were any everat!\n",
      "\n",
      "Sample text at iteration 96000:\n",
      "y back Bagman's,\" Saministovy.\n",
      "\"Weasley, hallo's hays to replance, \"warts of you!\"\n",
      "\"Neser and a gral the Weard ruther ou'll pilked trey from dreakly. He gray,\" said Muss they was come were any everat!\n",
      "\n",
      "iter = 96100, smooth loss = 1.644369, time = 97.44s\n",
      "iter = 96200, smooth loss = 1.646484, time = 97.54s\n",
      "iter = 96300, smooth loss = 1.633889, time = 97.64s\n",
      "iter = 96400, smooth loss = 1.628117, time = 97.74s\n",
      "iter = 96500, smooth loss = 1.616989, time = 97.84s\n",
      "iter = 96600, smooth loss = 1.613613, time = 97.94s\n",
      "iter = 96700, smooth loss = 1.609047, time = 98.04s\n",
      "iter = 96800, smooth loss = 1.602574, time = 98.14s\n",
      "iter = 96900, smooth loss = 1.597170, time = 98.23s\n",
      "iter = 97000, smooth loss = 1.589226, time = 98.34s\n",
      "Sample text at iteration 97000:\n",
      "ot the orouse moke happeeated, will the tame, Care conKryat throut!\" shehe?\"\n",
      "And heared,\" he had exaces, swembelty of mastenfright fall creaniin, jout come Mo Mr. Crouch've how Mr. Wewly yod. \"And Cod\n",
      "\n",
      "Sample text at iteration 97000:\n",
      "ot the orouse moke happeeated, will the tame, Care conKryat throut!\" shehe?\"\n",
      "And heared,\" he had exaces, swembelty of mastenfright fall creaniin, jout come Mo Mr. Crouch've how Mr. Wewly yod. \"And Cod\n",
      "\n",
      "iter = 97100, smooth loss = 1.576385, time = 98.44s\n",
      "iter = 97200, smooth loss = 1.569184, time = 98.54s\n",
      "iter = 97300, smooth loss = 1.567334, time = 98.64s\n",
      "iter = 97400, smooth loss = 1.579309, time = 98.74s\n",
      "iter = 97500, smooth loss = 1.590408, time = 98.84s\n",
      "iter = 97600, smooth loss = 1.588336, time = 98.94s\n",
      "iter = 97700, smooth loss = 1.597091, time = 99.04s\n",
      "iter = 97800, smooth loss = 1.607916, time = 99.14s\n",
      "iter = 97900, smooth loss = 1.604854, time = 99.24s\n",
      "iter = 98000, smooth loss = 1.609016, time = 99.34s\n",
      "Sample text at iteration 98000:\n",
      "e croubly.\n",
      "\"Cerrassor preper.\n",
      "\"What's a been songsting lowotr you moong,\" saiwise Fray,\"  R mo Beed, borron of paired looked looks, I after,\" he so looked zordy's place, and Quartly.\n",
      "\"No,\" seelves all\n",
      "\n",
      "Sample text at iteration 98000:\n",
      "e croubly.\n",
      "\"Cerrassor preper.\n",
      "\"What's a been songsting lowotr you moong,\" saiwise Fray,\"  R mo Beed, borron of paired looked looks, I after,\" he so looked zordy's place, and Quartly.\n",
      "\"No,\" seelves all\n",
      "\n",
      "iter = 98100, smooth loss = 1.606784, time = 99.44s\n",
      "iter = 98200, smooth loss = 1.603403, time = 99.54s\n",
      "iter = 98300, smooth loss = 1.599285, time = 99.64s\n",
      "iter = 98400, smooth loss = 1.613345, time = 99.75s\n",
      "iter = 98500, smooth loss = 1.601338, time = 99.85s\n",
      "iter = 98600, smooth loss = 1.607768, time = 99.94s\n",
      "iter = 98700, smooth loss = 1.618163, time = 100.04s\n",
      "iter = 98800, smooth loss = 1.620672, time = 100.14s\n",
      "iter = 98900, smooth loss = 1.629032, time = 100.25s\n",
      "iter = 99000, smooth loss = 1.637093, time = 100.35s\n",
      "Sample text at iteration 99000:\n",
      "ch stoppeder; Hous to at the firaying nived Hid Crquilky the Snoses be all herd to still-y. .  Luth Harry and they well, thy them!\"\n",
      "\"The tapk ovesst pormed.\n",
      "\"Exerenglity, when Noth here, her inte star\n",
      "\n",
      "Sample text at iteration 99000:\n",
      "ch stoppeder; Hous to at the firaying nived Hid Crquilky the Snoses be all herd to still-y. .  Luth Harry and they well, thy them!\"\n",
      "\"The tapk ovesst pormed.\n",
      "\"Exerenglity, when Noth here, her inte star\n",
      "\n",
      "iter = 99100, smooth loss = 1.637154, time = 100.45s\n",
      "iter = 99200, smooth loss = 1.650236, time = 100.55s\n",
      "iter = 99300, smooth loss = 1.664896, time = 100.65s\n",
      "iter = 99400, smooth loss = 1.671000, time = 100.75s\n",
      "iter = 99500, smooth loss = 1.670874, time = 100.85s\n",
      "iter = 99600, smooth loss = 1.676877, time = 100.95s\n",
      "iter = 99700, smooth loss = 1.665181, time = 101.05s\n",
      "iter = 99800, smooth loss = 1.664855, time = 101.15s\n",
      "iter = 99900, smooth loss = 1.661192, time = 101.25s\n",
      "iter = 100000, smooth loss = 1.652206, time = 101.35s\n",
      "Sample text at iteration 100000:\n",
      " like George, and Beadled all yetr, surkinfies wooked soomely now, Ron're who were wrom; shosed hand's seuddentians were cloeans table, halled though?\"  said  well gunger hoveing his yevered and Goors\n",
      "\n",
      "Sample text at iteration 100000:\n",
      " like George, and Beadled all yetr, surkinfies wooked soomely now, Ron're who were wrom; shosed hand's seuddentians were cloeans table, halled though?\"  said  well gunger hoveing his yevered and Goors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize the model\n",
    "model = RNN(K, m, rng)\n",
    "\n",
    "# Train for a larger number of iterations\n",
    "num_updates = 100000\n",
    "print(f\"Training the model for {num_updates} iterations...\")\n",
    "loss_history, sample_texts, sample_iters = train_rnn(\n",
    "    model, book_data, char_to_ind, ind_to_char, \n",
    "    seq_length=seq_length, eta=eta, num_updates=num_updates, rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot full loss history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.title('Training Loss (Full Training)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 1000-character sample from the fully trained model...\n",
      "e on, Dooky again,\" said Mr. Weaslin, but but your stowing an stufl,\" said Rod in,\" said Dumbledore's students was nevely.\n",
      "\"Aho'l, and Harry, \"sompirtion whoch, Ron, how, And Georted, gotweldly caured his fowr stown it, under coulled every derin-oy of woole naws.  \"Mosling,\" said Molding a tould tore.  \"Dumbledes wanding years openticalnd anxixcion lime her saviones not of who seemed it ispation who do that on a tapsed know last Hermury, Dust Dearlnes, Frose.  The coulsend whore fuets, and Geornes, are to prokentry chowers led retea know, anyon, eyes...  Do-blake incr. Goodars.  Ou and George ent.\n",
      "\"But' Genece innisemer ovey woodent to courch?  he roumentiniors to up,\" sain.\n",
      "\"What was anpotted.  \"Don'mogs.\n",
      "\"Every you atturestence evan, puoder on eyes, and Aude is.  The threalp rutmins beched neem inting to George, unliads looking though it deen was a there.  \"Pamansthay a tappes one pusncing them is is ears, wooking stoul wey.\n",
      "\"She suppespa compse Marks, a lessed toolers ond-once is to\n"
     ]
    }
   ],
   "source": [
    "# Generate a longer sample from the fully trained model\n",
    "h0 = np.zeros((m, 1))\n",
    "x0 = np.zeros((K, 1))\n",
    "x0[char_to_ind[book_data[0]], 0] = 1\n",
    "\n",
    "print(\"Generating a 1000-character sample from the fully trained model...\")\n",
    "final_sample, _ = model.synthesize_text(h0, x0, 1000, ind_to_char, char_to_ind, rng=rng)\n",
    "print(final_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Data for Report\n",
    "\n",
    "Here we examine samples from different stages of training to observe the model's progression.\n",
    "\n",
    "### Interpreting the Results:\n",
    "\n",
    "The output shows samples from different training stages with their corresponding iteration number and loss value:\n",
    "\n",
    "- **Early Training (iterations 1-5000)**: Text is mostly random characters with no real structure\n",
    "- **Middle Training (iterations 10000-50000)**: \n",
    "  - Words begin to form\n",
    "  - Basic sentence structure emerges\n",
    "  - Character names appear\n",
    "  - Still contains many errors and nonsensical sequences\n",
    "- **Late Training (iterations 50000-100000)**:\n",
    "  - More coherent sentences\n",
    "  - Better grammar\n",
    "  - Character dialogue with quotes\n",
    "  - Recognizable narrative elements from Harry Potter\n",
    "\n",
    "The loss decreases rapidly at first and then stabilizes, showing that the model becomes better at predicting the next character but has inherent limitations due to its size and architecture.\n",
    "\n",
    "This progression illustrates how RNNs learn language from the character level up:\n",
    "1. First learning character frequencies\n",
    "2. Then common character combinations\n",
    "3. Then word-like structures\n",
    "4. Then simple grammar patterns\n",
    "5. And finally, elements of the narrative style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 1, smooth loss=109.44553596936932\n",
      "^-Am}oz07g(uJ;zciCLnBNE9JIZ•;YphGXbTü6t\tDzZB\"}ybDY;,SK1YQfwüpO1tW/4YZ-•MeKyZIW6;6v(J•1!lidG\n",
      ";CH!di\tV:k0gkRyAVd•Tmw4ekd1XY904I}GliVW2jC\n",
      "H_H2NE'0,(.sCEdD\"2.Aa:HyZWYrV9cEvss\n",
      "/fY0afzZsI)WüfwmRnfsjW;b\tec26\n",
      "\n",
      "iter = 5000, smooth loss=2.8938249089332806\n",
      "in deids at them,\" on then'e uriingr juppuriplirs?\" Mry'sqeat, thaked shouple Is ardy thene eavisgudras, \"nyayg neonve thiike the thet crouor of themulliscing ouvirniching wen, whald; of rraillacknte \n",
      "\n",
      "iter = 10000, smooth loss=2.0170646501161604\n",
      "- om Did ly ow whe fas mats a cll?\"\n",
      "\"Bugl wat doune fine Cung a dedla treng of to picined eia seur vartsef emaks ank ele,\",\"\n",
      "'s Cometoly dobett,\" seaded ald acll treisly.  \"Mr.  hibe E wreald shane in\n",
      "\n",
      "iter = 15000, smooth loss=1.9477187656302413\n",
      ", and as enone llay umbind the aoplling at ank ortininglf clumbledone of ag in beck fustureato tlle, Durthey and midl he pered deend to Harry doowdorno lilking of the raldys Cenk atp atris hem's.  Dom\n",
      "\n",
      "iter = 20000, smooth loss=1.8470070083652699\n",
      "i.s Pettart abont Hagry uld in feched ach edereadly falkaing untaring to so had wormary thounging alk how in him, the fire aly intt bet them out. Tearth; and he hecrees ; a size bat withire wozaring t\n",
      "\n",
      "iter = 25000, smooth loss=1.8260110059886316\n",
      "ing seelednty, the uidanon, and bevirgone edy santely look ith eame.  Ha'ry he'clusier\n",
      "Sne of the himaly oney trale and of the was whetenosurdlys.\n",
      "\"S at Krumbon Hall skald githyoug piss sisted.\n",
      "The si\n",
      "\n",
      "iter = 30000, smooth loss=1.7934616652062634\n",
      "sper the vorg fatir.  Ye the washer ally on ha shay of the girer sen\"Whehe of thambo the laage afly of . . . ...\n",
      "He didne therorgss not viccull shrot over cnispe, an!  inter melenge s welzars weres,\n",
      "Y\n",
      "\n",
      "iter = 35000, smooth loss=1.71505058027931\n",
      "makaplatse Bagmbe!\"\n",
      "\"Co veryan paine;, I ne hapry looked and said I momenintcone the muld hissidg the even yffor. \"\n",
      "\"If to see this,\"  .  Profes, she was les wand to somean?\" said Hersierther had peam\n",
      "\n",
      "iter = 40000, smooth loss=1.6895974290875657\n",
      "hrourd thet thet dair chillfed thes, that.  I mass - Hermiat me into that aplarted biggiculld pioming now bease? \"Harry were rears, didn't retchen Lome tere; I was oven, \"\n",
      "Eand and a pee ford how.  bo\n",
      "\n",
      "iter = 45000, smooth loss=1.7094056525547527\n",
      "at at oul mitthestell mutters wimd beft to goo he deeld!  So wang carm a fre would hok wald tood like more hes was proice wos don lought could me.\"  It of yoing fill he Vith?\"  say to whot of condine \n",
      "\n",
      "iter = 50000, smooth loss=1.7467079064338618\n",
      "seetes them?   He was aid als wach fineves and Geary, what the.  The nomeen my a smigh,\" said Harry themes, stulled angienatch been scoolst here hombed pheir plocking having of chuers all seed - they \n",
      "\n",
      "iter = 55000, smooth loss=1.7376871220811982\n",
      "oume\n",
      "Long as saaxing a brove, with the batwed the ceat-ell ttatters, we Grope, cillswly calloully, as he said, therr toobleded apperiagon winched and deears the Mast you're with it was glife torble si\n",
      "\n",
      "iter = 60000, smooth loss=1.6596273360308766\n",
      " uned a seew Rig the live.\n",
      "The than you about stains' was the risemess mum of sugget, stasn of the trunger aspang.\n",
      "\"Astletching theled, wing as Hermione in into the id to shags feet, and yeaget, then \n",
      "\n",
      "iter = 65000, smooth loss=1.6363145918884399\n",
      "on yould I very ncally gass, wondent what it enterted an ideas bepy ut fued les.  They had you because the out to that,\"Seersy twong to in tigh toble he back treer in the firse sey.  Are I'd that wo k\n",
      "\n",
      "iter = 70000, smooth loss=1.66045515491432\n",
      "iruch's air.  Whthe really coll be a gone.\n",
      "\"Devel sor from Kauxin't hoden histots singiring you rage agan, Her, Professo patter Kurracougo beally.\n",
      "At Ker!\"\n",
      "Parvati.  Ron coom Marmowing they winding ex\n",
      "\n",
      "iter = 75000, smooth loss=1.6302177694773206\n",
      "ven and it was was just are awore tassere fact, Pottying I down buf Hermione has time to capsees outtile, subpring warted to Roghre.  Outhis were to Lad hare's guldes verledys of the their mos, and qu\n",
      "\n",
      "iter = 80000, smooth loss=1.5847140516031046\n",
      " me their was asly wall. Ron't will wouldn't she neverth aroff; Alkime of large whic.  Hagrine: . . . theyend?  Nothally frokend thes could supfen his swaved, very spillight was thispering elly; his v\n",
      "\n",
      "iter = 85000, smooth loss=1.5353078013436883\n",
      "ry, and.  \"I suddere Wart; and Dibving!\"  Moost?\"  shouters them, tist,\" said Moody fround to a happeath Harry upon at Minist teat as though foom, then he raundy!\"\n",
      "Harg,\" the go whose fare?\"\n",
      "\"Ind of b\n",
      "\n",
      "iter = 90000, smooth loss=1.59956599261281\n",
      "y aronasto insu coulde, before. Harry had for the have he pain applauge him.  It are carly, Curseo was go.. He follimed lorked of hismect to a latiover trouch Hermeation was had scrobling ous with to \n",
      "\n",
      "iter = 95000, smooth loss=1.6997240004710792\n",
      "SEx\n",
      "WTEn Harrys pail edge-Toing ammeat!\"\n",
      "The wards!\"\n",
      "Harry be you Glowntly!\"\n",
      "Canting to be snackon That they hand!\"\n",
      "\"Seay, who potting formin, spearle.\n",
      "\"Wo the enersiod had tinnoing! och said suder to\n",
      "\n",
      "iter = 100000, smooth loss=1.652205715854137\n",
      " like George, and Beadled all yetr, surkinfies wooked soomely now, Ron're who were wrom; shosed hand's seuddentians were cloeans table, halled though?\"  said  well gunger hoveing his yevered and Goors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print samples for the report\n",
    "for i, (iteration, text) in enumerate(zip(sample_iters, sample_texts)):\n",
    "    if i % 10 == 0 or i == 0:\n",
    "        print(f\"iter = {iteration}, smooth loss={loss_history[iteration-1]}\")\n",
    "        print(text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skynet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
